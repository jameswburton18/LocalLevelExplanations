{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/CodingProjects/Local_level_model_explanations/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import simplify_narr_question, label_qs\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 375/375 [00:00<00:00, 7429.51ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 8021.99ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 7907.43ex/s]\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(\"james-burton/textual-explanations\", split='train')\n",
    "test = load_dataset(\"james-burton/textual-explanations\", split='test')\n",
    "val = load_dataset(\"james-burton/textual-explanations\", split='validation')\n",
    "\n",
    "simple_train = train.map(lambda x: simplify_narr_question(label_qs(x)),\n",
    "                              load_from_cache_file=False)\n",
    "simple_val = val.map(lambda x: simplify_narr_question(label_qs(x)),\n",
    "                                load_from_cache_file=False) \n",
    "simple_test = test.map(lambda x: simplify_narr_question(label_qs(x)),\n",
    "                                load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['model_name', 'predicted_class', 'task_name', 'narration', 'values', 'sign', 'narrative_id', 'unique_id', 'classes_dict', 'narrative_questions', 'feature_nums', 'ft_num2name', 'old2new_ft_nums', 'old2new_classes', 'narr_q_label', 'narr_q_label_group', 'original_narrative_questions'],\n",
       "    num_rows: 375\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "reg = re.compile(r'F\\d+')\n",
    "mentions = [[reg.findall(n)for n in l['narrative_questions']][1] for l in simple_train if l['narrative_questions'][1][:28] == \"Summarise these top features\"]\n",
    "all_fts = [l['feature_nums'] for l in simple_train if l['narrative_questions'][1][:28] == \"Summarise these top features\"]\n",
    "indexes = [[narr.index(val) for val in mention] for narr, mention in zip(all_fts, mentions)]\n",
    "\n",
    "rev_indexes = [[narr[::-1].index(val) for val in mention] for narr, mention in zip(all_fts, mentions)]\n",
    "\n",
    "for i, r_i in zip(indexes, rev_indexes):\n",
    "    # print(i, r_i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [0, 1, 2, 3, 17, 18, 19], [], [2, 3, 4, 7], [0, 1, 5, 6], [0, 1]]\n",
      "[[], [0, 1], [0, 1], [2, 3, 4, 7, 10], [9, 10, 11]]\n",
      "[[], [0, 1, 2], [3, 4, 5, 6, 7, 8, 9], [0, 2, 1], [1, 3, 4, 6, 7, 5], [8, 9, 9]]\n",
      "[[], [], [], [0, 1, 2, 3, 4, 5, 6], [3, 1], [0, 2, 4]]\n",
      "[[], [1, 0, 2], [3, 5, 4], [6, 7, 8, 9], []]\n",
      "[[], [0, 1, 2, 3, 4], [20, 21, 22, 23], [], [0, 1, 2, 3, 4], []]\n",
      "[[], [], [0, 1, 2, 3, 5, 6, 4, 32, 33, 34, 35, 36, 37], [], [0, 1, 2, 3, 4, 0, 1], [2, 3, 4], [5, 6, 7], [0, 1, 8, 9, 2, 3, 7, 5, 6, 4]]\n",
      "[[0, 1, 2, 4, 3], [3, 4], [3, 4, 5, 6], [0, 1, 2], [7, 8, 10, 9], [0, 1, 2, 10, 7]]\n",
      "[[], [0, 1], [0, 1], [3, 2, 4, 10, 7], [9, 10, 11]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [0, 1, 2, 3, 4], [6, 7, 5], [20, 21, 22, 23]]\n",
      "[[], [1, 2, 3, 0, 4, 5, 6, 7, 8], [], [1, 2, 3], [3, 2, 1]]\n",
      "[[0, 1], [2, 3, 4, 6, 5, 7, 8], [0, 1, 2, 3], [4, 5, 6], [7, 8, 8, 7]]\n",
      "[[2, 3, 1, 0], [], [0, 1, 2, 3], [0, 1, 4, 5], [6, 7, 8, 2]]\n",
      "[[], [0, 1, 2, 3, 0], [0, 1, 2, 3, 4], [5, 6, 7, 5], [14, 15, 16, 17, 18]]\n",
      "[[], [12, 13, 0, 1], [2, 4, 10, 9, 11, 13], [], [1, 3, 0, 7, 8, 5, 6]]\n",
      "[[], [], [0, 1, 2, 3, 16, 17, 18, 19], [0, 1, 3], [2, 4, 5], [6, 7, 8, 10, 9]]\n",
      "[[], [], [0, 1, 2, 3, 4], [0], [], [0, 2, 1, 3, 4], [5, 6], [7, 8, 9, 10], [20, 21, 23, 22]]\n",
      "[[], [], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [20, 21, 22], [0, 1, 2, 3, 4, 2], [6, 5, 7], []]\n",
      "[[], [], [0, 1, 3, 2], [4, 5, 6, 8, 9, 7], [0, 2, 9, 8], [1, 5, 7, 3, 4, 6], [20, 22, 21, 23]]\n",
      "[[], [0, 1, 2, 3], [12, 13], [], [], [2, 4, 9, 10, 11, 13, 0, 1, 5, 3]]\n",
      "[[], [0, 1, 2, 3], [8, 9, 10], [3, 5, 9, 10], [1, 0, 2]]\n",
      "[[], [], [], [0, 1, 2, 3, 5, 6, 7], [0, 1, 2], [3], [3, 4, 5, 6], [0, 1, 2, 3], [7, 8, 10, 9], [7, 9, 8, 10]]\n",
      "[[], [0, 1, 2, 3, 4, 4], [0, 1, 2, 3], [5, 6, 11, 8, 10, 12, 7, 9], [21, 20, 22, 23], [0, 1, 39, 38]]\n",
      "[[], [], [0, 1, 2, 3, 4], [5, 10, 12, 15], [16, 17, 18]]\n",
      "[[], [], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 0], [7, 6], [], [4, 2, 3, 8, 9]]\n",
      "[[], [], [0, 1], [], [3, 4, 13, 16], [2, 5, 6, 7], [20, 21, 22, 23, 25, 24]]\n",
      "[[], [0, 1], [2, 3, 4, 5], [6, 8, 7, 9]]\n",
      "[[], [], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [20, 21, 22], [0, 1, 2, 3, 4, 2], [6, 5, 7, 6, 5, 7], []]\n",
      "[[], [], [0, 1, 2, 3, 5, 6, 4, 34, 33, 32, 37, 36, 35], [], [0, 1, 0, 1, 2, 3, 4], [2, 3, 4], [5, 6, 7], [0, 1, 8, 9, 2, 3, 7, 5, 6, 4]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 7], [1, 4, 5], [0, 2, 3, 6, 7], []]\n",
      "[[], [0, 1, 2], [20, 21, 22, 23], [2, 8, 9, 5, 0, 1, 3, 6, 7, 10, 4]]\n",
      "[[], [], [], [0, 1, 2, 3, 5, 4], [20, 22, 21, 24, 23], [], [0, 1, 2, 3, 13, 7, 16, 17], [5, 6, 4, 10, 8, 9, 11, 12]]\n",
      "[[], [0, 1, 2, 4, 3], [0, 1, 2, 4], [3, 5, 8, 6], [7, 12, 14, 21], [0, 1, 2], []]\n",
      "[[], [0, 1, 2, 3], [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, 1], [2, 3, 4, 5], [6, 7, 8, 9], [6, 7, 8, 9], [20, 22, 21]]\n",
      "[[], [], [0, 1, 2, 3, 11, 12, 13], [0, 3, 11, 13], [1, 2, 4, 5, 6, 7]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6], [4, 5], [0, 1, 2]]\n",
      "[[], [0, 1], [1], [0, 2, 3], [5, 6, 4, 7], [8, 9, 10, 11]]\n",
      "[[], [0, 1, 2, 4, 3], [0, 1, 2, 3, 4], [9, 8, 5, 6, 0, 1, 2], [0, 1, 2, 7]]\n",
      "[[], [6, 5], [], [], [0, 1, 3, 4, 2]]\n",
      "[[], [], [15, 1], [2, 3, 4, 7, 5], [6, 8, 9, 10], [0, 2, 3, 1], [], [20, 21, 23, 22]]\n",
      "[[], [0, 6, 7, 8], [1, 2, 3, 4, 5], [], [0, 3, 4, 6, 1, 2, 5, 7, 8]]\n",
      "[[0, 1, 2, 3, 4], [], [], [], [0, 2, 1, 3], [0, 2, 3, 1], [4, 5], [6, 7, 8, 9], [10, 11]]\n",
      "[[], [], [2, 0, 1, 3, 4], [0, 1], [5, 6, 8, 7], [7, 5, 6, 8], [9, 11, 10]]\n",
      "[[], [0, 1], [2, 3, 4, 5], [6, 8, 7, 9], [11, 12, 14, 13, 13]]\n",
      "[[], [0, 1, 2, 3], [6, 7, 8, 9], [37, 38, 39], [0, 2], [1], [1, 5, 8, 16, 18, 19]]\n",
      "[[], [], [1, 0], [0, 1], [3, 2, 4, 7, 10, 11], [9, 10, 11]]\n",
      "[[], [], [0, 1, 2], [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19], [], [3, 4, 0, 1, 2, 5], []]\n",
      "[[], [0, 1, 2, 8, 9], [1, 0], [6, 7], [1, 7, 0, 6], [2, 3, 4]]\n",
      "[[], [], [0, 1], [2, 3, 4, 5, 2, 1, 4, 5, 3], [0, 7, 6]]\n",
      "[[], [0, 1, 2], [3, 5, 6, 7, 8], [], []]\n",
      "[[], [], [0, 1, 2, 3, 5, 4, 21, 20, 22, 23, 24], [1, 6, 3, 7], [10, 12, 13, 11], [0, 2, 4, 5, 8, 14, 9], [0]]\n",
      "[[], [0, 1], [5, 4, 3, 2, 2, 4, 5, 3], [6, 7, 0]]\n",
      "[[], [0, 1, 2, 3, 4], [4, 0, 1, 2, 3], [5, 6, 11, 8, 10, 12, 7, 9], [21, 20, 22, 23], [0, 2, 1]]\n",
      "[[], [0, 1], [2, 3, 4, 5], [6, 8, 7, 9]]\n",
      "[[], [], [0, 1, 2, 3], [0, 3, 5, 1], [2, 4, 6, 7, 9], [30, 37, 22], []]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6], [1, 3], [0, 2, 4, 5, 6]]\n",
      "[[], [], [], [], [], [0, 1, 2, 3, 4, 5], [0, 3], [1, 2, 4, 5]]\n",
      "[[], [0, 1, 2, 3], [0, 2, 1, 3], [4, 5, 6]]\n",
      "[[], [1, 0, 2, 3], [4, 5, 6, 9], [7, 8, 13, 15], []]\n",
      "[[], [], [0, 3, 11, 13], [1, 2, 4, 5, 6, 8, 9, 7]]\n",
      "[[], [0, 1, 2, 3], [8, 9, 10], [3, 5, 9, 10], [], [1, 0, 2]]\n",
      "[[], [0, 1, 3, 2], [8, 9, 10], [1, 0, 2], [3, 5, 9, 10]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [], [6, 5, 3, 2, 7, 0], [8, 9, 10, 11]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [], [2, 3, 6, 5, 7], [0], [8, 9, 10, 11]]\n",
      "[[], [], [0, 2, 1, 3, 4, 5, 6, 7], [9, 15, 17], [], [9, 15, 17, 0, 1, 3, 2]]\n",
      "[[], [2, 1, 0, 0, 1, 2], [2, 3, 7, 10, 5, 4], [6, 7, 8, 9, 18, 19, 17]]\n",
      "[[], [], [0, 1, 2, 3, 4], [5, 10, 12, 15], [16, 17, 18]]\n",
      "[[], [], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [], [2, 3, 6, 5, 7], [0, 8, 9, 10, 11]]\n",
      "[[], [0, 0, 1, 2, 3], [0, 1, 2, 3, 4], [5, 6, 7, 5, 10, 11, 13], [14, 15, 16, 17, 18]]\n",
      "[[], [], [], [0, 1, 2, 3, 17, 18, 19], [3, 2, 7, 4], [0, 5, 6, 1], [0, 1]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [0, 7, 8, 14, 1], [2, 3, 4, 5, 6, 9]]\n",
      "[[], [0, 1, 2, 3, 4, 5], [0, 1], [3, 4, 10, 11, 5], [2, 6, 7, 8, 9], [13, 14, 15]]\n",
      "[[], [], [0, 1, 3, 2], [4, 5, 6, 8, 9, 7], [0, 2, 9, 8, 1, 3, 4, 5, 7, 6], [20, 21, 22, 23]]\n",
      "[[], [], [0, 1, 3, 2], [0, 3, 2], [], [1, 5, 4], []]\n",
      "[[], [], [15, 1], [5, 3, 7, 4, 2], [6, 8, 9, 10], [0, 2, 3, 1], [23, 21, 20, 22]]\n",
      "[[], [0, 1, 2, 3], [4, 6], [5, 8], [7, 9], [11]]\n",
      "[[], [0, 1, 2], [3, 5, 6, 8], [], [0, 1, 2, 4, 7]]\n",
      "[[], [], [0, 1, 2, 3, 4, 5, 6, 7], [1, 4, 5], [0, 2, 3, 6, 7], []]\n",
      "[[], [0, 1, 2, 3, 4, 5], [], [20, 22, 21, 23], [0, 1, 2, 3, 7], [4, 5, 6, 8, 10, 9, 11, 12], [0, 1]]\n",
      "[[], [0, 1, 2, 3], [10, 11, 12], [], [0, 1, 3, 6, 7, 4, 2, 5, 9]]\n",
      "[[], [0, 4, 1, 2, 7, 5, 6, 3, 8], [7, 6, 0, 1], [2, 3, 4, 5], [8]]\n",
      "[[], [0, 3, 1, 2], [13, 14], [], [13, 1, 9, 14], [1, 3, 2, 4]]\n",
      "[[], [0, 1, 2, 3], [4, 6], [5, 8], [9, 7, 11]]\n",
      "[[], [0, 1, 2, 3], [3], [3, 4, 5, 6], [0, 1, 2], [7, 8, 9, 10], [0, 1, 2, 7]]\n",
      "[[], [2, 0, 1, 3], [5, 9, 11, 4], [6, 8, 10, 7], []]\n",
      "[[], [0, 1, 2, 3, 0, 3], [5, 6, 4], [7]]\n",
      "[[], [], [0, 1, 2], [8, 9], [1, 6, 7, 0], [2, 3, 4]]\n",
      "[[], [], [0, 1, 2], [0, 1, 2, 3, 4, 5], [0, 1, 2, 4, 8], [3, 5, 6, 7, 9], []]\n",
      "[[], [0, 2, 1, 3, 10, 11, 12], [0, 1, 3, 6, 4, 7, 8], [9, 2, 5]]\n",
      "[[], [0, 1, 2], [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 16, 18, 19], [0, 1, 2], [3, 4, 5], [20, 21, 22, 23, 24]]\n",
      "[[], [], [], [0, 1, 2], [3, 4, 5, 0, 1, 2], [0, 1, 2, 4, 8], [3, 5, 6, 7, 9], []]\n",
      "[[], [], [], [], [0, 1, 2, 3, 4], [0, 3, 4, 1, 2], [6, 5, 7, 9, 8, 10, 11], [1, 2, 7, 11], []]\n",
      "[[], [], [15, 1], [5, 3, 7, 4, 2], [6, 8, 9, 10], [0, 2, 3, 1], [20, 21, 23, 24, 25, 22]]\n",
      "[[], [0, 1], [2, 3, 4, 5, 6, 7, 8], [], [1, 2, 3], [1, 2, 3]]\n",
      "[[], [], [0, 1, 3, 2], [0, 1], [2, 3, 4], [5, 6, 7, 14, 8, 9, 10, 11], [20, 21, 22], [0, 1, 2]]\n",
      "[[], [], [0, 1, 2, 3], [0, 2, 4, 5], [1, 3, 8, 10], [6, 7, 9, 11], [8, 9, 10, 11], []]\n",
      "[[], [0, 1, 3, 2], [0, 1], [2, 3], [4, 5, 6, 7, 8, 9, 10], [20, 21, 23, 22]]\n",
      "[[], [0, 1, 2, 3, 13, 14], [1, 9, 13, 14], [1, 2, 4, 3]]\n",
      "[[], [0, 1, 2, 5], [1, 5], [0, 2, 3, 4], []]\n",
      "[[], [0, 1, 3, 2], [0, 2, 1], [3, 4], [5]]\n",
      "[[], [], [4, 5, 8, 12], [0, 1, 2, 3], [6, 7, 11, 10, 9]]\n",
      "[[], [0], [1, 2, 3, 6, 7, 8], [5, 4], []]\n",
      "[[], [0, 1, 2], [3, 4, 5], [0]]\n",
      "[[], [0], [1, 2, 3, 4, 5], [5, 1], [11, 12, 13]]\n",
      "[[], [21, 22, 23, 25, 24], [0, 1, 2, 3, 4], [5, 6, 7, 8, 9, 10, 11], [0, 2, 3, 6, 7], [9, 10, 12, 13], [1, 4, 13, 8, 11]]\n",
      "[[], [0, 1, 2, 3], [4, 5, 6, 7, 8], [20, 21, 22, 23], [0, 1, 2, 3, 0, 2, 1, 3], [16, 13, 13, 15, 14, 16, 17, 18, 19]]\n",
      "[[], [], [0, 13], [6, 8, 10, 12], [0, 1, 2, 3], [11, 12, 13]]\n",
      "[[], [], [0, 1, 3, 2], [0, 1, 3, 2], [5, 9], [10, 11]]\n",
      "[[], [0, 1, 2, 4, 3], [36, 39, 38, 37], [0, 2, 1, 3], [4, 6, 7, 8], [9, 5]]\n",
      "[[], [0, 2, 3, 1, 0, 1, 2, 3], [1, 5, 6, 8, 9], [0, 2, 4, 7, 3], [10]]\n",
      "[[], [], [0, 1, 2], [3, 5, 4], [6, 7, 8, 9], [18, 19], []]\n",
      "[[], [], [0, 0, 1, 2, 3, 4], [0, 3, 4, 1, 2], [6, 5, 7, 9, 8, 10, 11], [1, 2, 7, 11]]\n",
      "[[], [0, 1, 3, 2], [6, 5, 10], [7, 4, 8, 9], [1, 0, 2]]\n",
      "[[], [0, 1, 2, 3], [10, 11, 12], [], [0, 1, 3, 6, 4], [2, 5, 9]]\n",
      "[[], [0, 1, 2, 3, 4], [13, 14, 15], [0, 1, 2, 5, 6, 7, 14], [3, 4, 8]]\n",
      "[[], [0, 1, 2, 3, 0, 3], [5, 6, 4], [7]]\n",
      "[[], [], [0, 1, 2, 3, 4], [0, 1, 3], [2, 4], [9, 12, 11], [5, 6, 7, 8], [0, 1]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4], [0, 7, 9, 10], [0], []]\n",
      "[[], [0, 6, 7, 8], [1, 2, 3, 4, 5], [], [0, 3, 4, 6, 1, 2, 5, 7, 8]]\n",
      "[[], [], [0, 1, 2], [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [], [3, 4, 5, 1, 0, 2], []]\n",
      "[[], [0, 1], [2, 3, 4, 5, 6, 7, 8], [1, 2, 3], []]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 10], [0, 1, 2, 3, 4], [5], [6, 7], [8, 9, 10]]\n",
      "[[], [0, 1, 2, 3, 4, 5, 6, 0, 6], [1, 4, 0, 2, 3]]\n",
      "[[], [0, 1, 2, 3], [0, 2, 1, 3], [4, 6, 7, 8], [9, 5], [21, 20, 22, 37]]\n",
      "[[0, 1, 2, 3], [], [0, 1, 2, 3], [0, 1, 4, 5], [6, 7, 8, 2]]\n"
     ]
    }
   ],
   "source": [
    "reg = re.compile(r'F\\d+')\n",
    "mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train if l['narrative_questions'][1][:26] == \"Summarise the top features\"]\n",
    "all_fts = [l['feature_nums'] for l in simple_train if l['narrative_questions'][1][:26] == \"Summarise the top features\"]\n",
    "indexes = [[[narr.index(val) if len(sent)>0 else None for val in sent ] for sent in mention] for narr, mention in zip(all_fts, mentions)]\n",
    "rev_indexes = [[[narr[::-1].index(val) if len(sent)>0 else None for val in sent ] for sent in mention] for narr, mention in zip(all_fts, mentions)]\n",
    "\n",
    "mentions2 = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train if l['narrative_questions'][1][:26] != \"Summarise the top features\"]\n",
    "all_fts2 = [l['feature_nums'] for l in simple_train if l['narrative_questions'][1][:26] != \"Summarise the top features\"]\n",
    "indexes2 = [[[narr.index(val) if len(sent)>0 else None for val in sent ] for sent in mention] for narr, mention in zip(all_fts2, mentions2)]\n",
    "\n",
    "for i, r_i in zip(indexes2, rev_indexes):\n",
    "    print(i)#, r_i)\n",
    "    # print(r_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['model_name', 'predicted_class', 'task_name', 'narration', 'values', 'sign', 'narrative_id', 'unique_id', 'classes_dict', 'narrative_questions', 'feature_nums', 'ft_num2name', 'old2new_ft_nums', 'old2new_classes', 'narr_q_label', 'narr_q_label_group', 'original_narrative_questions'],\n",
       "    num_rows: 375\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-5413440276a9b246.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-db302d1b36cba380.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-cd7dcc3edca842d8.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-ec5d4d8d27e022ff.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5, 33), (6, 29), (4, 16), (7, 13), (8, 5), (3, 3)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_b = simple_train.filter(lambda x: x['narr_q_label_group'] == 'A-B')['narration']\n",
    "a = simple_train.filter(lambda x: x['narr_q_label'] == 'A')['narration']\n",
    "a_val = simple_val.filter(lambda x: x['narr_q_label'] == 'A')['narration']\n",
    "a_test = simple_test.filter(lambda x: x['narr_q_label'] == 'A')['narration']\n",
    "Counter([len(sent_tokenize(n)) for n in a]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['num', 'sent'])\n",
    "    for narr in a:\n",
    "        length = len(sent_tokenize(narr))\n",
    "        for i, sent in enumerate(sent_tokenize(narr)):\n",
    "            if i == 0:\n",
    "                writer.writerow([1, sent])\n",
    "            elif i < 4:\n",
    "                writer.writerow([2, sent])\n",
    "            else:\n",
    "                writer.writerow([3, sent])\n",
    "        writer.writerow(['', ''])\n",
    "    writer.writerow(['val', 'val'])\n",
    "    writer.writerow(['num', 'sent'])\n",
    "    for narr in a_val:\n",
    "        length = len(sent_tokenize(narr))\n",
    "        for i, sent in enumerate(sent_tokenize(narr)):\n",
    "            if i == 0:\n",
    "                writer.writerow([1, sent])\n",
    "            elif i < 4:\n",
    "                writer.writerow([2, sent])\n",
    "            else:\n",
    "                writer.writerow([3, sent])\n",
    "        writer.writerow(['', ''])\n",
    "    writer.writerow(['test', 'test'])\n",
    "    writer.writerow(['num', 'sent'])\n",
    "    for narr in a_test:\n",
    "        length = len(sent_tokenize(narr))\n",
    "        for i, sent in enumerate(sent_tokenize(narr)):\n",
    "            if i == 0:\n",
    "                writer.writerow([1, sent])\n",
    "            elif i < 4:\n",
    "                writer.writerow([2, sent])\n",
    "            else:\n",
    "                writer.writerow([3, sent])\n",
    "        writer.writerow(['', ''])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A's really don't seem to answer the questions individually. They are more like a summary of the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-db302d1b36cba380.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-db302d1b36cba380.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['F2', 'F4', 'F6', 'F1', 'F3', 'F5'], ['F2'], ['F4', 'F6', 'F1'], ['F2']]  Q  [[], [], [], []]\n",
      "[[], [], ['F16', 'F19'], ['F1', 'F12', 'F17', 'F6'], ['F1', 'F6', 'F4', 'F9', 'F10'], ['F16', 'F19', 'F12', 'F17', 'F8', 'F7']]  Q  [[], [], ['F8', 'F7', 'F4'], []]\n",
      "[[], ['F24', 'F14', 'F16'], ['F3', 'F9', 'F7', 'F4', 'F12', 'F23'], ['F26', 'F11', 'F22', 'F20', 'F6', 'F19'], ['F24', 'F14', 'F16', 'F21', 'F1', 'F13']]  Q  [[], [], ['F26', 'F25', 'F5'], []]\n",
      "[[], [], ['F19', 'F12', 'F17'], ['F1', 'F9', 'F16', 'F10'], ['F15', 'F4']]  Q  [[], [], ['F18', 'F5', 'F11'], []]\n",
      "[[], [], ['F10', 'F2', 'F5', 'F4', 'F7'], [], ['F3', 'F9', 'F4'], []]  Q  [[], [], ['F4', 'F7'], []]\n",
      "[[], [], [], [], ['F6', 'F9', 'F4', 'F2', 'F8'], ['F7', 'F3', 'F1', 'F5']]  Q  [[], [], ['F2', 'F5', 'F8'], []]\n",
      "[[], [], ['F5', 'F7', 'F3', 'F2', 'F6', 'F4', 'F1'], ['F5', 'F1']]  Q  [[], [], ['F1'], []]\n",
      "[[], ['F8', 'F2', 'F4', 'F9'], [], [], ['F5', 'F7', 'F1'], []]  Q  [[], [], ['F6', 'F5', 'F1'], []]\n",
      "[[], [], ['F1', 'F6', 'F4', 'F12', 'F5'], ['F3', 'F2', 'F10', 'F7', 'F9', 'F11', 'F8'], ['F1', 'F6', 'F3', 'F2'], ['F9', 'F5', 'F11']]  Q  [[], [], ['F8', 'F9', 'F5'], []]\n",
      "[[], ['F1', 'F6', 'F8', 'F2', 'F5', 'F7', 'F4'], ['F1', 'F8', 'F2', 'F7', 'F5', 'F9'], ['F6', 'F3', 'F12', 'F11', 'F10', 'F4'], []]  Q  [[], [], ['F9', 'F10', 'F5'], []]\n",
      "[[], [], ['F27', 'F4', 'F17', 'F22', 'F7'], ['F14', 'F11', 'F15', 'F23'], ['F18', 'F10', 'F25', 'F9', 'F8'], ['F19', 'F3', 'F1', 'F6', 'F5', 'F20', 'F29', 'F28', 'F2', 'F13'], ['F27', 'F7', 'F24'], ['F4', 'F15', 'F17']]  Q  [[], [], ['F11', 'F15', 'F23', 'F16'], []]\n",
      "[[], ['F7', 'F2', 'F9', 'F8'], ['F7', 'F2'], ['F1'], ['F9', 'F8', 'F3', 'F6', 'F4', 'F5'], []]  Q  [[], [], ['F6', 'F4', 'F5'], []]\n",
      "[[], ['F12', 'F17', 'F8', 'F16', 'F9', 'F24', 'F14', 'F34', 'F23', 'F29', 'F1', 'F38', 'F37', 'F18', 'F6', 'F22', 'F25', 'F7', 'F10', 'F4'], ['F32', 'F13', 'F28'], ['F12', 'F17'], ['F8', 'F9', 'F16'], ['F12', 'F24', 'F17']]  Q  [[], [], ['F14', 'F34', 'F23', 'F29'], []]\n",
      "[[], [], [], ['F14'], ['F7', 'F17', 'F18', 'F15', 'F24', 'F32', 'F30', 'F10'], ['F7', 'F18', 'F15', 'F32', 'F30'], ['F17', 'F24', 'F10', 'F14']]  Q  [[], [], ['F10', 'F6', 'F1'], []]\n",
      "[[], [], ['F4', 'F3', 'F9', 'F8'], ['F7', 'F1', 'F6', 'F10', 'F2', 'F12', 'F11', 'F5'], []]  Q  [[], [], ['F6', 'F10', 'F2', 'F12'], []]\n",
      "[[], ['F4', 'F12', 'F16'], ['F1', 'F8', 'F17', 'F7', 'F14', 'F3', 'F11', 'F15', 'F13'], ['F8', 'F7', 'F5', 'F13', 'F11'], ['F1', 'F17', 'F10', 'F14']]  Q  [[], [], ['F14', 'F10', 'F9'], []]\n",
      "[[], [], ['F3', 'F9', 'F8', 'F5', 'F12'], ['F3', 'F8', 'F9', 'F12', 'F5'], ['F3', 'F9', 'F10', 'F17', 'F8', 'F12', 'F5', 'F19'], [], [], []]  Q  [[], [], ['F17', 'F19', 'F11', 'F14'], []]\n",
      "[[], ['F2', 'F1', 'F9', 'F7', 'F4', 'F10'], ['F2', 'F9', 'F6', 'F7', 'F4'], ['F1', 'F3', 'F8', 'F5', 'F10'], ['F2', 'F9']]  Q  [[], [], ['F6', 'F7', 'F4'], []]\n",
      "[[], ['F12', 'F19', 'F20'], [], ['F18', 'F3', 'F1', 'F8', 'F14', 'F5'], ['F9', 'F15', 'F24', 'F11', 'F21', 'F4'], []]  Q  [[], [], ['F9', 'F7', 'F23'], []]\n",
      "[[], ['F4', 'F8', 'F3', 'F6', 'F7', 'F11', 'F2', 'F1'], ['F7', 'F5', 'F9'], ['F7', 'F11', 'F1', 'F2']]  Q  [[], [], ['F10', 'F9', 'F5'], []]\n",
      "[[], ['F6', 'F3', 'F10', 'F8'], ['F11', 'F2', 'F12', 'F5'], ['F10', 'F9', 'F11', 'F2', 'F12', 'F5']]  Q  [[], [], ['F1', 'F7', 'F11', 'F2'], []]\n",
      "[[], [], [], ['F9', 'F7', 'F3'], ['F10', 'F5', 'F11', 'F4', 'F2', 'F6', 'F8', 'F1', 'F12'], ['F7', 'F3', 'F11', 'F4', 'F2', 'F9', 'F10', 'F5']]  Q  [[], [], ['F4', 'F2', 'F6', 'F8'], []]\n",
      "[[], [], ['F5', 'F4', 'F10', 'F6'], ['F1', 'F8', 'F2'], [], ['F5', 'F6', 'F7', 'F3', 'F4', 'F9', 'F1', 'F10']]  Q  [[], [], ['F8', 'F2'], []]\n",
      "[[], ['F1'], ['F5', 'F6', 'F2', 'F8', 'F9', 'F4', 'F3', 'F7'], [], ['F1', 'F6', 'F2', 'F4', 'F9'], ['F5', 'F8', 'F3', 'F7']]  Q  [[], [], ['F4', 'F3', 'F7'], []]\n",
      "[[], ['F23', 'F4', 'F31', 'F9', 'F35', 'F14', 'F5', 'F25', 'F3', 'F8', 'F18', 'F36', 'F34', 'F1', 'F22', 'F10', 'F33', 'F29', 'F16', 'F11'], ['F23', 'F4'], ['F31', 'F35', 'F9'], ['F23', 'F14', 'F4']]  Q  [[], [], ['F5', 'F25', 'F3', 'F8'], []]\n",
      "[[], ['F25', 'F5', 'F3'], ['F1', 'F13', 'F12', 'F24', 'F14', 'F19'], ['F26', 'F18', 'F2', 'F16', 'F23', 'F10'], ['F25', 'F5', 'F3', 'F7', 'F4', 'F20', 'F15']]  Q  [[], [], ['F26', 'F15', 'F9'], []]\n",
      "[[], [], ['F11', 'F6', 'F7', 'F1', 'F5'], ['F2', 'F10', 'F3', 'F4', 'F8', 'F9'], ['F11', 'F6', 'F2', 'F10'], ['F12']]  Q  [[], [], ['F1', 'F9', 'F5'], []]\n",
      "[[], [], ['F9'], ['F20', 'F2', 'F22', 'F12'], ['F1'], ['F21', 'F17'], ['F33', 'F23', 'F32', 'F6']]  Q  [[], [], ['F21', 'F17', 'F28'], []]\n",
      "[[], ['F4', 'F1', 'F7'], ['F9', 'F6', 'F11', 'F2'], ['F12', 'F5', 'F3'], []]  Q  [[], [], ['F11', 'F12', 'F3'], []]\n",
      "[[], ['F8', 'F12', 'F4', 'F6', 'F7'], ['F2', 'F5', 'F10', 'F11'], ['F9', 'F3', 'F1'], ['F6', 'F7', 'F3', 'F1', 'F5', 'F11'], ['F8', 'F12', 'F4']]  Q  [[], [], ['F3', 'F1', 'F2', 'F5'], []]\n",
      "[[], [], [], ['F3', 'F6', 'F2'], ['F9', 'F8', 'F1'], ['F6', 'F2', 'F7', 'F5'], ['F3', 'F4', 'F8', 'F9', 'F1'], ['F6', 'F2', 'F7', 'F5', 'F3']]  Q  [[], [], ['F8', 'F9', 'F1'], []]\n",
      "[[], ['F63', 'F90', 'F49', 'F64', 'F93'], ['F67'], ['F45', 'F20', 'F30', 'F50'], ['F20', 'F48', 'F23'], ['F38', 'F65', 'F72', 'F87'], ['F63', 'F90', 'F49', 'F64', 'F93', 'F67', 'F30', 'F50', 'F3']]  Q  [[], [], ['F20', 'F48', 'F23'], []]\n",
      "[[], ['F21', 'F4', 'F9', 'F30', 'F25', 'F16', 'F7', 'F27', 'F22', 'F19'], ['F21', 'F4', 'F25', 'F30'], ['F9', 'F6', 'F1'], []]  Q  [[], [], ['F5', 'F20', 'F10', 'F8'], []]\n",
      "[[], ['F4', 'F1', 'F7', 'F15', 'F6', 'F14', 'F25', 'F21', 'F11', 'F13', 'F29', 'F10', 'F26'], ['F20', 'F22', 'F5', 'F8', 'F17', 'F12', 'F24'], ['F9', 'F2', 'F16', 'F23'], ['F4', 'F1', 'F7', 'F6', 'F21', 'F29', 'F12'], []]  Q  [[], [], ['F21', 'F11', 'F13'], []]\n",
      "[[], ['F7', 'F2', 'F8', 'F6'], ['F3', 'F4', 'F9'], ['F10', 'F1'], ['F7', 'F2', 'F8', 'F5', 'F6']]  Q  [[], [], ['F5', 'F3', 'F4', 'F9'], []]\n",
      "[[], ['F9', 'F13', 'F5'], ['F1', 'F12', 'F6'], ['F7', 'F4', 'F10', 'F15'], [], ['F12', 'F3', 'F16']]  Q  [[], [], ['F3', 'F16', 'F14', 'F17'], []]\n",
      "[[], ['F6', 'F11', 'F12'], ['F1', 'F4', 'F2', 'F9'], ['F10', 'F8', 'F3'], []]  Q  [[], [], ['F2', 'F8', 'F3'], []]\n",
      "[[], ['F30', 'F5', 'F33', 'F10', 'F11', 'F9', 'F6'], ['F30', 'F33', 'F11', 'F9', 'F6'], ['F25', 'F12', 'F15', 'F17', 'F3']]  Q  [[], [], ['F25', 'F12', 'F15'], []]\n",
      "[[], [], ['F4'], ['F6', 'F9'], [], ['F4', 'F1', 'F8'], ['F3', 'F5', 'F4']]  Q  [[], [], ['F9'], []]\n",
      "[[], [], ['F10', 'F2', 'F14', 'F9', 'F3', 'F6'], ['F15', 'F8', 'F11'], ['F10', 'F8', 'F11', 'F4', 'F5', 'F6'], ['F2', 'F14', 'F12', 'F15'], []]  Q  [[], [], ['F12', 'F4', 'F5'], []]\n",
      "[[], ['F13', 'F2', 'F19', 'F20'], ['F1', 'F12'], ['F1', 'F12', 'F10', 'F14', 'F3', 'F15'], [], ['F13', 'F2', 'F19', 'F10', 'F14', 'F3', 'F17'], ['F20', 'F15', 'F11', 'F9'], []]  Q  [[], [], ['F3', 'F15', 'F17', 'F11'], []]\n",
      "[[], [], [], ['F1', 'F2', 'F7', 'F8', 'F5'], ['F3', 'F6', 'F9', 'F4']]  Q  [[], [], ['F8', 'F4', 'F5'], []]\n",
      "[['F9', 'F8', 'F11'], ['F9', 'F8', 'F11', 'F1', 'F5', 'F7', 'F11', 'F6', 'F3', 'F5'], ['F8', 'F9', 'F10', 'F4', 'F2']]  Q  [[], [], ['F6', 'F3', 'F1', 'F5'], []]\n",
      "[[], [], [], ['F2', 'F6', 'F3', 'F1'], ['F4', 'F7']]  Q  [[], [], ['F7'], []]\n",
      "[[], ['F3', 'F2', 'F5', 'F4'], ['F3', 'F2'], ['F6'], ['F5', 'F4', 'F8', 'F1', 'F7', 'F9'], []]  Q  [[], [], ['F1', 'F7', 'F9'], []]\n",
      "[[], ['F1', 'F2', 'F4', 'F6'], ['F8', 'F5', 'F7'], ['F1', 'F2', 'F3', 'F4', 'F6']]  Q  [[], [], ['F4', 'F6'], []]\n",
      "[['F23', 'F13', 'F24', 'F30'], [], ['F23', 'F30', 'F43', 'F18'], ['F13', 'F24', 'F27', 'F21'], ['F4', 'F26', 'F7', 'F25']]  Q  [[], [], ['F27', 'F5', 'F21'], []]\n",
      "[[], ['F12', 'F7', 'F6', 'F3', 'F11', 'F10', 'F9'], ['F4', 'F5', 'F2'], ['F6', 'F5', 'F3', 'F11'], ['F12', 'F7', 'F4']]  Q  [[], [], ['F1', 'F8', 'F3'], []]\n",
      "[[], ['F14', 'F7', 'F1'], ['F13', 'F12', 'F17'], ['F16', 'F9', 'F2', 'F8'], [], ['F12', 'F11', 'F6']]  Q  [[], [], ['F11', 'F6', 'F4', 'F5'], []]\n",
      "[[], ['F10', 'F2', 'F1', 'F7', 'F3', 'F4'], ['F5', 'F8', 'F9', 'F6'], ['F1', 'F3', 'F4']]  Q  [[], [], ['F5', 'F8', 'F9'], []]\n",
      "[[], [], ['F16', 'F25', 'F19', 'F22', 'F26'], ['F11', 'F18', 'F12', 'F10'], ['F22', 'F13', 'F10', 'F12', 'F5', 'F6', 'F24'], ['F26', 'F11', 'F14', 'F18', 'F4', 'F15']]  Q  [[], [], ['F15', 'F5', 'F6'], []]\n",
      "[[], ['F25', 'F3', 'F12', 'F8', 'F20', 'F21', 'F16', 'F23', 'F4', 'F9', 'F6', 'F26'], ['F19', 'F1', 'F24', 'F17'], ['F25', 'F20', 'F1', 'F17', 'F15', 'F7', 'F22', 'F14'], ['F3', 'F12', 'F8', 'F21'], ['F25']]  Q  [[], [], ['F19', 'F1', 'F18'], []]\n",
      "[[], ['F11', 'F3', 'F9', 'F12'], ['F5', 'F6', 'F4', 'F2'], ['F5', 'F8', 'F10', 'F7']]  Q  [[], [], ['F2', 'F1', 'F8'], []]\n",
      "[[], [], ['F8', 'F12', 'F9', 'F5'], ['F6'], ['F8', 'F9', 'F12'], ['F7', 'F4', 'F11'], ['F5', 'F10', 'F2', 'F1', 'F3', 'F6']]  Q  [[], [], ['F1', 'F3', 'F4'], []]\n",
      "[[], ['F1', 'F12', 'F15', 'F3', 'F14'], ['F9', 'F6', 'F7'], ['F14', 'F3'], ['F2', 'F11', 'F16', 'F7'], ['F1', 'F12', 'F15'], []]  Q  [[], [], ['F13', 'F8', 'F2', 'F11'], []]\n",
      "[[], [], ['F3', 'F1', 'F9'], ['F4', 'F2'], ['F3', 'F1', 'F10', 'F6', 'F2'], ['F9', 'F12', 'F8', 'F11']]  Q  [[], [], ['F5', 'F7', 'F10'], []]\n",
      "[[], [], ['F2', 'F4', 'F1', 'F8', 'F10'], ['F2', 'F4', 'F8'], ['F10', 'F1', 'F11', 'F7', 'F6']]  Q  [[], [], ['F3', 'F7', 'F5'], []]\n",
      "[[], ['F6', 'F5', 'F10', 'F13', 'F28', 'F14', 'F19', 'F30', 'F9', 'F12'], ['F6', 'F5', 'F28', 'F13', 'F10', 'F18', 'F1'], []]  Q  [[], [], ['F25', 'F22', 'F23', 'F7'], []]\n",
      "[[], ['F6', 'F9', 'F4', 'F10', 'F5', 'F8', 'F3', 'F1'], ['F5', 'F2', 'F11']]  Q  [[], [], ['F7', 'F2', 'F11'], []]\n",
      "[[], [], ['F9', 'F4', 'F5', 'F3', 'F2'], ['F9', 'F8', 'F5'], ['F4', 'F6', 'F9'], []]  Q  [[], [], ['F2'], []]\n",
      "[[], ['F12', 'F15', 'F1'], ['F8', 'F10', 'F7'], ['F12', 'F15', 'F1'], ['F11', 'F4', 'F13', 'F5'], ['F2', 'F6', 'F3', 'F14', 'F7'], []]  Q  [[], [], ['F5', 'F9', 'F14'], []]\n",
      "[[], ['F2', 'F3', 'F4', 'F8', 'F1', 'F6', 'F7', 'F5'], []]  Q  [[], [], ['F2'], []]\n",
      "[[], [], [], ['F16', 'F8', 'F2', 'F12', 'F13'], ['F1', 'F6', 'F4', 'F15', 'F3'], ['F10', 'F16', 'F9', 'F7', 'F1', 'F15', 'F3'], ['F8', 'F2', 'F12', 'F13']]  Q  [[], [], ['F9', 'F11', 'F14', 'F5'], []]\n",
      "[[], ['F13', 'F4', 'F2', 'F12', 'F14', 'F10', 'F5', 'F16', 'F7'], ['F13', 'F14', 'F12', 'F3', 'F1', 'F5', 'F16', 'F7'], ['F4', 'F2', 'F8', 'F9', 'F6']]  Q  [[], [], ['F9', 'F6', 'F3'], []]\n",
      "[[], ['F9', 'F7', 'F6'], [], ['F9', 'F3', 'F4'], ['F8', 'F6', 'F7', 'F5', 'F9']]  Q  [[], [], ['F7'], []]\n",
      "[[], [], [], ['F23'], ['F22', 'F7', 'F30', 'F14', 'F13', 'F20', 'F8', 'F6'], ['F22', 'F30', 'F14', 'F20', 'F18', 'F12', 'F8'], ['F7', 'F13', 'F10', 'F29', 'F6', 'F23']]  Q  [[], [], ['F6', 'F18', 'F29'], []]\n",
      "[[], [], ['F7', 'F8', 'F4', 'F1'], ['F6', 'F2', 'F3'], ['F7', 'F8', 'F5', 'F4', 'F1']]  Q  [[], [], ['F4', 'F1'], []]\n",
      "[[], ['F3', 'F5', 'F7', 'F1'], ['F6', 'F2'], [], ['F7', 'F1', 'F9', 'F8']]  Q  [[], [], ['F8', 'F10', 'F6', 'F2'], []]\n",
      "[[], ['F3', 'F6', 'F5', 'F4', 'F2', 'F1'], ['F3', 'F6', 'F5', 'F2', 'F4'], ['F3', 'F6', 'F5', 'F4', 'F2', 'F1']]  Q  [[], [], [], []]\n",
      "[[], ['F33', 'F5', 'F24', 'F10', 'F22', 'F21', 'F11', 'F23', 'F32', 'F29', 'F9', 'F17', 'F28', 'F20', 'F38', 'F19', 'F1', 'F4', 'F6', 'F31'], ['F2', 'F8', 'F35'], ['F33', 'F5'], ['F24', 'F22', 'F10'], ['F33', 'F21', 'F5']]  Q  [[], [], ['F11', 'F23', 'F32', 'F29'], []]\n",
      "[[], ['F61', 'F15', 'F1', 'F86', 'F23', 'F89', 'F61', 'F15', 'F1', 'F86', 'F23', 'F89'], ['F83', 'F4', 'F65', 'F13', 'F90', 'F77'], ['F4', 'F37', 'F2', 'F46', 'F6', 'F28'], ['F35', 'F3', 'F8', 'F85', 'F51']]  Q  [[], [], ['F4', 'F37', 'F28'], []]\n",
      "[[], [], ['F10', 'F11', 'F5', 'F2'], ['F12', 'F3', 'F6', 'F13'], ['F4', 'F8', 'F3'], ['F10', 'F11', 'F5']]  Q  [[], [], ['F1', 'F9', 'F4', 'F12'], []]\n",
      "[[], ['F20', 'F5', 'F1', 'F14', 'F4', 'F6', 'F13'], ['F16', 'F9', 'F30', 'F7', 'F22', 'F24', 'F11', 'F2', 'F27', 'F28'], ['F20', 'F5', 'F1'], []]  Q  [[], [], ['F6', 'F23', 'F3'], []]\n",
      "[[], ['F2', 'F8', 'F4', 'F3', 'F1', 'F10', 'F7'], ['F2', 'F8', 'F5', 'F10', 'F7'], ['F4', 'F9', 'F6']]  Q  [[], [], ['F1', 'F10', 'F7'], []]\n",
      "[[], ['F6', 'F8', 'F3', 'F18'], ['F6', 'F8'], ['F18'], ['F3'], ['F6', 'F8', 'F3'], ['F14', 'F16', 'F1'], ['F14', 'F16', 'F1']]  Q  [[], [], ['F14', 'F16', 'F1'], []]\n",
      "[[], [], ['F10', 'F8', 'F1', 'F4'], ['F10', 'F8', 'F1'], [], ['F4', 'F6', 'F3', 'F7', 'F11']]  Q  [[], [], ['F2', 'F7', 'F9'], []]\n",
      "[[], ['F11', 'F3', 'F4', 'F8', 'F2', 'F7', 'F9'], ['F11', 'F3', 'F1', 'F7', 'F9'], ['F4', 'F5', 'F6']]  Q  [[], [], ['F2', 'F7', 'F9'], []]\n",
      "[[], ['F1', 'F2', 'F4', 'F5'], ['F8', 'F3', 'F10', 'F9', 'F6', 'F7', 'F2', 'F4', 'F5', 'F1'], ['F1', 'F3', 'F8', 'F10', 'F9', 'F7', 'F5']]  Q  [[], [], ['F2', 'F4', 'F5'], []]\n",
      "[[], ['F9', 'F4', 'F10', 'F7', 'F5'], [], ['F3', 'F6', 'F7'], []]  Q  [[], [], ['F7', 'F5'], []]\n",
      "[[], [], [], ['F3', 'F4', 'F1', 'F7'], ['F2', 'F5']]  Q  [[], [], ['F2'], []]\n",
      "[[], ['F15', 'F14'], ['F9', 'F2', 'F13', 'F19'], ['F9', 'F19', 'F5', 'F10', 'F18'], ['F15', 'F14', 'F2', 'F13', 'F11', 'F17']]  Q  [[], [], ['F11', 'F17', 'F5'], []]\n",
      "[[], ['F2', 'F7', 'F1', 'F3'], ['F10', 'F11', 'F9'], [], ['F7', 'F6', 'F5', 'F10', 'F11', 'F8'], ['F2', 'F3', 'F4', 'F12', 'F1']]  Q  [[], [], ['F4', 'F9', 'F5'], []]\n",
      "[[], ['F18'], ['F18'], ['F18'], ['F17', 'F28', 'F24'], ['F7', 'F14', 'F9', 'F12', 'F30', 'F29', 'F4', 'F13', 'F11', 'F8']]  Q  [[], [], ['F1', 'F3', 'F2', 'F16'], []]\n",
      "[['F2', 'F7', 'F44', 'F8'], ['F2', 'F33', 'F39', 'F8'], [], ['F44', 'F7', 'F11', 'F36'], ['F17', 'F21', 'F41', 'F18']]  Q  [[], [], ['F11', 'F20', 'F36'], []]\n",
      "[[], [], ['F14', 'F19', 'F29', 'F6', 'F38', 'F20'], ['F12', 'F36', 'F16', 'F27', 'F26'], ['F2', 'F33', 'F13', 'F5', 'F41'], ['F14', 'F19', 'F6', 'F29']]  Q  [[], [], ['F4', 'F12', 'F36', 'F16'], []]\n",
      "[[], [], ['F3', 'F5', 'F8', 'F2', 'F6', 'F7', 'F1', 'F4'], []]  Q  [[], [], ['F3'], []]\n",
      "[[], ['F12', 'F13', 'F3'], ['F6', 'F17', 'F10', 'F9'], ['F19', 'F11']]  Q  [[], [], ['F14', 'F2', 'F1'], []]\n",
      "[[], [], ['F19', 'F17', 'F4', 'F12', 'F13'], ['F19', 'F4', 'F17', 'F13', 'F12'], ['F19', 'F17', 'F1', 'F14', 'F4', 'F13', 'F12', 'F15'], [], []]  Q  [[], [], ['F14', 'F15', 'F5', 'F16'], []]\n",
      "[[], [], ['F1', 'F5', 'F2', 'F3'], ['F7', 'F9'], [], ['F1', 'F3', 'F8', 'F10'], ['F5', 'F4', 'F6', 'F2']]  Q  [[], [], ['F7', 'F9'], []]\n",
      "[[], ['F10', 'F11', 'F13'], ['F6', 'F5', 'F15'], ['F17', 'F4', 'F12', 'F14'], [], ['F5', 'F2', 'F7']]  Q  [[], [], ['F2', 'F7', 'F1', 'F16'], []]\n",
      "[[], [], ['F1', 'F4', 'F3', 'F5', 'F6', 'F6'], ['F2'], []]  Q  [[], [], [], []]\n",
      "[[], ['F5', 'F6', 'F9'], ['F12', 'F1'], ['F2', 'F11', 'F10', 'F8'], ['F11', 'F3', 'F12', 'F5', 'F6', 'F9']]  Q  [[], [], ['F8', 'F7', 'F4', 'F3'], []]\n",
      "[[], [], ['F17', 'F26', 'F25', 'F2', 'F10', 'F32', 'F21'], ['F25', 'F10', 'F32', 'F13', 'F21'], ['F3', 'F9', 'F7', 'F19', 'F23'], ['F1', 'F11', 'F16', 'F29', 'F8', 'F33']]  Q  [[], [], ['F3', 'F9', 'F23'], []]\n",
      "[[], ['F29', 'F9', 'F88', 'F17', 'F77'], ['F53'], ['F30', 'F7', 'F85', 'F20', 'F81', 'F26', 'F3', 'F44', 'F31', 'F27', 'F69'], ['F49', 'F21', 'F36', 'F18', 'F63', 'F87']]  Q  [[], [], ['F3', 'F7', 'F85'], []]\n",
      "[[], ['F19', 'F11', 'F6', 'F16', 'F26'], ['F4', 'F24', 'F27', 'F10', 'F20'], ['F6', 'F26', 'F11', 'F14', 'F15', 'F3'], ['F19', 'F2', 'F22', 'F8', 'F1', 'F9', 'F13', 'F16']]  Q  [[], [], ['F22', 'F8', 'F1', 'F9'], []]\n",
      "[[], ['F22', 'F24', 'F2', 'F30', 'F1', 'F6', 'F17', 'F19', 'F7', 'F3', 'F8', 'F20', 'F4'], ['F9', 'F26', 'F13', 'F28', 'F14', 'F21', 'F10'], [], ['F29', 'F27', 'F18', 'F11'], ['F22', 'F24', 'F2', 'F1', 'F19', 'F8', 'F10'], []]  Q  [[], [], ['F19', 'F7', 'F3'], []]\n",
      "[[], ['F2', 'F6', 'F4', 'F5'], ['F11', 'F9', 'F1', 'F3'], ['F11', 'F7', 'F10', 'F11']]  Q  [[], [], ['F8', 'F7', 'F10'], []]\n",
      "[[], ['F3', 'F5', 'F2', 'F4', 'F7', 'F1', 'F10'], [], ['F5', 'F3', 'F7', 'F10'], ['F2', 'F4', 'F9', 'F11', 'F6']]  Q  [[], [], ['F6', 'F8', 'F7'], []]\n",
      "[[], ['F1'], ['F31', 'F14', 'F10', 'F6'], ['F16', 'F5', 'F4'], ['F19', 'F30', 'F28', 'F29']]  Q  [[], [], ['F5', 'F4', 'F20'], []]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A. For 99 cases the format is:\n",
    "* 'In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).'\n",
    "* \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\"\n",
    "* 'Describe the degree of impact of the following features: [0-4 fts (after first 7-9)]?' (3 times there are 0)\n",
    "'''\n",
    "\n",
    "\n",
    "    \n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == 'A')]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == 'A')]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B seems similar to A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-2e87d7282ff9a06c.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-2e87d7282ff9a06c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], ['F5', 'F1', 'F8', 'F12', 'F2', 'F4'], ['F5', 'F1', 'F8', 'F7'], ['F16', 'F3', 'F15', 'F14'], ['F11', 'F6', 'F13', 'F2', 'F12', 'F4'], []]  Q  [[], [], ['F6', 'F16', 'F15'], []]\n",
      "[[], ['F5', 'F10', 'F6'], ['F3', 'F1', 'F12', 'F7', 'F4'], ['F9', 'F2', 'F8'], ['F6', 'F10', 'F5'], ['F11']]  Q  [[], [], ['F10', 'F1', 'F9', 'F3'], []]\n",
      "[[], [], ['F1', 'F7', 'F3'], ['F5', 'F2', 'F10', 'F4', 'F8', 'F6', 'F9'], ['F7', 'F1', 'F8', 'F5', 'F2'], ['F3', 'F6', 'F10', 'F9', 'F4']]  Q  [[], [], ['F9', 'F5', 'F10'], []]\n",
      "[[], ['F38', 'F51', 'F13', 'F46', 'F28', 'F71', 'F44'], ['F70', 'F61', 'F85', 'F20', 'F59', 'F93', 'F14', 'F66', 'F24', 'F89', 'F30', 'F65', 'F54'], ['F47', 'F10', 'F7', 'F43'], [], ['F44', 'F61', 'F30', 'F65', 'F54'], ['F38', 'F51', 'F13', 'F46']]  Q  [[], [], ['F28', 'F44', 'F71'], []]\n",
      "[[], ['F12', 'F1', 'F11', 'F10', 'F9', 'F6', 'F3'], ['F12', 'F1', 'F10', 'F11', 'F2', 'F4', 'F6'], ['F8', 'F7', 'F3', 'F9', 'F5'], []]  Q  [[], [], ['F11', 'F8', 'F7'], []]\n",
      "[[], [], ['F4', 'F11', 'F1', 'F6', 'F2', 'F3', 'F7'], ['F5', 'F8', 'F9', 'F10'], ['F4', 'F1', 'F6', 'F10'], ['F11', 'F5', 'F9', 'F8'], []]  Q  [[], [], ['F1', 'F6', 'F5', 'F8'], []]\n",
      "[[], [], ['F30', 'F12', 'F11', 'F32'], ['F17', 'F24', 'F28'], [], ['F46', 'F2', 'F40', 'F8'], ['F30', 'F12', 'F11', 'F32'], ['F17', 'F24', 'F33', 'F29'], []]  Q  [[], [], ['F11', 'F32', 'F17', 'F24'], []]\n",
      "[[], ['F7', 'F5', 'F4', 'F2'], ['F6'], ['F5', 'F1', 'F4', 'F2'], ['F7', 'F9', 'F8']]  Q  [[], [], ['F4', 'F2', 'F1', 'F8'], []]\n",
      "[[], ['F2', 'F19', 'F24', 'F8'], ['F3', 'F18', 'F14', 'F16', 'F13', 'F22'], ['F25', 'F17', 'F7', 'F9'], ['F17', 'F25', 'F24', 'F19', 'F7', 'F21', 'F2', 'F4', 'F8', 'F5']]  Q  [[], [], ['F2', 'F8', 'F7', 'F17'], []]\n",
      "[[], [], ['F18', 'F11', 'F12'], ['F20', 'F15', 'F6', 'F14', 'F18', 'F11', 'F12'], ['F7', 'F19', 'F13', 'F9'], ['F16', 'F10', 'F3', 'F4'], []]  Q  [[], [], ['F16', 'F10', 'F3'], []]\n",
      "[[], ['F9', 'F2', 'F7', 'F6', 'F1'], ['F5', 'F3', 'F4', 'F8', 'F9', 'F2', 'F7'], [], ['F9', 'F7', 'F4', 'F8'], ['F2', 'F5', 'F3', 'F6']]  Q  [[], [], ['F4', 'F8', 'F6'], []]\n",
      "[[], [], ['F1', 'F15', 'F9', 'F2', 'F12', 'F11', 'F6'], ['F1', 'F15', 'F9', 'F2'], ['F4', 'F14', 'F18', 'F5'], ['F17', 'F8', 'F20', 'F19', 'F16'], ['F1'], ['F10', 'F11', 'F6']]  Q  [[], [], ['F8', 'F4', 'F19'], []]\n",
      "[[], ['F6', 'F15'], ['F5', 'F10', 'F4', 'F13'], ['F5', 'F10', 'F9', 'F8'], ['F2', 'F16', 'F1', 'F7']]  Q  [[], [], ['F13', 'F9', 'F8'], []]\n",
      "[[], [], ['F12', 'F6', 'F2'], ['F3', 'F11', 'F5'], ['F12', 'F6', 'F2', 'F3', 'F11', 'F8', 'F5', 'F9', 'F10', 'F1', 'F7'], ['F9', 'F7', 'F3'], ['F12', 'F6', 'F2', 'F10', 'F4', 'F1']]  Q  [[], [], ['F1', 'F7', 'F4'], []]\n",
      "[[], [], [], ['F6', 'F16', 'F7', 'F1', 'F8', 'F11', 'F5'], ['F14', 'F19', 'F2', 'F18', 'F9']]  Q  [[], [], ['F16', 'F2', 'F18'], []]\n",
      "[[], [], ['F5', 'F3', 'F2', 'F6'], ['F4', 'F1'], ['F5', 'F3', 'F2', 'F6']]  Q  [[], [], ['F1', 'F4', 'F2', 'F6'], []]\n",
      "[[], ['F8', 'F7', 'F1', 'F10', 'F4', 'F6', 'F3'], ['F9', 'F5', 'F2'], ['F7', 'F8', 'F9', 'F10', 'F4'], ['F1', 'F5', 'F6', 'F2', 'F3']]  Q  [[], [], ['F2', 'F10', 'F6'], []]\n",
      "[[], [], ['F11', 'F16', 'F22', 'F6', 'F32', 'F27', 'F25'], ['F24', 'F18', 'F31', 'F3', 'F19'], ['F32', 'F27', 'F25', 'F11', 'F16', 'F22', 'F29', 'F6']]  Q  [[], [], ['F27', 'F25', 'F32'], []]\n",
      "[[], ['F10', 'F7', 'F5', 'F9', 'F2', 'F1', 'F8'], ['F3', 'F11', 'F4', 'F6'], ['F9', 'F1'], ['F9', 'F1', 'F10', 'F7', 'F5']]  Q  [[], [], ['F1', 'F8', 'F3'], []]\n",
      "[[], [], [], ['F9', 'F12', 'F7', 'F6', 'F8', 'F1', 'F10', 'F2', 'F5', 'F3', 'F11', 'F4'], ['F12', 'F8', 'F2', 'F3', 'F4'], ['F9', 'F7', 'F6', 'F10', 'F1']]  Q  [[], [], ['F7', 'F6', 'F8', 'F1'], []]\n",
      "[[], [], ['F8', 'F2', 'F20', 'F7'], ['F13'], ['F14', 'F12', 'F1', 'F4'], ['F19', 'F5', 'F17'], ['F8', 'F2', 'F20', 'F7'], ['F21', 'F3', 'F10', 'F6', 'F11', 'F18']]  Q  [[], [], ['F2', 'F7', 'F20', 'F14'], []]\n",
      "[[], ['F20', 'F7', 'F17', 'F5'], ['F20', 'F7'], ['F5', 'F7', 'F20'], ['F8', 'F24', 'F25', 'F16'], ['F21', 'F2', 'F11', 'F26'], ['F6', 'F4', 'F14', 'F22']]  Q  [[], [], ['F24', 'F21', 'F25'], []]\n",
      "[[], ['F9', 'F13', 'F14', 'F10', 'F3', 'F6'], ['F5', 'F13', 'F2', 'F4', 'F10'], ['F9', 'F14', 'F8', 'F1']]  Q  [[], [], ['F5', 'F8', 'F2'], []]\n",
      "[[], ['F3', 'F11', 'F12', 'F5', 'F2', 'F10', 'F8', 'F9', 'F6', 'F7', 'F4', 'F1'], ['F3', 'F11', 'F4', 'F1'], ['F6', 'F7', 'F4'], ['F6', 'F7', 'F4', 'F3', 'F11', 'F12', 'F5', 'F2']]  Q  [[], [], ['F12', 'F5', 'F2', 'F10'], []]\n",
      "[[], ['F5', 'F12', 'F4'], [], ['F8', 'F9', 'F6', 'F7', 'F10'], ['F2', 'F3', 'F1'], ['F4', 'F5', 'F12'], ['F11']]  Q  [[], [], ['F5', 'F8', 'F2', 'F9'], []]\n",
      "[[], [], ['F4', 'F3', 'F1', 'F8', 'F2', 'F9', 'F5', 'F7', 'F6'], ['F3', 'F4', 'F7', 'F6'], ['F6', 'F9', 'F5', 'F1'], ['F7', 'F8', 'F2']]  Q  [[], [], ['F8', 'F1', 'F3'], []]\n",
      "[[], ['F2', 'F3', 'F4', 'F1', 'F5', 'F7', 'F8', 'F6', 'F9'], [], ['F2', 'F5', 'F6', 'F9', 'F3', 'F7', 'F4', 'F1', 'F8'], ['F3', 'F7', 'F4', 'F1', 'F8', 'F2', 'F5', 'F6', 'F9']]  Q  [[], [], ['F4', 'F1', 'F5'], []]\n",
      "[[], ['F11', 'F10', 'F6', 'F8', 'F14', 'F3'], [], ['F5', 'F4', 'F1', 'F8', 'F14', 'F3'], ['F11', 'F10', 'F6', 'F9', 'F7', 'F13', 'F12'], []]  Q  [[], [], ['F6', 'F5', 'F12', 'F4'], []]\n",
      "[[], [], ['F1', 'F6', 'F2', 'F9'], ['F8', 'F5', 'F4', 'F7', 'F3'], ['F1', 'F7', 'F8', 'F5'], ['F6', 'F9', 'F2', 'F4', 'F3'], ['F6', 'F9', 'F2']]  Q  [[], [], ['F2', 'F4', 'F7'], []]\n",
      "[[], ['F1', 'F7', 'F4', 'F2', 'F5'], ['F1', 'F7', 'F4', 'F8'], ['F3', 'F6', 'F9', 'F2', 'F5']]  Q  [[], [], ['F9', 'F8', 'F2'], []]\n",
      "[[], [], ['F3', 'F7', 'F2', 'F6', 'F4', 'F1', 'F8', 'F9', 'F5'], ['F7', 'F3', 'F9', 'F8', 'F5'], ['F5', 'F1', 'F8', 'F2'], ['F4', 'F6', 'F9']]  Q  [[], [], ['F6', 'F2', 'F7'], []]\n",
      "[[], ['F7', 'F3'], ['F5', 'F12', 'F11', 'F1'], ['F1', 'F8', 'F14', 'F4', 'F9', 'F13', 'F2'], ['F10', 'F16', 'F14', 'F6'], ['F10', 'F6', 'F14', 'F16']]  Q  [[], [], ['F1', 'F4', 'F2'], []]\n",
      "[[], ['F9', 'F8', 'F6', 'F1', 'F6'], ['F5', 'F10', 'F3', 'F4'], ['F7']]  Q  [[], [], ['F5', 'F3', 'F4'], []]\n",
      "[[], ['F30', 'F33', 'F38', 'F36'], ['F23', 'F28', 'F5'], [], ['F39', 'F35', 'F20', 'F14'], ['F30', 'F33', 'F38', 'F36'], ['F23', 'F28', 'F10', 'F40'], []]  Q  [[], [], ['F38', 'F36', 'F23', 'F28'], []]\n",
      "[[], ['F9', 'F24', 'F14', 'F6', 'F3', 'F30', 'F22', 'F12', 'F31', 'F19', 'F5'], ['F9', 'F24', 'F14', 'F11', 'F6'], ['F30', 'F22', 'F3', 'F18']]  Q  [[], [], ['F30', 'F22', 'F3'], []]\n",
      "[[], ['F1', 'F6', 'F2', 'F10', 'F13', 'F9'], ['F9', 'F13'], [], ['F5', 'F3', 'F11', 'F12', 'F8'], ['F7', 'F3', 'F13', 'F9']]  Q  [[], [], ['F2', 'F10', 'F9', 'F13'], []]\n",
      "[[], ['F8', 'F1', 'F7'], ['F5', 'F9', 'F4'], []]  Q  [[], [], ['F9', 'F12', 'F4'], []]\n",
      "[[], ['F12', 'F4'], ['F16', 'F9', 'F3', 'F8'], ['F5', 'F10'], ['F14', 'F1', 'F11', 'F6']]  Q  [[], [], ['F8', 'F5', 'F10'], []]\n",
      "[[], ['F7', 'F6', 'F2'], ['F10', 'F11', 'F3', 'F12', 'F8'], ['F5', 'F4', 'F9'], ['F7', 'F6', 'F2'], ['F1']]  Q  [[], [], ['F6', 'F10', 'F5', 'F11'], []]\n",
      "[[], [], ['F18', 'F20', 'F11'], ['F14', 'F15', 'F8', 'F10'], ['F18', 'F20', 'F11'], ['F6', 'F7', 'F9', 'F3'], ['F13', 'F16', 'F19', 'F1'], []]  Q  [[], [], ['F13', 'F16', 'F19'], []]\n",
      "[[], ['F8', 'F12', 'F9'], [], ['F11', 'F3', 'F10', 'F1'], []]  Q  [[], [], ['F13', 'F5', 'F7'], []]\n",
      "[[], ['F19', 'F8', 'F17', 'F10', 'F9', 'F7', 'F5', 'F3'], ['F15', 'F11', 'F20'], ['F15'], ['F8', 'F19'], []]  Q  [[], [], ['F17', 'F15', 'F11', 'F20'], []]\n",
      "[[], [], ['F16', 'F6', 'F10', 'F15', 'F11', 'F17'], ['F16', 'F9', 'F5', 'F13', 'F4'], ['F6', 'F1', 'F3', 'F7'], []]  Q  [[], [], ['F13', 'F4', 'F12'], []]\n",
      "[[], ['F12', 'F4', 'F13', 'F5', 'F2', 'F8', 'F9'], ['F3', 'F1', 'F10', 'F11', 'F7', 'F6'], ['F13', 'F1', 'F6', 'F12', 'F4', 'F3', 'F5']]  Q  [[], [], ['F13', 'F5', 'F3', 'F1'], []]\n",
      "[[], [], ['F1', 'F6', 'F10', 'F4', 'F8'], ['F2', 'F9', 'F7'], [], ['F5', 'F11', 'F3', 'F12'], []]  Q  [[], [], ['F10', 'F4', 'F8', 'F5'], []]\n",
      "[[], ['F7', 'F9', 'F8', 'F6', 'F10', 'F2', 'F1', 'F11', 'F5'], ['F6', 'F11'], ['F7', 'F9', 'F8', 'F10', 'F3', 'F4']]  Q  [[], [], ['F8', 'F6', 'F10', 'F3'], []]\n",
      "[[], ['F3', 'F4', 'F7', 'F1'], ['F6'], ['F3', 'F2', 'F7', 'F1'], ['F4', 'F5', 'F8']]  Q  [[], [], ['F7', 'F1', 'F2', 'F8'], []]\n",
      "[[], ['F1', 'F2'], [], ['F3', 'F6', 'F5', 'F4', 'F7']]  Q  [[], [], ['F7', 'F1', 'F2'], []]\n",
      "[[], [], ['F9', 'F3', 'F1', 'F5', 'F2'], ['F6', 'F4', 'F7', 'F8']]  Q  [[], [], ['F6', 'F4', 'F7'], []]\n",
      "[[], [], ['F9', 'F2', 'F3', 'F4', 'F8'], ['F6', 'F7', 'F5'], ['F3', 'F4', 'F8'], ['F1', 'F9', 'F2', 'F7', 'F6', 'F5'], []]  Q  [[], [], ['F4', 'F8', 'F1'], []]\n",
      "[[], ['F9', 'F10', 'F8'], ['F11', 'F4', 'F2', 'F14', 'F5'], ['F3', 'F5', 'F13', 'F6'], []]  Q  [[], [], ['F11', 'F4', 'F2'], []]\n",
      "[[], ['F1', 'F4', 'F8', 'F5'], ['F2', 'F3', 'F7'], ['F2', 'F1', 'F5', 'F9']]  Q  [[], [], ['F4', 'F3', 'F8', 'F7'], []]\n",
      "[[], [], ['F3', 'F7', 'F6', 'F11'], [], ['F8', 'F9', 'F10', 'F4', 'F1'], ['F2', 'F5', 'F13'], []]  Q  [[], [], ['F11', 'F2', 'F5'], []]\n",
      "[[], ['F27', 'F74', 'F84', 'F79', 'F72', 'F45', 'F42'], ['F40', 'F52', 'F11', 'F20', 'F38', 'F56', 'F6', 'F25', 'F55', 'F47', 'F46', 'F75', 'F1'], ['F23', 'F34', 'F85', 'F57'], ['F42', 'F52', 'F46', 'F75', 'F1'], ['F27', 'F74', 'F84', 'F79']]  Q  [[], [], ['F72', 'F42', 'F45'], []]\n",
      "[['F10', 'F3', 'F9', 'F1'], ['F1', 'F11', 'F8'], ['F10', 'F3', 'F4', 'F2', 'F7', 'F9'], []]  Q  [[], [], ['F9', 'F1', 'F4', 'F2'], []]\n",
      "[[], ['F2', 'F14', 'F20', 'F22'], ['F6', 'F3', 'F19', 'F20', 'F14', 'F2', 'F22'], ['F15', 'F11', 'F1', 'F7', 'F12'], ['F21', 'F8', 'F18', 'F9', 'F16', 'F13'], ['F13', 'F16']]  Q  [[], [], ['F14', 'F22', 'F2', 'F7'], []]\n",
      "[[], ['F8', 'F5'], ['F3', 'F7', 'F4'], ['F6'], ['F2', 'F1', 'F5'], []]  Q  [[], [], ['F1', 'F8', 'F5'], []]\n",
      "[[], [], ['F15', 'F18', 'F13'], [], ['F1', 'F2', 'F10', 'F5', 'F14', 'F6', 'F11', 'F7'], ['F14', 'F6', 'F11', 'F16', 'F4', 'F7'], ['F15', 'F18', 'F13', 'F19', 'F12', 'F2'], ['F5']]  Q  [[], [], ['F6', 'F11', 'F7'], []]\n",
      "[[], ['F9', 'F5', 'F7'], ['F9', 'F5', 'F7'], ['F8', 'F3', 'F10', 'F1'], ['F2']]  Q  [[], [], ['F8', 'F10', 'F1'], []]\n",
      "[[], ['F4', 'F8'], ['F6', 'F2', 'F1', 'F7', 'F5', 'F3'], ['F8', 'F5', 'F3'], ['F4', 'F1', 'F7', 'F6', 'F2']]  Q  [[], [], ['F1', 'F7', 'F5', 'F3'], []]\n",
      "[['F7', 'F2', 'F5', 'F11'], [], ['F11', 'F8', 'F9'], ['F7', 'F2', 'F5'], []]  Q  [[], [], ['F5', 'F11', 'F4', 'F1'], []]\n",
      "[[], ['F3', 'F6', 'F14', 'F10', 'F5', 'F8'], ['F3', 'F6', 'F14'], ['F11', 'F4', 'F1', 'F13', 'F5', 'F16'], ['F3', 'F6']]  Q  [[], [], ['F4', 'F1', 'F13'], []]\n",
      "[[], [], ['F7', 'F10', 'F2', 'F9', 'F4', 'F5', 'F6', 'F8', 'F3', 'F1', 'F11'], ['F11'], ['F7', 'F10', 'F2', 'F3'], ['F9', 'F4', 'F5', 'F6', 'F8', 'F1'], ['F7', 'F10', 'F2']]  Q  [[], [], ['F2', 'F9', 'F4', 'F5'], []]\n",
      "[[], ['F4', 'F3', 'F7', 'F21', 'F20', 'F8'], ['F4', 'F3', 'F7'], ['F20', 'F8', 'F12', 'F5'], ['F21', 'F22', 'F19', 'F1', 'F10'], ['F4', 'F3', 'F7'], ['F13', 'F2']]  Q  [[], [], ['F21', 'F20', 'F8'], []]\n",
      "[[], [], ['F7', 'F8', 'F6', 'F1'], ['F1', 'F2', 'F3', 'F9', 'F5', 'F8'], ['F7', 'F6', 'F5', 'F4'], ['F8', 'F1', 'F2']]  Q  [[], [], ['F2', 'F3', 'F9'], []]\n",
      "[[], [], [], ['F11', 'F6', 'F15', 'F12', 'F8', 'F11'], ['F11', 'F12', 'F20', 'F8'], ['F6', 'F15', 'F17']]  Q  [[], [], ['F15', 'F8', 'F17'], []]\n",
      "[[], [], ['F7', 'F11', 'F20', 'F5', 'F15', 'F14', 'F16', 'F13'], ['F6', 'F8', 'F12'], ['F6', 'F7', 'F11', 'F20', 'F6', 'F8'], ['F11', 'F7']]  Q  [[], [], ['F20', 'F6', 'F8', 'F12'], []]\n",
      "[[], ['F10', 'F7', 'F1', 'F10', 'F7'], ['F1', 'F6', 'F3', 'F4', 'F9', 'F2', 'F7', 'F10'], ['F8', 'F5']]  Q  [[], [], ['F6', 'F3', 'F4'], []]\n",
      "[[], ['F7', 'F17', 'F19', 'F14'], ['F6', 'F5', 'F26', 'F15', 'F20', 'F8'], ['F25', 'F21', 'F13', 'F18'], ['F21', 'F25', 'F7', 'F14', 'F13', 'F10', 'F19', 'F16', 'F17', 'F22']]  Q  [[], [], ['F19', 'F17', 'F13', 'F21'], []]\n",
      "[[], ['F6', 'F12', 'F11', 'F2', 'F1', 'F7', 'F3'], ['F6', 'F4', 'F11', 'F5', 'F2', 'F12', 'F7'], ['F8', 'F10', 'F3', 'F1', 'F9'], []]  Q  [[], [], ['F11', 'F8', 'F10'], []]\n",
      "[[], ['F7', 'F1', 'F6'], [], ['F5', 'F10', 'F4', 'F12'], []]  Q  [[], [], ['F3', 'F14', 'F11'], []]\n",
      "[[], ['F7', 'F9'], ['F1', 'F4', 'F6'], ['F8', 'F2', 'F5', 'F3'], ['F1', 'F4', 'F6']]  Q  [[], [], ['F2', 'F5', 'F3'], []]\n",
      "[[], ['F18', 'F10', 'F4', 'F16'], ['F23', 'F12', 'F2', 'F15', 'F6', 'F17'], ['F11', 'F14', 'F21', 'F5'], ['F10', 'F18', 'F14', 'F21', 'F4', 'F16', 'F11', 'F19', 'F3', 'F20']]  Q  [[], [], ['F4', 'F16', 'F11', 'F14'], []]\n",
      "[[], [], ['F1', 'F6', 'F4', 'F5'], ['F2', 'F3'], ['F2', 'F3']]  Q  [[], [], ['F4', 'F5', 'F2', 'F3'], []]\n",
      "[[], [], ['F6', 'F2', 'F15'], ['F7', 'F12', 'F14', 'F17', 'F18'], [], [], ['F15', 'F6', 'F10', 'F2', 'F11', 'F16'], []]  Q  [[], [], ['F10', 'F3', 'F19'], []]\n",
      "[[], [], ['F1', 'F2', 'F7'], ['F9', 'F14', 'F13'], ['F11', 'F12', 'F9'], ['F2', 'F1', 'F7', 'F3', 'F11', 'F12', 'F9']]  Q  [[], [], ['F11', 'F3', 'F10'], []]\n",
      "[[], [], ['F22', 'F19', 'F13', 'F1', 'F10', 'F20'], ['F22', 'F19', 'F13'], ['F22', 'F19', 'F13', 'F20', 'F1', 'F3', 'F16'], ['F10', 'F17', 'F18', 'F9', 'F7', 'F22', 'F19', 'F13'], ['F5', 'F8']]  Q  [[], [], ['F10', 'F20', 'F1'], []]\n",
      "[[], [], ['F15'], ['F4', 'F8', 'F1', 'F7'], ['F11', 'F6', 'F14', 'F19'], ['F15']]  Q  [[], [], ['F7', 'F18', 'F20'], []]\n"
     ]
    }
   ],
   "source": [
    "letter = 'B'\n",
    "'''\n",
    "B. For 78 cases the format is:\n",
    "* \"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\"\n",
    "* \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\"\n",
    "* 'Summarize the direction of influence of the features [the next 3-4 features (after first 2-4)] with moderate impact on the prediction made for this test case.'\n",
    "'''\n",
    "\n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-2e87d7282ff9a06c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The prediction probability associated with class C2 and class C1, respectively, is 35.34% and 64.66%. Based on these probabilities, the model labels the given case as C1 since it is the most probable class. According to the attribution analysis, the most relevant features considered by the model here are F5, F1, and F8, while the least relevant features are F12, F2, and F4. Regarding the direction of influence of the features, F5, F1, F8, and F7 are the top positively supporting features, driving the decision higher in favour of C1. Further increasing the probability that C1 is the true label are the values of other positive features such as F16, F3, F15, and F14. To explain why the likelihood of C2 is 35.34%, we have to look at the negative contributions from F11, F6, F13, F2, F12, and F4. The abovementioned negative features contradict the model's decision with respect to the classification outcome.\",\n",
       " \"Of the three possible labels, there is 100.0% confidence that C3 is the most probable label for the given case. The features that heavily influence the classification verdict presented here are F5, F10, and F6, and they have a very strong positive contribution, increasing the odds of the C3 prediction. Other features with a positive influence on the model are F3, F1, F12, F7, and F4. On the contrary, F9, F2, and F8 make the model's decision fluctuate negatively towards selecting an alternative label. All of the negative features mentioned above have a low to moderate impact on the classification verdict presented here compared to F6, F10, and F5. Finally, F11 with its very low positive impact is the least ranked feature marginally pushing the decision towards the assigned label.\",\n",
       " \"Per the model, class C2 has a prediction probability of 10.50 percent, whereas class C1 has a predicted probability of 89.50 percent. As a result of the model, it can be determined that C1 is the most likely label for the given scenario. All of the input features are shown to contribute to the above conclusion, with F1, F7, and F3 having the most influence on the classification decision. The least influential features with regard to this classification are F5, F2, F10, and F4, whereas, the impact of F8, F6, and F9 can be classified as modest. The large positive contributions of F7 and F1 are responsible for the model's high confidence which further supported by the positive contributions of F8, F5, and F2. In conclusion, the negative features F3, F6, F10, F9, and F4 favour labelling the case as C2 hence the associated predicted probability.\",\n",
       " \"The model's output labelling judgement for the case under consideration is as follows: C2 cannot be the label for the given case; C1 is the most likely class label with a 100.0% confidence level. The key driving factors resulting in the aforementioned classification are the values of the input features: F38, F51, F13, F46, F28, F71, and F44. F70, F61, F85, F20, F59, F93, F14, F66, F24, F89, F30, F65, and F54 are the features that have a modest effect on the decision. Aside from the aforementioned input features, all others, such as F47, F10, F7, and F43, are revealed to be irrelevant to the conclusion reached here. Not all of the influential features support labelling the current instance as C1, and they are referred to as negative features. F44, F61, F30, F65, and F54 are the negative attributes that diminish the likelihood that C1 is the correct label in this case. F38, F51, F13, and F46 are important positive features that strongly increase the likelihood that C1 is the correct label.\",\n",
       " 'Since the likelihood of C3 being the true label is shown by the prediction algorithm outputs to be equal to 93.02 percent, there is only a small chance that the true label for the given data instance is any of the other class labels, C2 and C1. The features F12, F1, F11, and F10 are the most important ones driving the label assignment verdict above, and on the other hand, the least relevant features are shown to be F9, F6, and F3. Considering the direction of influence of each input feature, as shown by the attribution analysis, it can be concluded that the positive features steering the prediction higher towards C3 are F12, F1, F10, F11, F2, F4, and F6. The marginal doubt in the predicted output decision is attributed to the negative contributions of F8, F7, F3, F9, and F5. Considering the attributions of the features and predicted probabilities across the classes, it can be concluded that the joint positive contribution outranks the negative contributions; hence, the algorithm is confident that C3 is likely the true label.',\n",
       " 'Based on the input variables, the model is moderately confident that the C2 is the appropriate label for the data under consideration. As a matter of fact, the prediction likelihood associated with class C1 is about 30.42%. The preceeding classification verdict can be largely blamed on the contributions of variables F4, F11, F1, and F6, whereas those with marginally lower contributions are F2, F3, and F7. The variables with moderate contributions are F5, F8, F9, and F10. Considering their respective contributions, F4, F1, F6, and F10 are the variables with positive influence that increase the chances of C2 being the correct label for the given data. The little doubt in the label choice here could be attributed to the negative variables, mainly F11, F5, F9, and F8, which decrease the chances of the model labelling the data given as C2 since these negative variables favour selecting the alternative label, C1 over C2. Given that majority of top variables contribute positively, it is not unexpected that C2 is the picked label with reasonably high confidence.',\n",
       " 'The case given is labelled as C1 by the classifier with a confidence level equal to 82.07%. Therefore, the probability of C2 being the correct label is only 17.93%. The classification above is mainly due to the contributions of features such as F30, F12, F11, and F32. F17, F24, and F28 are the next three with moderate influence. However, not all the features are considered by the classifier when determining the correct label for the given case. F46, F2, F40, and F8 are notable irrelevant features. With regards to the direction of influence of the relevant features, F30, F12, F11, and F32 are the top features with strong positive contributions favouring the assignment of label C1. The top negative features that shift the classification in a different direction are F17, F24, F33, and F29. Considering the fact that a number of the relevant features have positive attributions, it is not surprising that the classifier is quite certain that the appropriate label is C1 instead of C2.',\n",
       " \"With an 81.01% chance of being correct, C1 is the most likely label, consequently, the C2 class's prediction probability is only 18.99%. The algorithm or classifier got the above prediction mostly due to the influence of features like F7, F5, F4, and F2. F6, which is found to have very little impact with regard to the label choice here, is the least relevant feature for the algorithm. F5, F1, F4, and F2 have a positive direction of influence, pushing the algorithm higher towards the C1 label. Negative features like F7, F9, and F8 favour choosing or labelling the case as C2.\",\n",
       " \"Per the classifier for the given data, the most plausible label is C2. F2, F19, F24, and F8 are the main features pushing for the above-mentioned outcome. F3, F18, F14, F16, F13, and F22, on the other hand, have little contribution to the classifier employed here. F25, F17, F7, and F9 have a moderate contribution to the assignment of C2. The classifier's confidence in the label decision above can be attributed to larger positive attributions of F17, F25, F24, and F19 compared to the negative attributions of F7, F21, F2, F4, F8, and F5.\",\n",
       " \"According to the classification algorithm, neither C1 nor C3 nor C2 is the correct label for the given case. It is 100.0% certain that C4 is the right label. The higher degree of certainty in the above prediction can be attributed to the positive contributions of F18, F11, and F12. The other positive features include F20, F15, F6, and F14, however, unlike F18, F11, and F12, these features have a moderately low impact on the algorithm's decision. The remaining positive features, F7, F19, F13, and F9, are among the least influential input features considered by the algorithm. There are other features such as F16, F10, F3, and F4 whose contributions only serve to decrease the odds of C4 being the correct label for the given case. Regarding the high confidence of the algorithm with respect to this classification, one can conclude that the negative features have little influence on the algorithm's label decision here.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train.filter(lambda x: x['narr_q_label'] == letter)['narration'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C also seems similar, answering the questions in a summary way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-aa9655efd3946d15.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-aa9655efd3946d15.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['F20', 'F5', 'F10', 'F3', 'F3', 'F20', 'F5', 'F10'], ['F1', 'F18', 'F10'], ['F11', 'F13', 'F7', 'F8']]  Q  [[], [], ['F5', 'F18', 'F1'], []]\n",
      "[[], ['F22', 'F12', 'F23', 'F9'], ['F11', 'F18', 'F16', 'F19', 'F2', 'F4'], ['F22', 'F12', 'F23'], ['F9', 'F26', 'F21', 'F3'], ['F5', 'F1', 'F8', 'F10', 'F17', 'F20', 'F24', 'F6', 'F7']]  Q  [[], [], ['F10', 'F12', 'F2', 'F21'], []]\n",
      "[[], ['F11', 'F7', 'F3', 'F10'], ['F3', 'F10', 'F2'], ['F5', 'F12', 'F4'], ['F6', 'F8', 'F1', 'F9'], ['F2', 'F12', 'F7', 'F3', 'F11']]  Q  [[], [], ['F3', 'F10', 'F2', 'F6'], []]\n",
      "[[], ['F8', 'F11', 'F14'], [], ['F15', 'F6', 'F16'], ['F2', 'F10', 'F3', 'F7', 'F1'], ['F8', 'F11', 'F14'], ['F13', 'F9', 'F5', 'F17']]  Q  [[], [], ['F11', 'F2', 'F10', 'F15'], []]\n",
      "[[], [], ['F11', 'F46', 'F8', 'F36', 'F31'], ['F17', 'F9', 'F13', 'F19'], ['F11', 'F46', 'F36', 'F7', 'F29', 'F35', 'F6', 'F26', 'F44'], ['F8', 'F31', 'F15', 'F10', 'F38', 'F39', 'F16'], [], ['F11', 'F46']]  Q  [[], [], ['F31', 'F15', 'F7'], []]\n",
      "[[], ['F8', 'F4', 'F2'], [], ['F2', 'F8', 'F4'], ['F1', 'F9', 'F6', 'F15']]  Q  [[], [], ['F4', 'F13', 'F16', 'F14'], []]\n",
      "[[], ['F2', 'F4', 'F3', 'F14', 'F9', 'F12', 'F13'], ['F8', 'F16', 'F19', 'F15'], [], ['F2', 'F4', 'F3', 'F14', 'F7', 'F17']]  Q  [[], [], ['F3', 'F14', 'F11', 'F8'], []]\n",
      "[[], ['F7', 'F9', 'F1', 'F2', 'F4', 'F5', 'F8', 'F3', 'F6'], ['F7', 'F1'], ['F9', 'F4', 'F5', 'F3', 'F2', 'F8', 'F6'], []]  Q  [[], [], ['F2', 'F4', 'F5'], []]\n",
      "[[], [], ['F12', 'F6', 'F8', 'F3', 'F13', 'F15', 'F5', 'F1', 'F10', 'F2', 'F9', 'F14', 'F7', 'F11', 'F4'], ['F12'], ['F6', 'F8', 'F3'], ['F12', 'F5', 'F11', 'F2'], []]  Q  [[], [], ['F3', 'F13', 'F15'], []]\n",
      "[[], ['F26', 'F6', 'F16'], ['F11', 'F12', 'F19', 'F4'], ['F11', 'F26', 'F16', 'F12', 'F6', 'F18', 'F4', 'F19'], [], ['F15', 'F5', 'F10', 'F9']]  Q  [[], [], ['F12', 'F11', 'F19'], []]\n",
      "[[], [], [], ['F51', 'F26', 'F4', 'F55', 'F9'], [], ['F67', 'F45', 'F11', 'F71'], ['F4', 'F6', 'F32', 'F28', 'F10', 'F57'], ['F51', 'F26', 'F55', 'F9']]  Q  [[], [], ['F9', 'F59', 'F63'], []]\n",
      "[[], ['F13', 'F24', 'F1'], ['F1', 'F24', 'F13'], ['F1', 'F24', 'F13'], ['F7', 'F18', 'F21'], ['F17', 'F13'], ['F25', 'F26', 'F4', 'F9', 'F15', 'F8']]  Q  [[], [], ['F13', 'F7', 'F18', 'F21'], []]\n",
      "[[], ['F27', 'F12', 'F24', 'F14', 'F30', 'F18', 'F26', 'F2', 'F20', 'F22', 'F13', 'F21', 'F17', 'F23', 'F10', 'F25', 'F5', 'F6', 'F8'], ['F12', 'F27'], ['F30', 'F18', 'F20'], ['F24', 'F14', 'F26', 'F2', 'F22', 'F13'], ['F15', 'F4', 'F1', 'F29']]  Q  [[], [], ['F24', 'F14', 'F30', 'F18'], []]\n",
      "[[], [], ['F12'], ['F11', 'F4', 'F7', 'F6', 'F12'], ['F5', 'F2', 'F9', 'F1', 'F3', 'F10', 'F8', 'F3', 'F10', 'F8']]  Q  [[], [], ['F4', 'F7', 'F5', 'F2'], []]\n",
      "[[], ['F5', 'F12', 'F11', 'F4'], ['F1', 'F14', 'F6', 'F8'], ['F5', 'F12', 'F11', 'F4'], ['F3', 'F2', 'F13', 'F7']]  Q  [[], [], ['F4', 'F1', 'F14'], []]\n",
      "[[], [], [], ['F1', 'F7', 'F8', 'F2'], ['F26', 'F17', 'F15', 'F3'], ['F26', 'F1', 'F2', 'F4', 'F19', 'F17', 'F7', 'F8', 'F3', 'F15'], ['F22', 'F5', 'F20', 'F9']]  Q  [[], [], ['F17', 'F26', 'F15'], []]\n",
      "[[], ['F6'], ['F5', 'F8', 'F7', 'F1', 'F4', 'F2', 'F3', 'F6'], ['F6'], ['F8', 'F7', 'F1', 'F4'], ['F6'], ['F6']]  Q  [[], [], ['F8', 'F7', 'F1', 'F4'], []]\n",
      "[[], [], ['F10', 'F8', 'F7', 'F16', 'F15', 'F5'], ['F5', 'F11', 'F1', 'F2', 'F14', 'F10', 'F8'], ['F16', 'F15', 'F3', 'F12', 'F9', 'F4', 'F6']]  Q  [[], [], ['F11', 'F9', 'F4'], []]\n",
      "[[], ['F4', 'F5', 'F10', 'F6', 'F9'], ['F7', 'F2', 'F7'], ['F7', 'F2'], ['F3', 'F1'], ['F3', 'F1', 'F2'], ['F3', 'F1', 'F2']]  Q  [[], [], ['F7', 'F2', 'F8'], []]\n",
      "[[], ['F11', 'F10', 'F3'], ['F8', 'F13', 'F1'], ['F11', 'F13', 'F6', 'F9', 'F10', 'F3', 'F15'], []]  Q  [[], [], ['F15', 'F5', 'F4'], []]\n",
      "[[], ['F1', 'F9'], ['F12', 'F10', 'F8', 'F2'], ['F4', 'F6', 'F7', 'F3', 'F11', 'F5'], ['F9', 'F1', 'F12', 'F8', 'F2']]  Q  [[], [], ['F2', 'F10', 'F1', 'F4'], []]\n",
      "[[], ['F23', 'F1', 'F18', 'F12', 'F30', 'F10', 'F11', 'F16', 'F29', 'F24', 'F8', 'F15', 'F7', 'F28', 'F9', 'F17', 'F14', 'F6', 'F26', 'F25'], [], ['F5', 'F4', 'F27', 'F2'], ['F23', 'F1', 'F18', 'F12'], ['F23', 'F1'], ['F30', 'F10', 'F29', 'F11', 'F16', 'F24', 'F8']]  Q  [[], [], ['F18', 'F12', 'F30', 'F10'], []]\n",
      "[[], ['F5', 'F2', 'F8'], ['F5', 'F8', 'F7', 'F4'], ['F5', 'F8', 'F7', 'F4'], ['F2', 'F1', 'F9'], ['F3', 'F6', 'F10']]  Q  [[], [], ['F8', 'F7', 'F9', 'F1'], []]\n",
      "[[], ['F7', 'F3', 'F4', 'F10', 'F10'], ['F7', 'F3', 'F4', 'F10', 'F5', 'F9'], ['F7', 'F3', 'F4', 'F5', 'F9'], ['F10', 'F1', 'F8', 'F6', 'F11']]  Q  [[], [], ['F4', 'F10', 'F5', 'F9'], []]\n",
      "[[], ['F4', 'F11', 'F9', 'F7'], [], ['F2', 'F10', 'F6', 'F8'], ['F3', 'F1', 'F12', 'F5'], ['F3', 'F1', 'F12', 'F5']]  Q  [[], [], ['F7', 'F6', 'F8'], []]\n",
      "[[], ['F5', 'F3', 'F8', 'F4'], ['F1', 'F6'], ['F5', 'F3', 'F8', 'F4']]  Q  [[], [], ['F4', 'F9', 'F7'], []]\n",
      "[[], ['F15', 'F2', 'F6'], ['F22', 'F19', 'F4'], ['F22', 'F15', 'F6', 'F19', 'F2', 'F9', 'F18', 'F4'], ['F17', 'F26', 'F5', 'F1']]  Q  [[], [], ['F19', 'F22', 'F4'], []]\n",
      "[[], ['F10'], ['F8', 'F3'], ['F6', 'F4'], ['F11', 'F2', 'F5', 'F7', 'F1'], ['F9', 'F6', 'F4', 'F11', 'F2', 'F7']]  Q  [[], [], ['F8', 'F6', 'F4', 'F3'], []]\n",
      "[[], ['F1', 'F7', 'F9'], ['F1', 'F9', 'F3', 'F6'], ['F1', 'F9', 'F3', 'F6'], ['F7', 'F10', 'F2', 'F5', 'F8', 'F4']]  Q  [[], [], ['F9', 'F3', 'F2', 'F10'], []]\n",
      "[[], [], ['F3', 'F11', 'F12', 'F13', 'F1', 'F9'], ['F9', 'F2', 'F5', 'F15', 'F10', 'F3', 'F11'], ['F13', 'F1', 'F14', 'F16', 'F4', 'F6', 'F8']]  Q  [[], [], ['F2', 'F4', 'F6'], []]\n",
      "[[], ['F3', 'F1', 'F9'], ['F8', 'F2', 'F4'], ['F5', 'F6', 'F7'], ['F9', 'F5'], [], []]  Q  [[], [], ['F5', 'F6', 'F7'], []]\n",
      "[[], ['F11', 'F6'], ['F8', 'F1', 'F10', 'F2'], ['F5', 'F7'], ['F4', 'F9', 'F2', 'F3', 'F10'], ['F6', 'F5', 'F7', 'F4', 'F9', 'F3']]  Q  [[], [], ['F8', 'F5', 'F7', 'F1'], []]\n",
      "[[], [], ['F12', 'F3', 'F9'], ['F3', 'F12', 'F9'], ['F14', 'F6', 'F2', 'F11']]  Q  [[], [], ['F9', 'F8', 'F16', 'F15'], []]\n",
      "[[], ['F8', 'F10', 'F16', 'F3'], ['F8', 'F10', 'F3', 'F16'], ['F12', 'F9', 'F17', 'F5', 'F19', 'F7']]  Q  [[], [], ['F3', 'F9', 'F12'], []]\n",
      "[[], ['F4', 'F5', 'F13', 'F6'], ['F3', 'F1', 'F10'], ['F9', 'F8', 'F2', 'F12', 'F11', 'F7', 'F8', 'F12']]  Q  [[], [], ['F10', 'F3', 'F1'], []]\n",
      "[[], ['F7'], ['F10', 'F2', 'F8', 'F4', 'F1', 'F9', 'F3', 'F7'], ['F7'], ['F2', 'F8', 'F4', 'F1'], ['F7'], ['F7']]  Q  [[], [], ['F2', 'F8', 'F4', 'F1'], []]\n",
      "[[], [], ['F14', 'F6', 'F11', 'F16', 'F13'], ['F8', 'F10', 'F9', 'F15', 'F1'], ['F6', 'F9', 'F3', 'F7', 'F2', 'F4', 'F16'], ['F14', 'F11', 'F8', 'F10', 'F15', 'F1', 'F5']]  Q  [[], [], ['F9', 'F15', 'F1'], []]\n",
      "[[], ['F6', 'F1'], ['F6', 'F3'], ['F7', 'F4', 'F3', 'F2', 'F7', 'F4', 'F3', 'F2'], ['F9', 'F5', 'F8'], ['F8']]  Q  [[], [], ['F7', 'F4', 'F3', 'F2'], []]\n",
      "[[], ['F13', 'F6', 'F4', 'F1', 'F5', 'F10', 'F12', 'F9'], ['F1', 'F5'], ['F10', 'F12', 'F7', 'F8'], ['F9'], ['F9', 'F2', 'F4'], ['F9', 'F2', 'F4']]  Q  [[], [], ['F9', 'F7', 'F8'], []]\n",
      "[[], ['F4'], ['F7'], ['F1', 'F5', 'F7', 'F8'], ['F1', 'F5', 'F7', 'F8'], ['F9', 'F3', 'F6']]  Q  [[], [], ['F1', 'F5', 'F7', 'F8'], []]\n",
      "[[], [], ['F2', 'F7', 'F16', 'F2', 'F7', 'F16'], ['F5', 'F1', 'F9'], ['F19', 'F8', 'F15', 'F4', 'F10', 'F3', 'F20']]  Q  [[], [], ['F16', 'F1', 'F5', 'F9'], []]\n",
      "[[], ['F5', 'F2', 'F1', 'F8', 'F7', 'F9', 'F4'], ['F1', 'F8', 'F7', 'F6'], ['F5', 'F2', 'F3'], []]  Q  [[], [], ['F1', 'F8', 'F7', 'F6'], []]\n",
      "[[], ['F40', 'F8', 'F5', 'F22'], ['F40', 'F8', 'F22', 'F29', 'F4'], ['F5', 'F6', 'F45', 'F27', 'F36'], ['F18', 'F20', 'F15', 'F44', 'F11', 'F10', 'F26', 'F3'], ['F40', 'F8']]  Q  [[], [], ['F29', 'F4', 'F45'], []]\n",
      "[[], ['F6', 'F5', 'F26', 'F11'], ['F20', 'F25', 'F1', 'F21'], ['F10', 'F8', 'F9'], ['F6', 'F11', 'F21'], ['F5', 'F26', 'F1', 'F25']]  Q  [[], [], ['F21', 'F20', 'F1'], []]\n",
      "[[], [], ['F2'], ['F11', 'F10', 'F1', 'F3'], ['F2'], ['F7', 'F9', 'F5', 'F12', 'F8', 'F4', 'F6']]  Q  [[], [], ['F10', 'F1', 'F7', 'F9'], []]\n",
      "[[], ['F1', 'F29', 'F27'], [], ['F12', 'F22', 'F8', 'F15', 'F20'], ['F6', 'F25', 'F9', 'F16', 'F17'], []]  Q  [[], [], ['F12', 'F22', 'F20'], []]\n",
      "[[], ['F38', 'F19'], ['F46', 'F40', 'F17', 'F31', 'F42', 'F43', 'F5', 'F37', 'F39', 'F28', 'F7', 'F1', 'F10', 'F16', 'F3', 'F25', 'F6', 'F27'], ['F46', 'F17', 'F43', 'F39', 'F5']]  Q  [[], [], ['F31', 'F42', 'F43'], []]\n",
      "[[], [], ['F11'], ['F9', 'F3', 'F5', 'F1'], ['F11'], ['F7', 'F6', 'F12', 'F8', 'F4', 'F10', 'F2'], ['F4', 'F10', 'F2']]  Q  [[], [], ['F3', 'F5', 'F7', 'F6'], []]\n",
      "[[], ['F9', 'F10', 'F5'], ['F5'], ['F9', 'F10'], ['F11', 'F14', 'F17', 'F12']]  Q  [[], [], ['F10', 'F4', 'F6', 'F3'], []]\n",
      "[[], ['F10', 'F5', 'F4', 'F8', 'F9'], ['F3', 'F7', 'F3'], ['F3', 'F7'], ['F2', 'F6'], ['F7', 'F6', 'F2'], ['F2', 'F6', 'F7']]  Q  [[], [], ['F3', 'F7', 'F1'], []]\n",
      "[[], [], ['F5', 'F1', 'F11', 'F8', 'F10', 'F7', 'F3', 'F4', 'F12', 'F9', 'F2', 'F6'], [], ['F10', 'F3', 'F7', 'F12', 'F6', 'F2'], ['F5', 'F1', 'F11']]  Q  [[], [], ['F11', 'F8', 'F10', 'F7'], []]\n",
      "[[], [], ['F28', 'F13', 'F1'], ['F20', 'F30', 'F10', 'F6', 'F12'], ['F25', 'F5', 'F27'], []]  Q  [[], [], ['F20', 'F30', 'F12'], []]\n",
      "[[], ['F5', 'F1'], [], ['F6', 'F3', 'F2'], ['F5', 'F1'], ['F4'], ['F4']]  Q  [[], [], ['F6', 'F3', 'F2', 'F4'], []]\n"
     ]
    }
   ],
   "source": [
    "letter = 'C'\n",
    "'''\n",
    "C. For 53 cases the format is:\n",
    "* 'Summarize the prediction for the given test example?'\n",
    "* \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\"\n",
    "* 'Compare and contrast the impact of the following attributes  [3-4 seemingly random features] on the model’s prediction of [C1/C2].'\n",
    "* 'Summarize the set of features has little to no impact on the prediction?'\n",
    "'''\n",
    "\n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-84450e6c7ca381de.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-84450e6c7ca381de.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], ['F7', 'F5', 'F2', 'F10'], ['F6', 'F1', 'F9'], ['F11', 'F4', 'F3'], ['F12', 'F8'], ['F5', 'F7', 'F10', 'F2']]  Q  [[], [], [], []]\n",
      "[[], ['F25', 'F4', 'F1', 'F28', 'F4', 'F1'], ['F12', 'F27', 'F23', 'F18'], ['F12', 'F27', 'F23', 'F18'], ['F17', 'F10', 'F9', 'F11']]  Q  [[], [], [], []]\n",
      "[[], ['F6', 'F1', 'F7', 'F12'], ['F6', 'F1', 'F12'], ['F7', 'F13'], ['F6', 'F1', 'F12'], ['F5', 'F3', 'F11', 'F2', 'F9', 'F10']]  Q  [[], [], [], []]\n",
      "[[], [], ['F9', 'F6', 'F4', 'F1', 'F2', 'F7'], ['F9', 'F6'], ['F4', 'F1', 'F2', 'F7', 'F7'], ['F5', 'F8', 'F3'], ['F5', 'F3', 'F8']]  Q  [[], [], [], []]\n",
      "[[], ['F10', 'F3', 'F5'], ['F10', 'F3', 'F5'], ['F2', 'F12', 'F9'], ['F4', 'F6', 'F8', 'F11']]  Q  [[], [], [], []]\n",
      "[[], ['F3', 'F9', 'F7', 'F2', 'F1'], ['F3', 'F9', 'F7', 'F2', 'F4', 'F1'], ['F6', 'F10', 'F8', 'F5']]  Q  [[], [], [], []]\n",
      "[[], ['F10', 'F2', 'F4', 'F6', 'F1', 'F11'], [], ['F10', 'F5', 'F1']]  Q  [[], [], [], []]\n",
      "[[], ['F38', 'F28', 'F31', 'F15', 'F22'], ['F38', 'F28'], ['F31', 'F15', 'F22'], ['F17', 'F14', 'F13', 'F26', 'F9', 'F6'], ['F7', 'F29', 'F21', 'F36']]  Q  [[], [], [], []]\n",
      "[[], ['F1', 'F8', 'F6', 'F4', 'F2', 'F5'], ['F8', 'F8', 'F4', 'F5'], []]  Q  [[], [], [], []]\n",
      "[[], ['F4', 'F5', 'F3'], ['F9', 'F6', 'F1'], [], ['F4', 'F10', 'F6'], []]  Q  [[], [], [], []]\n",
      "[[], [], ['F5', 'F4', 'F7'], ['F4'], ['F7', 'F5'], ['F8', 'F2'], ['F3', 'F6']]  Q  [[], [], [], []]\n",
      "[[], ['F24', 'F7', 'F6', 'F38', 'F11'], ['F19', 'F26', 'F14', 'F18', 'F37', 'F4', 'F28', 'F25', 'F3', 'F22', 'F21', 'F30', 'F8', 'F15', 'F34'], ['F24', 'F7'], ['F19', 'F26', 'F37'], ['F6', 'F38', 'F11', 'F14'], ['F23', 'F17', 'F32', 'F13']]  Q  [[], [], [], []]\n",
      "[[], ['F1', 'F7', 'F4', 'F2', 'F6', 'F5'], ['F7', 'F7', 'F2', 'F5'], ['F4', 'F1', 'F8', 'F9', 'F3', 'F6']]  Q  [[], [], [], []]\n",
      "[[], ['F3', 'F14', 'F12', 'F5'], ['F8', 'F6', 'F7', 'F1']]  Q  [[], [], [], []]\n",
      "[[], ['F1', 'F3', 'F4'], ['F5', 'F9', 'F7'], [], ['F1', 'F8', 'F9'], []]  Q  [[], [], [], []]\n",
      "[[], ['F3', 'F2', 'F1'], ['F3'], ['F2', 'F1', 'F9', 'F6'], ['F5', 'F4']]  Q  [[], [], [], []]\n",
      "[[], ['F2', 'F9', 'F6'], ['F7', 'F12', 'F1'], ['F4', 'F10', 'F3', 'F5', 'F14', 'F8', 'F13'], [], ['F3', 'F11', 'F13', 'F12', 'F2', 'F9', 'F6', 'F4', 'F10']]  Q  [[], [], [], []]\n",
      "[[], [], ['F1', 'F8', 'F5', 'F10'], ['F10', 'F9'], ['F10', 'F8', 'F1', 'F5', 'F6', 'F9'], ['F4', 'F2', 'F7', 'F3']]  Q  [[], [], [], []]\n",
      "[[], ['F4', 'F5', 'F6'], ['F4', 'F9'], ['F4'], ['F5', 'F6', 'F10', 'F3', 'F1', 'F7'], ['F2', 'F8']]  Q  [[], [], [], []]\n",
      "[[], [], ['F21', 'F26', 'F32', 'F18'], ['F2', 'F15', 'F6', 'F28', 'F22'], ['F8', 'F11', 'F14', 'F13', 'F30', 'F3', 'F25', 'F20', 'F31', 'F24', 'F33'], ['F27', 'F19', 'F12', 'F29']]  Q  [[], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "letter = 'D'\n",
    "'''\n",
    "D. For 20 cases the format is:\n",
    "* 'Summarize the prediction for the given test example?'\n",
    "* 'For this test case, summarize the top features influencing the model's decision.'\n",
    "* 'For these top features, what are the respective directions of influence on the prediction?'\n",
    "* 'Provide a statement on the set of features has limited impact on the prediction of [C1/C2] by the model for the given test example?'\n",
    "'''\n",
    "\n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-84450e6c7ca381de.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Between the three possible classes, there is an 88.0% probability that the correct label for this case is C1. This means that there is a 12.0% chance that the label could be one of the other possible labels, C2 or C3. Increasing the odds of the predicted label are the variables F7, F5, F2, and F10. The next set of variables, F6, F1, and F9, have values that moderately decrease the likelihood of C1 being the correct label. F11, F4, and F3 are the other negatively contributing features, and given that they are lowly ranked, they have a marginal impact when determining the correct label for this case. The other positive features further increasing the probability that C1 is the right label are F12 and F8. Overall, we can conclude that the decision to label the case as C1 is largely due to the strong positive influence of F5, F7, F10, and F2.',\n",
       " 'The class assigned by the model is C2 with a close to 97.67% confidence level, implying that the likelihood of C1 is only 2.33%. Based on the analysis, the most important features considered during the classification are F25, F4, F1, and F28 but among these features, F4 and F1 are the only ones with negative attributions, decreasing the likelihood of C2 being the label for the given case. Furthermore, moderately influencing the decision are F12, F27, F23, and F18. F12, F27, and F23 have positive attributions, while F18 has a negative impact, shifting the prediction in a different direction. Finally, the features with insignificant impact on the model when it comes to this case include F17, F10, F9, and F11.',\n",
       " 'Between the two classes, the model labelled this case as C1 with a likelihood of about 97.0% since there is only a marginal chance that it belongs to label C2. The most relevant features influencing this decision are F6, F1, F7, and F12. In this case, F6, F1, and F12 have a considerable positive influence on the prediction of C1. In contrast, the values of F7 and F13 throw a bit of doubt on the C1 prediction. However, compared to F6, F1, and F12, this shift is very small. Finally, there are some attributes with limited impact on the prediction of C1 and these are F5, F3, F11, F2, F9, and F10 since their values are less important to the model in terms of determining the label for this case.',\n",
       " 'The classifier states that there is a 50.0% chance that the true label of this test observation is C2. This indicates that the classifier is less certain in its prediction decision regarding the case under consideration. The label assigned is mainly due to the values of the features F9, F6, F4, F1, F2, and F7. The top features, F9 and F6, have very strong positive contributions pushing the prediction higher towards the most probable label. Among the remaining features stated above, F4, F1, F2, and F7, only F7 demonstrates some level of contradiction, forcing the labelling decision in a different direction. Finally, the features with marginal impact on the prediction made here are F5, F8, and F3. While F5 and F3 positively influence the decision made, F8 suggests that the label assigned by the classifier might not be the true label.',\n",
       " 'The final prediction given by the model was C1 with almost 100% certainty, showing the model is confident about its decision. F10 had significantly more influence on the prediction than any other feature with F3 and F5 having the next highest attribution values. All the top features, F10, F3, and F5, encouraged the model to output class C1. F2, F12, and F9 are the features that had the least positive impact on the final classification. The features F4, F6, F8, and F11 have moderate impacts, pushing the model slightly away from a C1 classification.',\n",
       " 'Considering the values of the features, the prediction from the model for the case under consideration is C2 and this labelling decision is not 100% certain given that there is a 27.27% probability that it could be C1. For the case under consideration, the assigned label is mainly due to the values of the features F3, F9, F7, and F2 while the least important is F1. The direction of the contributions of the relevant features is summarised in the following sentences: F3 and F9 have a very strong joint positive contribution in favour of class C2 coupled with moderately positive input features F7, F2, and F4, however unlike them, F1 has a very low positive impact on the model for the case here. All of F6, F10, F8, and F5 have a negative impact on the prediction made here, however, their pull is not enough to shift the prediction in the direction of the other class label, C1.',\n",
       " 'The model is assigned the label C1 for the given example. F10, F2, and F4 are the most important features that influence the above-mentioned estimate decision, however unlike them, F6, F1, and F11 are less important. The majority of features have values that swing the judgement towards the other label, C2. The only input features that increase the likelihood that C1 is the correct label are F10, F5, and F1, therefore it is very surprising that the model has 100.0% confidence in its estimate for the given example.',\n",
       " \"Considering the values of the input variables, the classification model is very confident that the most probable label is not C2 but C1. The top input variables receiving much consideration from the model to arrive at the classification verdict are F38, F28, F31, F15, and F22. Among these most influential variables, F38 and F28 are regarded as negatives since their contributions serve to swing the classification decision in the opposite direction. On the contrary, F31, F15, and F22 have a positive influence, increasing the model's response to favour labelling the given case as C1. Other positive variables include F17, F14, and F13, whereas the other negative ones include F26, F9, and F6. Input variables such as F7, F29, F21, and F36 are shown to have zero attributions, that is, their values are not paid enough attention to influence the model's decision with respect to the given case.\",\n",
       " \"There is uncertainty about the correct label for the given example since both labels, C2 and C1 are shown to have a 50.0% chance of being correct. The prediction decision above is mainly attributed to the influence of the input features F1, F8, and F6, while F4, F2, and F5 are deemed less important to the decision above. Looking at the direction of influence of each input feature, only F8, F8, F4, and F5 are shown to have a positive contribution, increasing the model's response towards assigning C2. All the remaining six features have a negative contribution towards the decision here, supporting the assignment of the other class.\",\n",
       " 'The classification model assigned the label C2 to the given example and given that the confidence level is 100.0%, we can be certain that the chances of C1 being the true label are negligible. The most relevant features controlling the prediction decision above are F4, F5, and F3. F9, F6, and F1 are among the least relevant features. Most of the properties have values that sway the decision towards the other C1 class. The only features that increase the odds that C2 is the correct label are F4, F10, and F6. It is strange that the model has 100.0% confidence in its prediction for the selected sample, given that only a small number of the input features contribute positively to reaching the C2 estimate.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train.filter(lambda x: x['narr_q_label'] == letter)['narration'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor features are mentioned a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-186461e0bb98b547.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-186461e0bb98b547.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], ['F4', 'F11', 'F3', 'F15', 'F7', 'F19', 'F1'], [], ['F3', 'F15', 'F8', 'F20'], ['F4', 'F11', 'F12', 'F2'], ['F4', 'F11']]  Q  [[], ['F4', 'F11'], ['F3', 'F15', 'F8', 'F12'], []]\n",
      "[[], ['F6', 'F10'], ['F6', 'F10'], ['F4', 'F1', 'F9', 'F12', 'F8'], ['F3', 'F8', 'F2']]  Q  [[], ['F6', 'F10'], ['F4', 'F1', 'F9', 'F11'], []]\n",
      "[[], ['F5', 'F30', 'F26', 'F17', 'F15'], ['F3', 'F4', 'F13', 'F27'], [], ['F5', 'F30', 'F26', 'F17', 'F15'], []]  Q  [[], ['F5', 'F30'], ['F26', 'F17', 'F15', 'F28'], []]\n",
      "[[], [], ['F18', 'F31', 'F19', 'F36', 'F35', 'F20', 'F38', 'F37', 'F3', 'F25', 'F16', 'F33', 'F6'], [], ['F18', 'F31', 'F19', 'F36', 'F38', 'F18', 'F31'], ['F19', 'F36', 'F38'], ['F35', 'F20', 'F5'], ['F18', 'F31', 'F9', 'F23', 'F19', 'F36', 'F5', 'F35', 'F20', 'F38']]  Q  [[], ['F18', 'F31', 'F19', 'F36', 'F38'], ['F35', 'F20', 'F5'], []]\n",
      "[[], ['F12', 'F1'], ['F12', 'F1'], ['F4', 'F11', 'F3', 'F8', 'F2'], ['F7', 'F8', 'F6']]  Q  [[], ['F12', 'F1'], ['F11', 'F4', 'F3', 'F5'], []]\n",
      "[[], ['F24', 'F23', 'F9', 'F18', 'F14', 'F10', 'F11', 'F2', 'F8', 'F21', 'F20', 'F27', 'F4', 'F12', 'F15', 'F19', 'F13', 'F16', 'F30', 'F29'], ['F24', 'F23', 'F9', 'F18', 'F14'], ['F11', 'F2', 'F10'], ['F22', 'F6', 'F1', 'F5']]  Q  [[], ['F24', 'F23', 'F9', 'F18', 'F14'], ['F10', 'F11', 'F2'], []]\n",
      "[[], ['F11', 'F4', 'F6', 'F17', 'F11'], ['F11', 'F4', 'F6', 'F17', 'F3'], ['F5', 'F2', 'F16', 'F5'], ['F15', 'F8', 'F13', 'F19', 'F10']]  Q  [[], ['F11', 'F4', 'F6', 'F17', 'F3'], ['F5', 'F2', 'F16'], []]\n",
      "[[], [], ['F18', 'F3', 'F12', 'F15', 'F1', 'F8', 'F19', 'F9'], ['F18', 'F3', 'F15'], ['F12', 'F14', 'F4'], ['F17', 'F11', 'F13', 'F7', 'F2']]  Q  [[], ['F18', 'F3', 'F12'], ['F15', 'F14', 'F4'], []]\n",
      "[[], [], ['F36', 'F8', 'F26', 'F35', 'F3', 'F12', 'F24', 'F9', 'F21', 'F6', 'F20', 'F5', 'F4', 'F25', 'F19', 'F27', 'F7', 'F23', 'F37', 'F31'], ['F30', 'F33', 'F13'], ['F36', 'F8', 'F26', 'F35', 'F3', 'F26'], ['F24', 'F12', 'F9'], []]  Q  [[], ['F36', 'F8', 'F26', 'F35', 'F3'], ['F12', 'F24', 'F9'], []]\n",
      "[[], [], ['F17', 'F9', 'F18', 'F19'], ['F43', 'F23', 'F32', 'F33', 'F29', 'F20'], ['F17', 'F19', 'F29', 'F33'], ['F9', 'F23', 'F20', 'F18', 'F43', 'F32'], ['F14', 'F31', 'F7', 'F38']]  Q  [[], ['F17', 'F9'], ['F19', 'F18', 'F43', 'F23'], []]\n",
      "[[], ['F4', 'F8', 'F3', 'F14'], ['F6', 'F1'], [], [], ['F3', 'F5', 'F13', 'F2', 'F9', 'F1', 'F4', 'F8', 'F7', 'F14']]  Q  [[], ['F4', 'F8'], ['F3', 'F14', 'F5', 'F7'], []]\n",
      "[[], [], ['F8', 'F6', 'F17', 'F4', 'F10'], ['F5', 'F19', 'F15', 'F16'], ['F11', 'F12', 'F3']]  Q  [[], ['F8', 'F6', 'F17'], ['F4', 'F10', 'F5'], []]\n",
      "[[], [], ['F4', 'F10', 'F1', 'F2', 'F7', 'F9', 'F8', 'F6', 'F3', 'F5'], ['F10', 'F4'], ['F6', 'F8'], [], ['F7', 'F1', 'F2', 'F3', 'F5']]  Q  [[], ['F4', 'F10', 'F1', 'F2', 'F7'], ['F9', 'F8', 'F6'], []]\n",
      "[[], [], ['F8', 'F21', 'F27', 'F24', 'F14', 'F25', 'F28', 'F17', 'F26', 'F15', 'F22', 'F12', 'F20', 'F4', 'F19', 'F7', 'F16', 'F35', 'F6', 'F30'], ['F36', 'F9', 'F38'], ['F8', 'F21', 'F27', 'F24', 'F14', 'F27'], ['F28', 'F25', 'F17', 'F28', 'F25', 'F17'], []]  Q  [[], ['F8', 'F21', 'F27', 'F24', 'F14'], ['F25', 'F28', 'F17'], []]\n",
      "[[], [], ['F33', 'F8', 'F17', 'F37', 'F29', 'F32', 'F4', 'F25', 'F18', 'F26', 'F15', 'F13', 'F3'], [], ['F33', 'F8', 'F33', 'F8', 'F17', 'F37', 'F4'], ['F17', 'F37', 'F4'], ['F29', 'F32', 'F2'], ['F33', 'F8', 'F31', 'F11', 'F17', 'F37', 'F2', 'F29', 'F32', 'F4']]  Q  [[], ['F33', 'F8', 'F17', 'F37', 'F4'], ['F29', 'F32', 'F2'], []]\n",
      "[[], ['F1', 'F4', 'F2', 'F6', 'F5', 'F7', 'F3', 'F8'], ['F4', 'F5', 'F7'], ['F1', 'F2', 'F6', 'F3', 'F8'], []]  Q  [[], ['F1', 'F4', 'F2'], ['F6', 'F5', 'F7'], []]\n",
      "[[], ['F12', 'F38', 'F75'], ['F58', 'F24', 'F57', 'F63'], ['F75', 'F19', 'F64', 'F23', 'F12', 'F38', 'F61', 'F72', 'F7', 'F26', 'F92']]  Q  [[], ['F12', 'F38'], ['F75', 'F61', 'F92', 'F23'], []]\n",
      "[[], ['F2', 'F5', 'F1', 'F3', 'F4', 'F6', 'F7'], ['F4', 'F6'], ['F2', 'F5', 'F1']]  Q  [[], ['F2', 'F5', 'F1', 'F3', 'F4'], ['F6', 'F7'], []]\n",
      "[[], ['F11', 'F4'], ['F4'], ['F11', 'F2', 'F1'], ['F7', 'F6', 'F9', 'F3'], ['F8', 'F12', 'F5', 'F10']]  Q  [[], ['F11', 'F4', 'F2', 'F1'], ['F9', 'F7', 'F6'], []]\n",
      "[[], [], ['F10', 'F4'], ['F4', 'F10'], ['F1', 'F5', 'F8', 'F11', 'F9', 'F6'], ['F12', 'F9', 'F6']]  Q  [[], ['F4', 'F10'], ['F5', 'F1', 'F8', 'F7'], []]\n",
      "[[], [], ['F7', 'F15', 'F8', 'F16', 'F2', 'F1', 'F33', 'F10', 'F25', 'F13', 'F4'], ['F15', 'F5', 'F16', 'F21'], ['F9', 'F17', 'F26', 'F20'], ['F7', 'F8', 'F1', 'F2', 'F28', 'F19', 'F23'], ['F7']]  Q  [[], ['F7', 'F15'], ['F8', 'F16', 'F1', 'F2'], []]\n",
      "[[], ['F10', 'F11', 'F9', 'F7', 'F12', 'F3', 'F6', 'F4', 'F8', 'F2', 'F1', 'F5'], [], ['F6', 'F3', 'F7', 'F9', 'F4', 'F10'], ['F8', 'F2', 'F1', 'F5']]  Q  [[], ['F10', 'F11'], ['F9', 'F7', 'F12', 'F3'], []]\n",
      "[[], ['F11', 'F1', 'F5', 'F2', 'F8', 'F12', 'F7', 'F10', 'F6', 'F9', 'F3', 'F4'], [], ['F5', 'F2', 'F7', 'F12', 'F10'], ['F11'], ['F6', 'F9', 'F3', 'F4']]  Q  [[], ['F11', 'F1'], ['F5', 'F2', 'F8', 'F12'], []]\n",
      "[[], [], ['F4', 'F15', 'F3', 'F12', 'F17'], ['F14', 'F2', 'F8', 'F13'], ['F1', 'F7', 'F6']]  Q  [[], ['F4', 'F15', 'F3'], ['F12', 'F17', 'F14'], []]\n",
      "[[], [], ['F6', 'F8', 'F1', 'F5', 'F4', 'F2', 'F7', 'F11', 'F12', 'F3', 'F10', 'F9'], [], ['F1', 'F5', 'F7', 'F2', 'F11'], ['F6', 'F12', 'F3', 'F10', 'F9']]  Q  [[], ['F6', 'F8'], ['F1', 'F5', 'F4', 'F2'], []]\n",
      "[[], ['F12', 'F12', 'F5', 'F15', 'F6'], ['F12', 'F5', 'F15', 'F6', 'F1'], ['F13', 'F16', 'F10', 'F13', 'F2', 'F18', 'F11'], ['F19', 'F14', 'F8', 'F7', 'F9']]  Q  [[], ['F12', 'F5', 'F15', 'F6', 'F1'], ['F13', 'F16', 'F10'], []]\n",
      "[[], [], [], ['F6', 'F9', 'F12', 'F3', 'F10', 'F2', 'F5'], ['F3', 'F12', 'F19', 'F1'], ['F6', 'F13', 'F8', 'F9'], ['F6', 'F9']]  Q  [[], ['F6', 'F9'], ['F12', 'F3', 'F1', 'F13'], []]\n",
      "[[], ['F4', 'F8', 'F10', 'F11', 'F12', 'F9'], ['F4', 'F8'], ['F11', 'F12', 'F2', 'F13', 'F9'], ['F10', 'F3', 'F14', 'F6', 'F7'], ['F5', 'F16', 'F15']]  Q  [[], ['F4', 'F8'], ['F10', 'F11', 'F12', 'F9'], []]\n",
      "[[], [], ['F16', 'F43', 'F35', 'F14'], ['F17', 'F44', 'F3', 'F21', 'F5', 'F40'], ['F16', 'F14', 'F5', 'F21', 'F43', 'F35', 'F17', 'F44', 'F40', 'F3'], ['F15', 'F39', 'F4', 'F18']]  Q  [[], ['F16', 'F43'], ['F14', 'F35', 'F17', 'F44'], []]\n",
      "[[], [], ['F1', 'F2', 'F4', 'F8', 'F5', 'F3', 'F7', 'F6'], ['F2', 'F5', 'F3'], ['F1', 'F4', 'F8', 'F7', 'F6'], []]  Q  [[], ['F1', 'F2', 'F4'], ['F8', 'F5', 'F3'], []]\n",
      "[[], ['F5', 'F7', 'F1', 'F6', 'F8', 'F9', 'F3', 'F4', 'F2'], ['F8', 'F3', 'F5', 'F1'], ['F6', 'F4', 'F7', 'F9'], ['F2']]  Q  [[], ['F5', 'F1'], ['F6', 'F4', 'F7', 'F9'], []]\n",
      "[[], ['F3', 'F5', 'F14'], ['F20', 'F1', 'F12', 'F7', 'F33', 'F18', 'F10', 'F17', 'F27', 'F26', 'F19', 'F32', 'F11', 'F16', 'F31', 'F21'], ['F3', 'F5', 'F14'], ['F20', 'F1', 'F12'], ['F4', 'F22', 'F24', 'F9', 'F15']]  Q  [[], ['F3', 'F5', 'F14'], ['F20', 'F1', 'F12'], []]\n",
      "[[], ['F23', 'F30', 'F15', 'F8', 'F12'], ['F14', 'F25', 'F7', 'F13', 'F16'], ['F19', 'F3', 'F26', 'F24', 'F22', 'F1', 'F2'], ['F14', 'F7', 'F13', 'F3', 'F26'], ['F22', 'F1', 'F18', 'F10'], ['F25', 'F16', 'F10', 'F24', 'F2']]  Q  [[], ['F14', 'F25'], ['F7', 'F13', 'F16', 'F19'], []]\n",
      "[[], ['F22', 'F20', 'F37', 'F10'], ['F16', 'F23', 'F24', 'F5', 'F19'], ['F4', 'F27', 'F1', 'F18'], ['F22', 'F20', 'F37', 'F10', 'F22', 'F37', 'F20', 'F10'], ['F3', 'F14', 'F14', 'F28', 'F29', 'F3', 'F9', 'F31', 'F12']]  Q  [[], ['F22', 'F20', 'F37', 'F10'], ['F16', 'F23', 'F24'], []]\n",
      "[[], [], ['F3', 'F1'], ['F11', 'F13', 'F5', 'F14'], ['F3', 'F4', 'F7', 'F12'], ['F8', 'F14', 'F1']]  Q  [[], ['F3', 'F4', 'F7', 'F12'], ['F10', 'F2', 'F11'], []]\n",
      "[[], [], ['F10', 'F8', 'F2', 'F9'], ['F10', 'F8', 'F2', 'F9'], ['F7', 'F1'], ['F4', 'F6']]  Q  [[], ['F10', 'F8', 'F9'], ['F2', 'F3', 'F7'], []]\n",
      "[[], ['F27', 'F15', 'F2', 'F7', 'F21'], ['F12', 'F33', 'F14', 'F30'], ['F27', 'F2', 'F15', 'F21'], ['F7', 'F5', 'F38', 'F24'], ['F6', 'F9']]  Q  [[], ['F27', 'F15', 'F2', 'F21'], ['F7', 'F9', 'F5'], []]\n",
      "[[], ['F11', 'F6', 'F1', 'F3', 'F11', 'F3', 'F6', 'F1'], ['F3', 'F8', 'F4', 'F10', 'F9'], ['F11', 'F6', 'F7', 'F2', 'F1'], ['F5']]  Q  [[], ['F11', 'F3', 'F6'], ['F1', 'F7', 'F8'], []]\n",
      "[[], ['F44', 'F8', 'F3', 'F27'], ['F44', 'F3', 'F8', 'F27'], ['F10', 'F40', 'F46', 'F28'], ['F33', 'F37'], ['F7', 'F12', 'F41', 'F18']]  Q  [[], ['F44', 'F8', 'F3', 'F27'], ['F10', 'F37', 'F40'], []]\n"
     ]
    }
   ],
   "source": [
    "letter = 'E'\n",
    "'''\n",
    "E. For 39 cases the format is:\n",
    "* 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.'\n",
    "* 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.'\n",
    "* 'Compare the direction of impact of the features: [2-5 top features].'\n",
    "* 'Summarize the direction of influence of the features [the next 3-4 features] with moderate impact on the prediction made for this test case.'\n",
    "* 'Provide a statement on the features with the least impact on the prediction made for this test case.'\n",
    "'''\n",
    "\n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-186461e0bb98b547.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The classifier is very uncertain about the correct label for the case given.  Regarding the classifier's decision, there is close to an even split on the probability of either of the possible labels is the correct label but the classifier chooses the label as C2. The prediction verdict above is attributed to the contributions of mainly the following features: F4, F11, F3, and F15, however, the lowest ranked features are F7, F19, and F1. Analysing the direction of influence of the features shows that there are ten positive and ten negative features.  Positive features such as F3, F15, F8, and F20 increase the response of the classifier in favour of the assigned label. Conversely, negative features such as F4, F11, F12, and F2 decrease the likelihood of C2 being the correct label given that their values support the alternative label, C1. The uncertainty concerning the label assignment can be due to the fact that the top negative features F4 and F11 have very high attributions shifting the classifier's verdict away from the C2 class.\",\n",
       " 'The model is confident in its prediction, as it predicted class C1 with a likelihood of 90.48% and hence, for the given case, there is a smaller chance of it being any other class label. F6 and F10 are deemed the most important features whereas on the other hand all the other features have moderate to minimal amounts of influence. Both F6 and F10 have the same direction of impact, increasing the odds of the predicted label, C1. While F4 and F1 are both encouraging the model to make a prediction of C1, the others F9, F12, and F8 is pushing the model towards a different label. Many features have moderately low impact on the final prediction, but the features F3, F8, and F2 are those with the smallest influence.',\n",
       " \"The most likely label for the given case is C1 since the predicted probability of C2 is only 34.27% and this means that the likelihood of C1 is 65.73%. The most relevant features that led to the C1 classification verdict are F5, F30, F26, F17, and F15. However, some of the features are deemed irrelevant to the above verdict and these include F3, F4, F13, and F27. Among the relevant features with some degree of impact, seven are shown to drive the model's class assignment towards the C2, while the remaining support the C1 prediction. Notable negative features swinging the prediction towards C2  are F5, F30, and F26, while the notable positive features are F17 and F15. The small uncertainty associated with the prediction decision for the given case could be attributed to the fact that all the three most important features are negative features whose values contradict assigning the label C1.\",\n",
       " \"The prediction likelihoods across the two classes are 15.35% for class C1 and 84.65% for C2, it can be concluded that C2 is the most probable class label for the given data instance. According to the attribution analysis conducted, the different input variables have varying degrees of influence on the model's decision here. The most influential set of variables is F18, F31, F19, F36, F35, F20, and F38, while the variables with the least influence include F37, F3, F25, F16, F33, and F6. The following or subsequent analysis performed to understand the direction of contribution of of the features  will focus on the most influential ones controlling the label selection here. Among the top influential features, F18, F31, F19, F36, and F38, only F18 and F31 have negative contributions, decreasing the probability that C2 is the correct label, and they strongly support labelling the case as C1 instead. Pushing the classification decision in favour of C2 are the positive variables such as F19, F36, and F38. The contributions of the remaining variables, including F35, F20, and F5, have moderate to low influence. All in all, the marginal uncertainty in the decision here is mainly due to the negative influences of F18, F31, F9, and F23, but the positive contributions of F19, F36, F5, F35, F20, and F38 drive the decision higher towards C2.\",\n",
       " 'The model is very confident that C3 is the most probable class for the given case, with a probability of 90.48% which means that the other labels are very unlikely. F12 and F1 are the most important variables with respect to this classification verdict while all other variables are shown to have a medium or low impact. Fortunately, the top variables, F12 and F1, have the same direction of influence, increasing the likelihood of C3. Furthermore, while F4 and F11 push the model to predict C3, those pushing for the assignment of a different label are F3, F8, and F2. Finally, many features have a fairly small impact on the final prediction made by the model here, but F7, F8, and F6 have the least impact.',\n",
       " \"The model predicted class C1 with an 81.98% prediction likelihood. F24 had the largest impact, followed by F23, F9, F18, F14, F10, F11, F2, F8, F21, F20, F27, F4, F12, F15, F19, F13, F16, F30, and finally, F29, which had the smallest non-zero impact. F24, the feature with the largest impact, contributed against the direction of the prediction, whereas F23, F9, F18, and F14 all contributed positively towards the prediction. Other features that had a negative influence on the prediction included F11 and F2, whereas F10 had a positive influence on the prediction. F22, F6, F1, and F5 are shown to have close to zero attribution in the model's prediction verdict in the given case.\",\n",
       " 'The classification output is C1, however, the classifier is somewhat unsure about this prediction decision because the corresponding predicted probability is only 55.19%. F11 is by far the most influential feature whereas F4, F6, and F17 have been recognised as having the biggest effect on prediction output here after F11. The combination of F11, F4, F6, F17, and F3 features has resulted in the classification choice being altered from C1 to C2. While F5, F2, and F16 all have a minor influence on the classification, F5 is the only one that has a positive impact on the C1 classification. In this case, many features had lower influence on the prediction, with F15, F8, F13, F19, and F10 having a marginal effect.',\n",
       " 'For the selected case, the model assigns the label C1. The prediction probability distribution across the classes C2 and C1 is 2.40% and 97.60%, respectively. The most important features considered for this prediction are F18, F3, F12, and F15, while on the other hand, the least relevant features with little contributions to the decision based on the analysis are F1, F8, F19, and F9. The top positive features Increasing the likelihood of the prediction being made are F18, F3, and F15. Pushing the prediction towards the alternative class C2, the top negative features are F12, F14, and F4. F17, F11, F13, F7, and F2 are some of the features that have a moderate impact on the classification decision in this case.',\n",
       " \"According to the classification algorithm, the best label for the given case is C2, because there is little to no chance that C1 is the correct label. Not all of the features are found to contribute to the label given here. The following significant features are ordered in order of their effect on the algorithm's output: F36, F8, F26, F35, F3, F12, F24, F9, F21, F6, F20, F5, F4, F25, F19, F27, F7, F23, F37, F31. F30, F33, and F13, on the other hand, are unimportant features since they have almost no influence. Among the most influential features F36, F8, F26, F35, and F3, F26 is considered the most negative, dragging the verdict in a different direction, while the others have positive contributions, increasing the possibility that C2 is correct in this case. F24 is recognised as a positive feature with modest effect, whereas F12 and F9 are identified as negative features. Given that the majority of the top five attributes have positive contributions, boosting the likelihood that C2 is the correct label, it is not unexpected that the algorithm is quite confident in the assigned label's accuracy.\",\n",
       " 'The model labels the case as C2 with fairly high confidence equal to 89.73%, whereas the likelihood of C1 is only 10.27%. Analysis shows that only 20 of the 46 input variables contribute to the prediction assertion above. The prediction judgement C2 is mainly based on the variables F17, F9, F18, and F19. F43, F23, F32, F33, F29, and F20 also contribute to the decision, however, their degree of influence is only moderate. According to the direction of influence analysis, F17, F19, F29, and F33 positively support the decision of the model to assign the label C2. However, F9, F23, F20, F18, F43, and F32 reduce the likelihood or chance that C2 is the true label for this particular test instance. The main variables with less influence on the above classification decision are F14, F31, F7, and F38.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train.filter(lambda x: x['narr_q_label'] == letter)['narration'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Always mentions the features that are asked,as well as extra. Maybe that is just the format of the questions such that they are asked linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-4b09f02380b36fdb.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-4b09f02380b36fdb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], ['F7', 'F1', 'F5', 'F3', 'F4', 'F6', 'F2'], ['F3', 'F1'], ['F7', 'F5', 'F4']]  Q  [[], ['F7', 'F1'], ['F5', 'F3', 'F4', 'F6'], ['F2']]\n",
      "[[], ['F8', 'F5', 'F7'], ['F9', 'F18', 'F16'], ['F4', 'F1', 'F13', 'F20'], []]  Q  [[], ['F5', 'F8', 'F7'], ['F9', 'F16', 'F18'], ['F4', 'F1', 'F13', 'F20']]\n",
      "[[], ['F1', 'F7', 'F3', 'F2', 'F8', 'F6', 'F4', 'F9', 'F5'], [], ['F1', 'F7', 'F3'], ['F3', 'F7', 'F1']]  Q  [[], ['F2', 'F1', 'F7', 'F3', 'F8'], ['F6', 'F4', 'F9'], ['F5']]\n",
      "[[], ['F14', 'F6', 'F5', 'F9'], ['F13', 'F12', 'F1', 'F8', 'F7', 'F6'], [], ['F9', 'F2', 'F5', 'F4', 'F10', 'F3', 'F11']]  Q  [[], ['F5', 'F9', 'F13', 'F2', 'F12'], ['F3', 'F11', 'F4'], ['F10', 'F8', 'F1']]\n",
      "[[], [], ['F8', 'F25', 'F9', 'F2', 'F27'], ['F8'], [], ['F8', 'F9', 'F25', 'F2', 'F27'], ['F7', 'F24'], ['F3', 'F31', 'F5', 'F32'], ['F10', 'F20', 'F28', 'F26']]  Q  [[], ['F8', 'F25', 'F9', 'F2', 'F27'], ['F7', 'F24', 'F3'], ['F31', 'F5', 'F32']]\n",
      "[[], ['F7', 'F21', 'F33', 'F8', 'F27', 'F27'], ['F7', 'F21', 'F33', 'F8'], ['F10', 'F37', 'F34', 'F23', 'F25', 'F17', 'F1', 'F14'], ['F13', 'F18', 'F35', 'F19'], ['F7', 'F21', 'F38', 'F32']]  Q  [[], ['F7', 'F21'], ['F33', 'F8', 'F27', 'F10'], ['F37', 'F1', 'F23', 'F14']]\n",
      "[[], [], ['F5', 'F20'], [], ['F28', 'F8', 'F3', 'F37'], ['F31', 'F17', 'F16', 'F6'], ['F39', 'F4', 'F22', 'F30', 'F14', 'F1']]  Q  [[], ['F5', 'F20'], ['F31', 'F28', 'F8', 'F17'], ['F16', 'F6', 'F2', 'F11']]\n",
      "[[], ['F13', 'F11'], ['F12', 'F8', 'F2', 'F7'], ['F1', 'F3', 'F10', 'F14']]  Q  [[], ['F13', 'F11'], ['F12', 'F8', 'F2', 'F7'], ['F1', 'F10', 'F3', 'F14']]\n",
      "[[], ['F29', 'F8', 'F10', 'F26', 'F23'], ['F29', 'F8', 'F10', 'F26'], ['F23', 'F4', 'F3', 'F7'], ['F25', 'F12', 'F16', 'F5'], ['F29', 'F8', 'F10'], []]  Q  [[], ['F29', 'F8'], ['F10', 'F23', 'F26', 'F4'], ['F7', 'F25', 'F3']]\n",
      "[[], ['F4', 'F7'], [], [], ['F3', 'F2', 'F1', 'F5', 'F6']]  Q  [[], ['F3', 'F2'], ['F6', 'F1', 'F5', 'F7'], ['F4']]\n",
      "[[], [], ['F5', 'F1'], ['F22', 'F6', 'F12', 'F29', 'F11'], ['F17', 'F35', 'F15', 'F14'], ['F9', 'F22', 'F6', 'F1'], [], ['F21', 'F36', 'F42', 'F13']]  Q  [[], ['F9', 'F1'], ['F22', 'F6', 'F12', 'F11'], ['F17', 'F29', 'F35']]\n",
      "[['F1', 'F6', 'F12', 'F4', 'F5'], [], [], [], ['F1', 'F12', 'F6', 'F4'], ['F1', 'F12', 'F4', 'F6'], ['F5', 'F11'], ['F10', 'F9', 'F3', 'F8'], ['F2', 'F7']]  Q  [[], ['F1', 'F6'], ['F12', 'F4', 'F5', 'F11'], ['F10', 'F9', 'F3', 'F8']]\n",
      "[[], ['F10', 'F8'], ['F9', 'F13', 'F1', 'F2'], ['F14', 'F15', 'F6', 'F12'], ['F7', 'F3', 'F5', 'F4', 'F4']]  Q  [[], ['F10', 'F8'], ['F9', 'F13', 'F1', 'F2'], ['F14', 'F6', 'F15', 'F12']]\n",
      "[[], ['F15', 'F13', 'F42', 'F21'], ['F10', 'F25', 'F11', 'F27'], ['F38', 'F41', 'F35'], ['F15', 'F42'], ['F13'], ['F13', 'F17', 'F11', 'F30', 'F12', 'F16']]  Q  [[], ['F15', 'F13', 'F42'], ['F21', 'F20', 'F17'], ['F10', 'F25', 'F11', 'F27']]\n",
      "[[], [], ['F9', 'F19', 'F1'], ['F8', 'F15', 'F13', 'F18', 'F4', 'F6', 'F12', 'F20', 'F7', 'F10', 'F5', 'F2', 'F16'], ['F14', 'F17', 'F11', 'F3'], [], ['F8', 'F15', 'F9', 'F19', 'F1', 'F13'], []]  Q  [[], ['F9', 'F19', 'F1'], ['F8', 'F15', 'F13'], ['F18', 'F4', 'F6', 'F12']]\n",
      "[[], ['F9', 'F3', 'F1', 'F4', 'F8'], ['F3', 'F9'], ['F2', 'F6'], ['F3', 'F6', 'F9', 'F2'], ['F1', 'F7', 'F10']]  Q  [[], ['F9', 'F3'], ['F1', 'F7', 'F10', 'F5'], ['F2', 'F6', 'F4', 'F8']]\n",
      "[[], [], ['F4', 'F8'], ['F1', 'F5', 'F3', 'F2', 'F1', 'F8', 'F3', 'F2', 'F5'], ['F4', 'F6', 'F7']]  Q  [[], ['F4', 'F8'], ['F1', 'F5', 'F3', 'F2'], ['F7', 'F6']]\n",
      "[[], ['F3', 'F6', 'F8'], ['F9', 'F2', 'F5', 'F4', 'F1'], [], []]  Q  [[], ['F3', 'F6', 'F8', 'F9'], ['F7', 'F2', 'F5'], ['F4', 'F1']]\n",
      "[[], ['F8', 'F6'], ['F4', 'F3', 'F7', 'F1', 'F1', 'F3', 'F4', 'F7'], ['F2', 'F5', 'F8']]  Q  [[], ['F8', 'F6'], ['F1', 'F7', 'F3', 'F4'], ['F2', 'F5']]\n",
      "[[], ['F16', 'F6', 'F39', 'F35', 'F32'], ['F32', 'F16', 'F6', 'F39', 'F35'], ['F3', 'F33', 'F10', 'F21', 'F22', 'F19', 'F24', 'F4'], ['F1', 'F27', 'F30', 'F9'], ['F16', 'F39', 'F6']]  Q  [[], ['F16', 'F6'], ['F39', 'F35', 'F32', 'F3'], ['F33', 'F24', 'F21', 'F4']]\n",
      "[[], ['F6', 'F13'], ['F10', 'F14', 'F4', 'F8'], ['F5', 'F12', 'F15', 'F2']]  Q  [[], ['F6', 'F13'], ['F10', 'F14', 'F4', 'F8'], ['F5', 'F15', 'F12', 'F2']]\n",
      "[[], [], ['F38', 'F59', 'F47', 'F27'], ['F38', 'F27', 'F52', 'F59'], ['F47', 'F16', 'F75', 'F13', 'F32'], ['F17', 'F54', 'F6'], []]  Q  [[], ['F38', 'F59', 'F47', 'F27'], ['F16', 'F52', 'F75'], ['F13', 'F68', 'F32']]\n",
      "[[], ['F5', 'F1', 'F3', 'F7', 'F6', 'F4', 'F2'], ['F1', 'F7'], ['F5', 'F3', 'F6', 'F4', 'F2']]  Q  [[], ['F5', 'F1'], ['F3', 'F7', 'F6', 'F4'], ['F2']]\n",
      "[[], ['F1', 'F16', 'F18', 'F18', 'F16', 'F1'], ['F1', 'F5', 'F3', 'F20', 'F2', 'F8'], ['F7', 'F3', 'F15', 'F12', 'F11', 'F14', 'F9']]  Q  [[], ['F18', 'F16', 'F1'], ['F5', 'F8', 'F2'], ['F7', 'F3', 'F15', 'F12']]\n",
      "[[], [], ['F16', 'F2', 'F9', 'F10'], ['F16', 'F9', 'F10'], [], ['F2', 'F3', 'F12'], []]  Q  [[], ['F16', 'F2', 'F10', 'F9'], ['F12', 'F3', 'F11'], ['F7', 'F6', 'F4']]\n",
      "[[], [], ['F29', 'F1'], ['F8', 'F27', 'F7', 'F13', 'F22'], ['F18', 'F36', 'F23', 'F6'], ['F31', 'F22', 'F27', 'F1'], ['F41', 'F32', 'F39', 'F40']]  Q  [[], ['F31', 'F1'], ['F22', 'F27', 'F13', 'F8'], ['F18', 'F7', 'F36']]\n",
      "[[], ['F4', 'F7', 'F9', 'F1'], ['F3', 'F8'], ['F11', 'F5'], ['F12', 'F6'], ['F10']]  Q  [[], ['F4', 'F7', 'F9', 'F1'], ['F3', 'F11', 'F8'], ['F12', 'F5', 'F6']]\n",
      "[[], ['F3', 'F4', 'F7'], ['F8', 'F5', 'F1', 'F2'], [], ['F3', 'F4', 'F7', 'F6', 'F9']]  Q  [[], ['F3', 'F4', 'F7', 'F8', 'F6'], ['F5', 'F1', 'F9'], ['F2']]\n",
      "[[], ['F14', 'F4', 'F6', 'F9'], ['F10', 'F2'], [], ['F10', 'F6', 'F13', 'F2'], ['F6', 'F4', 'F9', 'F11']]  Q  [[], ['F14', 'F6', 'F9', 'F4', 'F11'], ['F3', 'F1', 'F12'], ['F7', 'F13', 'F5']]\n",
      "[[], ['F6', 'F11', 'F8', 'F9'], ['F10', 'F3'], ['F5', 'F12'], ['F1', 'F4', 'F7']]  Q  [[], ['F6', 'F11', 'F8', 'F9'], ['F10', 'F5', 'F3'], ['F4', 'F12', 'F1']]\n",
      "[[], ['F4', 'F5', 'F1', 'F7', 'F4', 'F7'], ['F8', 'F6', 'F2'], ['F3']]  Q  [[], ['F4', 'F5', 'F1', 'F7'], ['F2', 'F8', 'F6'], ['F3']]\n",
      "[[], [], ['F2', 'F6', 'F3'], ['F8', 'F5'], ['F6', 'F1', 'F9', 'F2'], ['F3', 'F7', 'F10']]  Q  [[], ['F2', 'F6'], ['F3', 'F7', 'F10', 'F4'], ['F1', 'F9', 'F8', 'F5']]\n",
      "[[], [], [], [], ['F9', 'F10', 'F1', 'F7', 'F2'], ['F9', 'F7', 'F2', 'F10', 'F1'], ['F5', 'F6', 'F11', 'F12', 'F3', 'F4', 'F8'], ['F10', 'F1', 'F11', 'F8'], []]  Q  [[], ['F9', 'F10'], ['F1', 'F7', 'F2', 'F6'], ['F5', 'F11', 'F3', 'F12']]\n",
      "[[], [], ['F34', 'F29'], ['F18', 'F3', 'F14', 'F37', 'F23'], ['F4', 'F39', 'F27', 'F21'], ['F38', 'F23', 'F3', 'F29'], ['F7', 'F16', 'F41', 'F12', 'F42', 'F10']]  Q  [[], ['F38', 'F29'], ['F23', 'F3', 'F37', 'F18'], ['F4', 'F14', 'F39']]\n",
      "[[], ['F1', 'F4'], ['F5', 'F7', 'F8', 'F9', 'F6', 'F3', 'F2'], [], ['F4', 'F5', 'F7'], ['F4', 'F5', 'F7']]  Q  [[], ['F1', 'F4', 'F5', 'F7', 'F8'], ['F9', 'F6', 'F3'], ['F2']]\n",
      "[[], [], ['F26', 'F36', 'F18', 'F34'], ['F26', 'F36'], ['F34', 'F18', 'F14'], ['F8', 'F19', 'F16', 'F39', 'F20', 'F11', 'F33', 'F1'], ['F41', 'F37', 'F30'], ['F26', 'F36', 'F34']]  Q  [[], ['F26', 'F36', 'F34'], ['F18', 'F14', 'F8'], ['F19', 'F16', 'F20', 'F11']]\n",
      "[[], ['F1', 'F9', 'F4', 'F5', 'F10', 'F2'], ['F9', 'F14', 'F10', 'F2'], ['F9', 'F4', 'F15', 'F5']]  Q  [[], ['F1', 'F9', 'F4', 'F5', 'F15'], ['F12', 'F7', 'F11'], ['F13', 'F14', 'F8']]\n",
      "[[], ['F3', 'F4', 'F2', 'F6'], ['F4', 'F6'], ['F3', 'F2', 'F5', 'F1'], []]  Q  [[], ['F3', 'F4'], ['F2', 'F5', 'F1', 'F6'], []]\n",
      "[[], ['F2', 'F3', 'F5'], ['F1', 'F6', 'F4'], ['F2']]  Q  [[], ['F2', 'F3', 'F5'], ['F1', 'F6', 'F4'], []]\n",
      "[[], [], ['F2', 'F16', 'F11'], ['F12', 'F9', 'F10'], ['F8', 'F14', 'F15', 'F3'], ['F6', 'F1'], []]  Q  [[], ['F2', 'F16', 'F11'], ['F12', 'F10', 'F9'], ['F8', 'F14', 'F15', 'F3']]\n",
      "[[], [], ['F1', 'F1', 'F7', 'F5', 'F10', 'F9'], ['F1', 'F10', 'F9', 'F7', 'F5'], ['F12', 'F6', 'F2', 'F11', 'F3', 'F8', 'F4'], ['F7', 'F5', 'F2', 'F4']]  Q  [[], ['F1', 'F7'], ['F5', 'F10', 'F9', 'F6'], ['F12', 'F2', 'F3', 'F11']]\n",
      "[[], ['F1', 'F2', 'F3', 'F4', 'F1', 'F4'], ['F7', 'F5', 'F6'], ['F8']]  Q  [[], ['F1', 'F2', 'F3', 'F4'], ['F6', 'F7', 'F5'], ['F8']]\n",
      "[[], [], ['F2', 'F18', 'F19'], ['F11', 'F14', 'F8', 'F4', 'F7', 'F16', 'F13', 'F20', 'F9', 'F17', 'F12', 'F6', 'F5', 'F10', 'F1', 'F3', 'F15'], [], ['F11', 'F14', 'F8', 'F18', 'F2', 'F19'], []]  Q  [[], ['F2', 'F18', 'F19'], ['F11', 'F14', 'F8'], ['F4', 'F7', 'F16', 'F13']]\n",
      "[[], ['F4', 'F3'], ['F9', 'F8', 'F5', 'F1', 'F2', 'F7', 'F6'], ['F3', 'F9', 'F8'], []]  Q  [[], ['F4', 'F3', 'F9', 'F8', 'F5'], ['F1', 'F2', 'F7'], ['F6']]\n"
     ]
    }
   ],
   "source": [
    "letter = 'F'\n",
    "'''\n",
    "F. For 44 cases the format is:\n",
    "* 'Provide a statement summarizing the prediction made for the test case.'\n",
    "* 'For the current test instance, describe the direction of influence of the following features: [2-5 top features]'\n",
    "* 'Compare and contrast the impact of the following features [the next 3-4 features] on the model’s prediction of [C1/C2].'\n",
    "* 'Describe the degree of impact of the following features: [the next 0-4 features]?' (usually 4 unless there are not enough features)\n",
    "'''\n",
    "\n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-4b09f02380b36fdb.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The classifier trained on this prediction problem assigns a label to a given case based on the information supplied. The class assigned by the classifier to the case under consideration is C1. The probability that C2 is the correct label is around 25.28%; therefore, it is less likely to be the true label. The above classification decision is mainly based on the influence of the features F7, F1, F5, F3, F4, F6, and F2. Of the above stated features, F3 and F1 are the ones shown to have a negative impact, decreasing the odds of C1 being the accurate label for the given case and encouraging the classifier to select C2 instead. Finally, it can be concluded that there is a moderately high level of confidence in the assigned label, which can be attributed to the strong positive contribution of F7 combined with other positive features such as F5 and F4.',\n",
       " 'According to the model, C1 has a prediction probability of 99.45 percent, C2 has a prediction probability of 0.47 percent, C4 has a prediction probability of 0.04 percent, and C3 has a prediction probability of 0.05 percent, therefore, the most likely class is C1. F8 and F5 positively influence the above-mentioned label decision in favour of C1, but F7 has the opposite effect, favouring a different label. F9 and F18 both have a similar negative impact on the C1 prediction, whereas F16 has a positive impact. In this case, F4, F1, F13, and F20 have little influence on the labelling result. All in all, the model is confident in its assignment of the C1 class as shown by the predicted probabilities across the classes.',\n",
       " \"This case's label has a 70.83 percent chance of being C3 and per the predicted likelihoods across the alternative labels, C1 has a 29.71 percent chance of being the correct label, however, the model is certain that C2 is not the true label. The most important variables are F1, F7, F3, and F2, whereas the remaining influential variables are listed in order of the magnitude of their contributions: F8, F6, F4, F9, and F5. Three of the nine variables have values that push towards the prediction of label C1 while the other attributes are referred to as positive since their values inspire the prediction of class C3. F1, F7, and F3 are the three attributes that have a negative influence on the prediction judgement, pushing it away from C3 towards the label C1. Finally, it is essential to highlight that the cumulative effect of positive attributes is greater than that of negative attributes, F3, F7, and F1.\",\n",
       " 'Because the confidence level associated with the other class, C1, is just 2.29%, the model predicts that the given example is likely C2 and to be specific, the model is quite certain that the right label for the given case is C2. All the features are shown to have some degree of influence on the decision above, with F14 and F6 being the least relevant features, while F5 and F9 are the top features. From the analysis performed to understand how each feature contributes to the above prediction assertion, only  the features F13, F12, F1, F8, F7, and F6, have negative influences, shifting the prediction verdict towards C1.  The remaining features all contribute positively, strongly shifting the prediction towards the assigned label which could explain the prediction confidence level associated with label C2. The most positive features are F9, F2, and F5 with stronger push in favour of the output label and they are supported by other positive features such as F4, F10, F3, and F11 have a moderate degree of influence.',\n",
       " \"The given instance was labelled as C1 by the model based on the values of its features. The model is about 79.64% certain about this prediction decision, hence, there is a slight chance that the label could be C2. Among the different features, the ones with the most impact on the model are F8, F25, F9, F2, and F27. The most negative feature is F8, and it is significantly pushing the narrative toward the prediction of C2. From this, it is foreseeable that there is a chance that the true label could be C2 which is about 20.36%. The influence of F8 and F9 is somewhat counterbalanced by the values of the features F25, F2, and F27. Other attributes that shift the decision in favour of C2 are F7 and F24. F3 shifts the decision further in the direction of C1 and in addition, F31 supports the model's prediction while the values of F5 and F32 of the given test case contradict the model's decision, decreasing the likelihood of C1. Among the features not relevant to this prediction decision for this case are F10, F20, F28, and F26.\",\n",
       " \"The algorithm identifies the provided data or case as C1 with a greater level of certainty since the prediction probability of class C2 is just 0.07 percent as a result, C2 is less likely than C1. The influence of input features such as F7, F21, F33, F8, and F27 is mostly responsible for the classification verdict above with only F27  having a negative influence among them, slightly pulling the decision in favour of C2. F7, F21, F33, and F8, on the other hand, make considerable positive contributions in favour of assigning C1 to the data. F10, F37, F34, F23, F25, F17, F1, and F14 are some more features that have a modest effect on the algorithm's decision. But, not all features are demonstrated to influence the classification decision either negatively or positively to the aforementioned classification outcome and in reality, a number of these are demonstrated to be irrelevant for determining the suitable label for this case and these include F13, F18, F35, and F19. All in all, the most important features for this classification instance are F7 and F21, whereas F38 and F32 are the least important.  \",\n",
       " 'The predicted probability of class C2 is 12.81% and that of class C1 is 87.19%. Therefore, the label chosen by the model is C1, which is the most probable class. The top two features with significant influence on the prediction verdict above are F5 and F20. These features have positive attributions, shifting the decision higher in support of label C1. Other positive features are F28, F8, F3, and F37. Decreasing the likelihood of the assigned label are the negative features such as F31, F17, F16, and F6. Finally, the values of features such as F39, F4, F22, F30, F14, and F1 are considered irrelevant to the prediction decision above.',\n",
       " \"The algorithm's forecast for the data instance under consideration is C2, and the decision's confidence level is about 91.36 percent. We can observe from the plot that the variables F13 and F11 are moving the prediction judgement towards the other label, C1. The F12, F8, F2, and F7, on the other hand, have values that have a favourable influence, pushing the data classification choice towards label C2. While F1 and F3 contradict the prediction, F10 and F14 have values that confirm the algorithm's prediction output verdict.\",\n",
       " \"The classification algorithm classifies the given case as C1 with a confidence level equal to 99.99%, suggesting that there is little chance that the C2 label could be the true label. The classification confidence level can be attributed to the influence and contributions of the features F29, F8, F10, F26, and F23. Positively supporting the model's decision are values of F29, F8, F10, and F26. On the contrary, the values of F23, F4, F3, and F7 are shifting the model towards producing the C2 label, which results in a marginal decrease in the certainty associated with the C1 label. The other positively supported features further improving the odds in favour of C1 include F25, F12, F16, and F5. Overall, it is not farfetched to accept that C1 is the correct label for the case under consideration since the strong positive influences of F29, F8, and F10 far outweigh the influence of any of the other input features. In other words, as mentioned above, there is only a small chance that the true label is not C1 considering the attributions of the top influential input features.\",\n",
       " \"The ML model or algorithm employed here predicted the class C2 with 100.0% confidence level, clearly implying that the case belongs under the class C2 and not C1 since its associated likelihood is 0.0%. Analysis of the contributions of the features indicated that only features F4 and F7 have negative influence, shifting the classification decision away from C2. However, these features are shown to be the least significant ones when it comes to assigning a label to the case under consideration. Therefore, it is a little surprising to see that the model's confidence level is very high with respect to the prediction made here. Among the remaining positive features, F3, and F2, have the strongest impact or influence, increasing the odds of C2 being the label for the case under consideration and the least positive features are F1, F5, and F6.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train.filter(lambda x: x['narr_q_label'] == letter)['narration'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G: Similar to F, most important, positive, negative, then minor features are mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b569de9575aedb82.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b569de9575aedb82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['F7', 'F9', 'F3'], ['F4', 'F6', 'F8', 'F10', 'F1', 'F2', 'F5'], ['F7', 'F3', 'F9'], ['F9', 'F4', 'F6', 'F10', 'F1', 'F8'], ['F2', 'F5', 'F5']]  Q  [[], ['F7', 'F9'], ['F3', 'F4', 'F6', 'F8'], ['F10', 'F1', 'F2', 'F5']]\n",
      "[['F8', 'F10', 'F6', 'F9', 'F1'], ['F1', 'F9'], ['F1', 'F9', 'F3', 'F2'], ['F8', 'F10', 'F6'], ['F5', 'F7', 'F11', 'F4'], ['F8', 'F10', 'F6', 'F11', 'F5']]  Q  [[], ['F8', 'F10', 'F6', 'F1'], ['F9', 'F3', 'F2'], ['F5', 'F7', 'F4']]\n",
      "[['F9', 'F2'], ['F6', 'F8', 'F3', 'F4', 'F5', 'F7', 'F1'], ['F9', 'F2', 'F6', 'F8'], ['F3', 'F5', 'F4'], ['F7', 'F1', 'F1', 'F7']]  Q  [[], ['F9', 'F2', 'F6', 'F8'], ['F3', 'F5', 'F4'], ['F7', 'F1']]\n",
      "[['F5', 'F8', 'F6', 'F2'], [], ['F2', 'F6', 'F5', 'F8'], ['F2', 'F6', 'F3', 'F9'], ['F1', 'F7', 'F4', 'F5']]  Q  [[], ['F2', 'F6', 'F5'], ['F8', 'F3', 'F9'], ['F1', 'F7', 'F4']]\n",
      "[[], ['F11', 'F4', 'F7', 'F9'], ['F10', 'F2', 'F5'], ['F9', 'F8', 'F2', 'F5'], ['F4', 'F11', 'F7']]  Q  [[], ['F11', 'F4', 'F7', 'F9'], ['F6', 'F8', 'F1'], ['F3', 'F10', 'F2']]\n",
      "[[], [], [], ['F8', 'F1', 'F7', 'F5', 'F3', 'F11', 'F2'], ['F8', 'F1', 'F7'], ['F5'], ['F5', 'F10', 'F3', 'F11'], ['F8', 'F1', 'F7', 'F5'], ['F2', 'F6', 'F4', 'F9'], ['F2', 'F9', 'F6', 'F4']]  Q  [[], ['F8', 'F1', 'F7', 'F5'], ['F10', 'F3', 'F11'], ['F2', 'F6', 'F9']]\n",
      "[[], [], [], ['F6', 'F26', 'F32', 'F42', 'F43', 'F25'], ['F38', 'F24', 'F14', 'F28', 'F33'], [], ['F6', 'F26', 'F32', 'F42', 'F4', 'F7', 'F16', 'F21'], ['F43', 'F29', 'F25', 'F13', 'F39', 'F5', 'F41', 'F12']]  Q  [[], ['F6', 'F26', 'F32', 'F42', 'F25'], ['F43', 'F29', 'F7'], ['F39', 'F5', 'F13']]\n",
      "[[], ['F12', 'F1', 'F17', 'F28'], ['F5', 'F7', 'F10', 'F27', 'F21', 'F18', 'F2', 'F23', 'F24', 'F29', 'F11', 'F6'], ['F12', 'F1'], ['F17', 'F28', 'F5', 'F7'], ['F10', 'F27', 'F21', 'F18'], ['F10', 'F27', 'F21', 'F18'], ['F22', 'F25', 'F30']]  Q  [[], ['F12', 'F1'], ['F17', 'F28', 'F5', 'F7'], ['F10', 'F27', 'F21', 'F18']]\n",
      "[[], [], ['F9', 'F8', 'F14', 'F7', 'F13', 'F6', 'F11'], ['F9', 'F7', 'F13', 'F11'], ['F8', 'F14', 'F4', 'F12', 'F2', 'F1']]  Q  [[], ['F9', 'F8', 'F14', 'F7', 'F4'], ['F12', 'F2', 'F1'], ['F10', 'F3', 'F5']]\n",
      "[[], ['F2', 'F7', 'F4', 'F3', 'F8'], ['F2', 'F7', 'F4', 'F8', 'F3'], ['F10', 'F9', 'F5', 'F6', 'F2', 'F7', 'F4'], ['F2', 'F7', 'F4', 'F1']]  Q  [[], ['F2', 'F7', 'F4', 'F8'], ['F3', 'F5', 'F6'], ['F1', 'F9', 'F10']]\n",
      "[[], ['F1', 'F8', 'F7', 'F3'], ['F4', 'F9', 'F6', 'F5', 'F2'], [], ['F1', 'F6', 'F5', 'F8', 'F4', 'F9', 'F2', 'F7', 'F3']]  Q  [[], ['F1', 'F4'], ['F9', 'F6', 'F5', 'F2'], ['F8', 'F7', 'F3']]\n",
      "[[], [], ['F3', 'F1', 'F2', 'F5', 'F7'], ['F1', 'F2'], ['F6', 'F8', 'F9', 'F4'], ['F4', 'F6', 'F8', 'F9'], ['F10', 'F12', 'F11']]  Q  [[], ['F1', 'F2', 'F3', 'F5', 'F7'], ['F6', 'F8', 'F4'], ['F9', 'F10', 'F11']]\n",
      "[[], [], [], [], [], ['F4', 'F3', 'F1', 'F5', 'F6', 'F2'], ['F4', 'F5'], ['F3', 'F1', 'F6', 'F2']]  Q  [[], ['F4', 'F3', 'F1'], ['F5', 'F6', 'F2'], []]\n",
      "[[], ['F4', 'F1', 'F5', 'F6'], ['F4', 'F5', 'F1', 'F6'], ['F3', 'F7', 'F2']]  Q  [[], ['F4', 'F1', 'F5'], ['F6', 'F3', 'F7'], ['F2']]\n",
      "[[], ['F1', 'F8', 'F15', 'F10'], ['F11', 'F17', 'F5', 'F4'], ['F9', 'F6', 'F2', 'F14'], []]  Q  [[], ['F8', 'F1', 'F15'], ['F10', 'F11', 'F17'], ['F5', 'F9', 'F6', 'F4']]\n",
      "[[], [], ['F10', 'F14', 'F9', 'F7'], ['F5', 'F3', 'F12', 'F8', 'F6', 'F4', 'F13', 'F1']]  Q  [[], ['F10', 'F5', 'F3', 'F14', 'F12'], ['F8', 'F6', 'F1'], ['F4', 'F13', 'F11']]\n",
      "[[], ['F2', 'F11', 'F9', 'F1'], ['F8', 'F3', 'F5'], ['F1', 'F10', 'F3', 'F5'], [], ['F11', 'F2', 'F9']]  Q  [[], ['F2', 'F11', 'F9', 'F1'], ['F6', 'F10', 'F7'], ['F4', 'F8', 'F3']]\n",
      "[[], ['F1', 'F7', 'F11', 'F9'], ['F5', 'F6', 'F8'], ['F7', 'F1', 'F9'], ['F11', 'F10', 'F6', 'F8']]  Q  [[], ['F1', 'F7', 'F9', 'F11'], ['F2', 'F10', 'F3'], ['F4', 'F5', 'F6']]\n",
      "[[], [], ['F13', 'F2', 'F3', 'F11', 'F8', 'F9', 'F4', 'F10'], ['F5', 'F15', 'F16'], [], ['F5', 'F15', 'F16', 'F13', 'F3', 'F11', 'F2']]  Q  [[], ['F13', 'F3', 'F2'], ['F11', 'F8', 'F9'], ['F4', 'F10', 'F17', 'F5']]\n",
      "[[], ['F8', 'F1', 'F15', 'F14', 'F4', 'F13', 'F7', 'F3', 'F6', 'F11', 'F2', 'F5', 'F12', 'F9', 'F10'], ['F8', 'F3', 'F6', 'F10', 'F1'], ['F15', 'F14', 'F4', 'F13', 'F7', 'F11']]  Q  [[], ['F8', 'F1', 'F15', 'F14'], ['F4', 'F13', 'F7'], ['F3', 'F6', 'F11']]\n",
      "[[], ['F39', 'F13', 'F24', 'F38', 'F22', 'F26'], [], ['F40', 'F33', 'F11', 'F8'], ['F39', 'F13', 'F24', 'F38', 'F18'], ['F22', 'F26', 'F36', 'F29', 'F4', 'F42', 'F27', 'F20'], ['F39', 'F13']]  Q  [[], ['F39', 'F13', 'F24', 'F38', 'F22'], ['F26', 'F36', 'F18'], ['F29', 'F42', 'F4']]\n",
      "[[], ['F10', 'F6', 'F9', 'F5'], ['F7', 'F11', 'F1'], [], ['F10', 'F6', 'F5', 'F2', 'F12', 'F13', 'F9', 'F4', 'F8']]  Q  [[], ['F10', 'F6'], ['F9', 'F5', 'F13', 'F4'], ['F2', 'F12', 'F3']]\n",
      "[[], ['F3', 'F9', 'F4', 'F5'], ['F5'], ['F5', 'F10', 'F6', 'F8'], ['F3', 'F9', 'F4'], ['F1', 'F2', 'F11', 'F7'], ['F3', 'F9', 'F4', 'F1']]  Q  [[], ['F3', 'F9', 'F4', 'F5'], ['F10', 'F6', 'F8'], ['F1', 'F2', 'F11']]\n",
      "[[], ['F10', 'F11', 'F5', 'F18'], ['F12', 'F14', 'F1', 'F2'], ['F7', 'F13', 'F3', 'F15'], []]  Q  [[], ['F11', 'F5', 'F10', 'F18', 'F2'], ['F12', 'F7', 'F15'], ['F13', 'F14', 'F3']]\n",
      "[[], [], ['F7', 'F5', 'F11'], ['F7', 'F5', 'F11', 'F1', 'F12', 'F6'], ['F7', 'F5', 'F11', 'F12', 'F10'], ['F1', 'F6', 'F3', 'F4', 'F9'], []]  Q  [[], ['F7', 'F5'], ['F11', 'F1', 'F12', 'F6'], ['F3', 'F4', 'F10']]\n",
      "[[], ['F1', 'F3', 'F11', 'F4', 'F10', 'F9', 'F12'], ['F1', 'F11', 'F4', 'F8', 'F6', 'F2', 'F5'], ['F13', 'F3', 'F7']]  Q  [[], ['F1', 'F11'], ['F3', 'F4', 'F6', 'F7'], ['F8', 'F2', 'F5']]\n",
      "[[], [], [], ['F11', 'F7', 'F1'], ['F9', 'F12', 'F8', 'F11', 'F7', 'F1'], ['F11', 'F7', 'F1', 'F12', 'F10'], ['F9', 'F8', 'F3', 'F6', 'F5'], []]  Q  [[], ['F11', 'F7'], ['F1', 'F9', 'F12', 'F8'], ['F3', 'F6', 'F10']]\n",
      "[[], [], ['F4', 'F5', 'F3', 'F6'], ['F4', 'F3', 'F9', 'F11'], ['F5', 'F6', 'F1', 'F2'], ['F8', 'F12', 'F10', 'F7'], ['F1', 'F10', 'F2', 'F7'], []]  Q  [[], ['F4', 'F5', 'F3'], ['F6', 'F9', 'F11'], ['F8', 'F12', 'F1', 'F10']]\n",
      "[[], ['F5', 'F4', 'F6', 'F3'], ['F5', 'F3', 'F4'], ['F6', 'F1'], ['F2']]  Q  [[], ['F5', 'F4'], ['F3', 'F6', 'F1', 'F2'], []]\n",
      "[[], [], ['F13', 'F11', 'F3', 'F9'], ['F12', 'F7', 'F6', 'F8'], ['F2', 'F10', 'F1', 'F5', 'F4']]  Q  [[], ['F12', 'F7', 'F6', 'F8'], ['F13', 'F11', 'F2'], ['F10', 'F3', 'F4']]\n",
      "[[], ['F11'], ['F4', 'F6', 'F10', 'F2', 'F7'], ['F7', 'F4'], ['F8', 'F5', 'F12']]  Q  [[], ['F11', 'F4'], ['F6', 'F10', 'F2', 'F7'], ['F9', 'F3', 'F13']]\n",
      "[[], ['F4', 'F6', 'F11', 'F7'], ['F8', 'F2', 'F5'], ['F9', 'F10', 'F1', 'F3'], ['F6', 'F4', 'F7']]  Q  [[], ['F4', 'F6'], ['F7', 'F11', 'F10', 'F2'], ['F8', 'F9', 'F1']]\n",
      "[[], ['F7', 'F10', 'F9', 'F1'], ['F5', 'F3', 'F13'], [], ['F7', 'F10', 'F1', 'F12', 'F4'], ['F9', 'F11', 'F2']]  Q  [[], ['F7', 'F10'], ['F9', 'F1', 'F4', 'F11'], ['F12', 'F8', 'F6']]\n",
      "[[], ['F14', 'F8', 'F1', 'F12', 'F4'], ['F16', 'F5', 'F7'], ['F14', 'F8', 'F1', 'F2', 'F6', 'F11', 'F5'], ['F12', 'F4', 'F3']]  Q  [[], ['F14', 'F8'], ['F1', 'F12', 'F4', 'F2'], ['F6', 'F11', 'F3', 'F9']]\n",
      "[[], [], ['F11', 'F5', 'F6', 'F12', 'F10'], ['F11', 'F5', 'F12'], ['F6', 'F10'], ['F3', 'F2', 'F7'], ['F1', 'F8', 'F13', 'F4'], ['F11', 'F5']]  Q  [[], ['F11', 'F5', 'F6', 'F12'], ['F10', 'F1', 'F8'], ['F13', 'F4', 'F3']]\n",
      "[[], ['F7', 'F5', 'F6', 'F1'], ['F8', 'F3', 'F2', 'F9', 'F4'], [], ['F7', 'F2', 'F9', 'F5', 'F8', 'F3', 'F4', 'F6', 'F1']]  Q  [[], ['F7', 'F8'], ['F3', 'F2', 'F9', 'F4'], ['F5', 'F6', 'F1']]\n",
      "[[], ['F2', 'F5', 'F8', 'F7', 'F10', 'F9', 'F4', 'F11', 'F1', 'F12', 'F6', 'F3'], ['F2', 'F5', 'F8', 'F7', 'F10'], ['F9'], ['F4', 'F11'], ['F1', 'F12', 'F3']]  Q  [[], ['F2', 'F5', 'F8', 'F7', 'F10'], ['F9', 'F4', 'F11'], ['F1', 'F12', 'F3']]\n",
      "[[], ['F1', 'F3', 'F4', 'F7', 'F2', 'F6', 'F5', 'F1', 'F5'], ['F3', 'F2', 'F1', 'F4', 'F7']]  Q  [[], ['F1', 'F3'], ['F4', 'F7', 'F2', 'F6'], ['F5']]\n",
      "[['F9', 'F1', 'F5', 'F8'], [], ['F9', 'F1', 'F5', 'F8'], ['F9', 'F1', 'F7', 'F4'], ['F6', 'F3', 'F2', 'F5']]  Q  [[], ['F9', 'F1', 'F5'], ['F8', 'F7', 'F4'], ['F6', 'F3', 'F2']]\n"
     ]
    }
   ],
   "source": [
    "letter = 'G'\n",
    "'''\n",
    "G. For 39 cases the format is:\n",
    "* 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.'\n",
    "* 'Summarize the direction of influence of the features [2-5 top features] on the prediction made for this test case.'\n",
    "* 'Compare the direction of impact of the features: [the next 3-4 features].'\n",
    "* 'Describe the degree of impact of the following features:[the next 0-4 features]'\n",
    "'''\n",
    "\n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b569de9575aedb82.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The classifier is 69.02% certain that the given case is under the class label C1, implying that the likelihood of C2 is only 30.98%. Analysis performed to understand the contribution of each input feature revealed that: F7, F9, and F3 are the most influential features when assigning a label to the given case. Features F4, F6, F8, and F10 have moderate contributions, whereas the F1, F2 and F5 have lower relevance to the final classification decision. F7 and F3 push the class assignment towards C1, whereas F9 does the opposite, decreasing the likelihood of C1. Similar to F9, F4, and F6 negatively impact the C1 classification, whereas F10, F1, and F8 positively push the decision towards the C1 class. Features F2, and F5 all have little impact on the final decision, with F5 having the least impact.',\n",
       " \"According to the machine learning model, it is more likely that the case's label is C2, with a certainty of 100.0%, and this prediction decision is mainly based on the effects of the following features: F8, F10, F6, F9, and F1 on the model. Apart from F1 and F9, all the other variables mentioned above have a strong positive influence, improving the odds of the prediction class, C2. Together with F1 and F9, the values of variables F3 and F2 indicate that C1 could be the correct label instead. Unlike the top positive variables, F8, F10, and F6, each of these negative variables has a moderate contribution to the final decision. The features F5, F7, F11, and F4 are shown to have made minor contributions to the model's decision in this case. In summary, with only the positive contributions from F8, F10, F6, F11, and F5, the model is very certain of the classification output as indicated by the predicted probabilities across C2 and C1.\",\n",
       " 'The given case is likely C2 with a confidence level of 87.50% judged based on the values of the input features supplied to the classifier and according to the attributions analysis, F9 and F2 have a high degree of impact. F6, F8, F3, F4, and F5 have a moderate degree of impact while on the contrary F7 and F1 have little impact. Examining further, the values of F9, F2, F6, and F8 all have a positive influence on the classifier supporting the label assignment decision for the given test case. F3 and F5 are also positively supporting features, whereas F4 has a negative influence on the final classification. Finally, F7 and F1 both have very little contributions, though F1 has significantly less than even F7.',\n",
       " \"The model has classified the instance as C2 due to the effects of the following features: F5, F8, F6, and F2. Based on the values of these variables, the likelihood of the C2 label is 65.51 percent. F2 and F6 are the top positively contributing variables, whereas F5 and F8 are the most adversely contributing variables. Unlike F2 and F6, which have greater influences on the model's prediction choice in this situation, F3 and F9 have fairly modest positive influences. Finally, F1, F7, and F4 show negative predictive effects, however, as compared to F5, their attributions are modest.\",\n",
       " 'The likelihood of C2 being the correct label for the selected case or instance is 67.54% according to the classifier. This means, there is a 32.46% chance that C1 could be the label and the classification assertion above is influenced mainly by the variables F11, F4, F7, and F9. On the contrary, F10, F2, and F5 are deemed less important when deciding the correct label for this given case.   Decreasing the likelihood of the predicted label , C2, are the variables  F9, F8, F2, and F5, therefore, these negative variables support the alternative class C1. However, the collective or joint attribution of the top positive variables, F4, F11, and F7 is strong enough to tilt the classification in favour of C2.',\n",
       " 'The confidence level score with respect to each class label suggests that this case should be labelled as C2. Specifically, there is about an 80.0% chance that C2 is the correct label. However, this implies that there is also about a 20.0% chance that it should be C1. The above prediction decision is based predominantly on the influence of the following features: F8, F1, F7, F5, F3, F11, and F2. According to the analysis, the features F8, F1, and F7 have a very strong positive influence, swinging the prediction decision towards C2. In contrast, the value of F5 also suggests the decision should be the alternative class, C1. Similar to F5, the values of F10, F3, and F11 indicate the label could be C1. However, the influence of these features is very small compared to F8, F1, F7, and F5. Finally, the attributes with a moderately low influence on the final prediction decision for this case include F2, F6, F4, and F9. The values of F2 and F9 have a negative attribution, while F6 and F4 have positive attributions.',\n",
       " \"The prediction probability of C1 is 17.93% and that of C2 is 82.07%. Therefore, the most probable class for the given case is C2. The above classification assertion statements are based on the information supplied to the classifier about the case given. The top features with significant attributions leading to the decision made above are F6, F26, F32, F42, F43, and F25. Conversely, F38, F24, F14, F28, and F33 are among the features deemed irrelevant to the classification decision here since their contributions are almost negligible and much closer to zero. The attribution analysis suggests that not all the relevant features positively contribute to the classifier's arriving at the verdict here. Those with positive attributions that push the classifier towards generating C2 as the label are F6, F26, F32, F42, F4, F7, F16, and F21. Decreasing the likelihood of the correctness of C2 are the negative features such as F43, F29, F25, F13, F39, F5, F41, and F12, which could be blamed for the little uncertainty in the classification output, as indicated by the prediction probability of C1.\",\n",
       " \"All features are shown to have a positive impact on the classification to class C1 or to have no impact at all. F12, F1, F17, and F28 are the four features with the most impact.  Some of the remaining features, in order of feature importance, are F5, F7, F10, F27, F21, F18, F2, F23, F24, F29, F11, and F6. F12 and F1 both have the highest positive impact on the final classification, pushing the classification towards class C1. All of F17, F28, F5, and F7 influence the model's classification to C1. In terms of the features which have a positive impact on the classification, features F10, F27, F21, and F18 are all ranked to have a medium degree of influence on the final classification. F10 and F27 both have a similar importance attribution, which is higher than that of F21 and F18. All the other features not listed above are irrelevant to the decision above and among them are F22, F25, and F30.\",\n",
       " \"Deciding the most probable label for the given case on the basis of the values of the input variables, the classification algorithm's output decision is that:  the probability of C2 being the correct label is 79.78%, the probability of C1 is 20.22%. Therefore, the most likely label is identified as C2 and the attribution analysis shows that all the variables contributed to some extent to the final decision by the algorithm with respect to the given case. The most influential variables are F9, F8, F14, and F7, but F13, F6, and F11 are the least influential ones. The analysis also indicates that F9, F7, F13, and F11 are responsible for the marginal doubt in the classification decision here hence they are commonly referred to as negative variables since their contributions only tend to shift the verdict in a different direction than the assigned label. Finally, the variables such as F8, F14, F4, F12, F2, and F1 are the positive variables that increase the algorithm's response in favour of outputting the C2 label.\",\n",
       " 'According to the model employed, the label for the case is more likely to be C1. This assessment decision is mainly based on the inpacts of features such as F2, F7, F4, F3, and F8. Among these top features, F2, F7, and F4 have positive contributions to the prediction above, while F8 and F3 are identified as negative features which decreases the likelihood associated with class C1 for this case. Furthermore, the values of F10, F9, F5, and F6 also indicate that the other label, C2, may be the correct label but luckily, the influence of the above-mentioned negative features can be classified as only moderate when compared to F2, F7, and F4. In conclusion, with such a strong positive influence from F2, F7, F4, and F1, it is safe to say that the model is very accurate in its classification judgments, with 100.0% certainty.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train.filter(lambda x: x['narr_q_label'] == letter)['narration'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H: Similar to F, most important, positive, negative, then minor features are mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-530d4ba593fb3de0.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-530d4ba593fb3de0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['F33', 'F3', 'F11', 'F29'], ['F33', 'F3'], ['F29', 'F11'], ['F6', 'F12', 'F38', 'F35', 'F20', 'F2', 'F43'], ['F31', 'F41', 'F4', 'F10']]  Q  [[], ['F33', 'F3', 'F29'], ['F11', 'F6', 'F12'], ['F38', 'F35', 'F20', 'F2']]\n",
      "[[], ['F2'], ['F5', 'F7', 'F4', 'F3', 'F6', 'F9'], ['F1', 'F8'], []]  Q  [[], ['F2', 'F5'], ['F7', 'F4', 'F8', 'F1'], ['F3', 'F6', 'F9']]\n",
      "[[], ['F1', 'F10', 'F5', 'F2', 'F6', 'F4', 'F3', 'F7', 'F8', 'F9', 'F11'], ['F10', 'F5', 'F2', 'F6'], ['F1', 'F7', 'F9', 'F11'], ['F1'], []]  Q  [[], ['F1', 'F10'], ['F5', 'F2', 'F6', 'F4'], ['F3', 'F7', 'F8']]\n"
     ]
    }
   ],
   "source": [
    "letter = 'H'\n",
    "'''\n",
    "H. For 3 cases the format is:\n",
    "* 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.'\n",
    "* 'Summarize the direction of influence of the variables [2-3 top features] on the prediction made for this test case.' -->\n",
    "* 'Compare the direction of impact of the variables: [the next 3-4 features].'\n",
    "* 'Describe the degree of impact of the following variables: [the next 3-4 features]?'\n",
    "'''\n",
    "\n",
    "narr_mentions = [[reg.findall(n)for n in sent_tokenize(l['narration'])] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "q_mentions = [[reg.findall(n)for n in l['narrative_questions']] for l in simple_train.filter(lambda x: x['narr_q_label'] == letter)]\n",
    "for n, q in zip(narr_mentions, q_mentions):\n",
    "    print(n,' Q ', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-530d4ba593fb3de0.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Judging based on the values of the input features, a decision is made by the classifier to label the given data as C2 with a prediction confidence equal to 84.90%. The major influential features resulting in the classification here are F33, F3, F11, and F29. F33 and F3 are identified as the most negative features, with contributions that lead to a decrease in the classification confidence of label C2. F29 and F11, on the other hand, are the top positive features, leading the classifier to label the case as C2. Other notable negative features are F6, F12, and F38 while other notable positives are F35, F20, F2, and F43. Unlike all those mentioned above, F31, F41, F4, and F10 are among the many irrelevant features with negligible contributions to the classification decision here.',\n",
       " 'With a higher degree of confidence, the classifier assigns the label C2 due to the fact that there is a close to zero chance that C1 is the label. The confidence level with respect to this classification output is largely due to the strong positive influence of F2. However, decreasing the probability that C2 is the true label are the negative features F5, F7, F4, F3, F6, and F9. Furthermore, F1 and F8 also increase the likelihood of C2 being the true label. In conclusion, the joint impact of the negative features is very weak compared to the positive features, hence the strong driving force of the classifier to assign the chosen label, C2.',\n",
       " 'The classifier assigned to the given case the label C2 with a very high prediction confidence level, and the classifier is very certain that C1 is not the correct label. Analysing the contributions of the features towards the prediction decision above shows that the features can be ranked from the most important to the least important in the following order: F1, F10, F5, F2, F6, F4, F3, F7, F8, F9, and F11. The features such as F10, F5, F2, and F6 are the top negatively contributing features. However, F1, F7, F9, and F11 are the only features that positively contribute to the label assigned. The strongest positive contribution is from F1, which also happens to be the most relevant feature when it comes to determining the correct label for the given instance or case. Another observation is that the majority of the input features have a negative influence on the classifier, pushing the prediction for the given instance in a different direction.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train.filter(lambda x: x['narr_q_label'] == letter)['narration'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negligible features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When are features labelled as negligible? When are they mentioned in the answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-c3d0734658798cba.arrow\n"
     ]
    }
   ],
   "source": [
    "null_train = simple_train.filter(lambda x: 'negligible' in x['sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "[' '.join([str(i) for i, s in enumerate(signs) if s=='negligible']) for signs in null_train['sign']]\n",
    "negl_indexes = [[i for i, s in enumerate(signs) if s=='negligible'] for signs in null_train['sign']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00',\n",
       " '0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join([l[i] for i in idxs]) for l, idxs in zip(null_train['values'], negl_indexes)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that negligible features are always 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.01',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '0.02',\n",
       " '-0.01',\n",
       " '-0.01',\n",
       " '0.01',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '-0.01',\n",
       " '0.01',\n",
       " '0.02',\n",
       " '0.00',\n",
       " '0.03',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '-0.02',\n",
       " '-0.02',\n",
       " '-0.03',\n",
       " '0.01',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '0.01',\n",
       " '0.00',\n",
       " '-0.02',\n",
       " '0.00',\n",
       " '0.03',\n",
       " '-0.01',\n",
       " '-0.00',\n",
       " '-0.01',\n",
       " '0.01',\n",
       " '0.01',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '-0.01',\n",
       " '-0.00',\n",
       " '-0.02',\n",
       " '0.04',\n",
       " '-0.01',\n",
       " '0.01',\n",
       " '-0.02',\n",
       " '0.00',\n",
       " '0.02',\n",
       " '0.02',\n",
       " '-0.02',\n",
       " '-0.01',\n",
       " '-0.02',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '0.03',\n",
       " '-0.02',\n",
       " '0.01',\n",
       " '-0.01',\n",
       " '0.00',\n",
       " '-0.00',\n",
       " '-0.01',\n",
       " '0.00',\n",
       " '-0.02',\n",
       " '0.01',\n",
       " '-0.02',\n",
       " '-0.02',\n",
       " '0.02',\n",
       " '0.05',\n",
       " '-0.00',\n",
       " '0.01',\n",
       " '0.04',\n",
       " '-0.01',\n",
       " '0.01',\n",
       " '-0.00',\n",
       " '0.02',\n",
       " '0.01',\n",
       " '0.02',\n",
       " '0.01',\n",
       " '0.04',\n",
       " '0.01',\n",
       " '0.00',\n",
       " '-0.01',\n",
       " '-0.01',\n",
       " '0.02',\n",
       " '0.02',\n",
       " '-0.02',\n",
       " '0.01',\n",
       " '0.01']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l[idxs[0]-1] for l, idxs in zip(null_train['values'], negl_indexes)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the first feature that is not negligible. As you can see it is always more than 0.00. So therefore if and only if a feature's value is 0.00 it is negligible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does this line up with the values people talk of as negligible in the narrations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible'],\n",
       " ['positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible',\n",
       "  'negligible']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[signs for signs in null_train['sign']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-89aef500c2d6d1b7.arrow\n"
     ]
    }
   ],
   "source": [
    "not_null_train = simple_train.filter(lambda x: 'negligible' not in x['sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 73),\n",
       " ('B', 64),\n",
       " ('C', 39),\n",
       " ('G', 36),\n",
       " ('F', 34),\n",
       " ('E', 26),\n",
       " ('D', 16),\n",
       " ('H', 2)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(not_null_train['narr_q_label']).most_common()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels A and B do not ask about negligible features, what about the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-41e740a7d4bcb69d.arrow\n"
     ]
    }
   ],
   "source": [
    "not_null2 = not_null_train.filter(lambda x: x['narr_q_label'] in ['C', 'D', 'E', 'F', 'G', 'H'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from below, the narratives tend to mention the bottom 2-4 features, depending on the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F17', 'F13', 'F7', 'F19', 'F1']\n",
      "['-0.00', '-0.00', '0.00', '0.00', '0.00']\n",
      "The classifier is very uncertain about the correct label for the case given.  Regarding the classifier's decision, there is close to an even split on the probability of either of the possible labels is the correct label but the classifier chooses the label as C2. The prediction verdict above is attributed to the contributions of mainly the following features: F4, F11, F3, and F15, however, the lowest ranked features are F7, F19, and F1. Analysing the direction of influence of the features shows that there are ten positive and ten negative features.  Positive features such as F3, F15, F8, and F20 increase the response of the classifier in favour of the assigned label. Conversely, negative features such as F4, F11, F12, and F2 decrease the likelihood of C2 being the correct label given that their values support the alternative label, C1. The uncertainty concerning the label assignment can be due to the fact that the top negative features F4 and F11 have very high attributions shifting the classifier's verdict away from the C2 class.\n",
      "\n",
      "['F2', 'F7', 'F11', 'F8', 'F13']\n",
      "['-0.02', '0.02', '0.01', '-0.00', '0.00']\n",
      "C2 is the label picked by the algorithm with about 82.06% certainty, since the prediction likelihood of C1 is only 17.94%. F20, F5, F10, and F3 all contribute significantly to the above classification output and among them, the features that support the most positive contribution to the C2 prediction are F3, F20, and F5, while F10 drives the final prediction against assigning C2 in support of C1. F1 also contributes positively to the classification here, but F18 contributes negatively and like F10 favours C1. Finally, according to the analysis, F11, F13, F7, and F8 all have little effect on the final prediction made by the algorithm for this case.\n",
      "\n",
      "['F12', 'F7', 'F3', 'F8', 'F2']\n",
      "['-0.02', '0.02', '0.02', '-0.01', '-0.01']\n",
      "The model is confident in its prediction, as it predicted class C1 with a likelihood of 90.48% and hence, for the given case, there is a smaller chance of it being any other class label. F6 and F10 are deemed the most important features whereas on the other hand all the other features have moderate to minimal amounts of influence. Both F6 and F10 have the same direction of impact, increasing the odds of the predicted label, C1. While F4 and F1 are both encouraging the model to make a prediction of C1, the others F9, F12, and F8 is pushing the model towards a different label. Many features have moderately low impact on the final prediction, but the features F3, F8, and F2 are those with the smallest influence.\n",
      "\n",
      "['F1', 'F8', 'F12', 'F4', 'F5']\n",
      "['0.04', '0.03', '-0.01', '0.01', '0.00']\n",
      "For the case under consideration, the model assigned C1 with very high confidence, since the likelihood of C2 being the right label is only 0.52% which is very small. F11, F7, F3, and F10 have a large positive impact on the model's output prediction. F3 and F10 have a moderately positive impact on the prediction of C1, while F2 has a similar impact but in the opposite direction. F5, F12, and F4 have a very low impact on classification. F6, F8, F1, and F9 have a larger but still insignificant effect. Examining the attributions indicates that there are only two features, F2 and F12, with values that contradict the prediction made here but, their impact on the model is smaller when compared to positive features such as F7, F3, and F11, which explains why the confidence level associated with this classification is high.\n",
      "\n",
      "['F12', 'F8', 'F11', 'F4', 'F3']\n",
      "['0.02', '0.01', '-0.01', '-0.01', '-0.00']\n",
      "Between the three possible classes, there is an 88.0% probability that the correct label for this case is C1. This means that there is a 12.0% chance that the label could be one of the other possible labels, C2 or C3. Increasing the odds of the predicted label are the variables F7, F5, F2, and F10. The next set of variables, F6, F1, and F9, have values that moderately decrease the likelihood of C1 being the correct label. F11, F4, and F3 are the other negatively contributing features, and given that they are lowly ranked, they have a marginal impact when determining the correct label for this case. The other positive features further increasing the probability that C1 is the right label are F12 and F8. Overall, we can conclude that the decision to label the case as C1 is largely due to the strong positive influence of F5, F7, F10, and F2.\n",
      "\n",
      "['F8', 'F10', 'F1', 'F2', 'F5']\n",
      "['0.01', '0.01', '0.01', '0.01', '0.00']\n",
      "The classifier is 69.02% certain that the given case is under the class label C1, implying that the likelihood of C2 is only 30.98%. Analysis performed to understand the contribution of each input feature revealed that: F7, F9, and F3 are the most influential features when assigning a label to the given case. Features F4, F6, F8, and F10 have moderate contributions, whereas the F1, F2 and F5 have lower relevance to the final classification decision. F7 and F3 push the class assignment towards C1, whereas F9 does the opposite, decreasing the likelihood of C1. Similar to F9, F4, and F6 negatively impact the C1 classification, whereas F10, F1, and F8 positively push the decision towards the C1 class. Features F2, and F5 all have little impact on the final decision, with F5 having the least impact.\n",
      "\n",
      "['F5', 'F3', 'F4', 'F6', 'F2']\n",
      "['0.03', '-0.03', '0.02', '0.02', '0.01']\n",
      "The classifier trained on this prediction problem assigns a label to a given case based on the information supplied. The class assigned by the classifier to the case under consideration is C1. The probability that C2 is the correct label is around 25.28%; therefore, it is less likely to be the true label. The above classification decision is mainly based on the influence of the features F7, F1, F5, F3, F4, F6, and F2. Of the above stated features, F3 and F1 are the ones shown to have a negative impact, decreasing the odds of C1 being the accurate label for the given case and encouraging the classifier to select C2 instead. Finally, it can be concluded that there is a moderately high level of confidence in the assigned label, which can be attributed to the strong positive contribution of F7 combined with other positive features such as F5 and F4.\n",
      "\n",
      "['F1', 'F13', 'F9', 'F5', 'F17']\n",
      "['-0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "The model predicts that the label for this case is C2 with a high degree of certainty of about 99.19% and the probability of the other label is only 0.81%. From the analysis, the variables with the strongest attributions to this classification decision are F8, F11, and F14. The attributions of these variables increased the response of the model in favour of labelling the case as C2. Other variables that positively supported the label decision include F15, F6, and F16. Not all the variables support the model's prediction of C2 and this is because the values of F2, F10, F3, F7, and F1 are driving the prediction towards C1. The joint attribution from these variables is weaker than that from F8, F11, and F14, so the model is biased toward predicting C2. Finally, F13, F9, F5, and F17 are the least important positive features, given that they have minimal attributions in favour of C2.\n",
      "\n",
      "['F12', 'F10', 'F6', 'F15', 'F11']\n",
      "['-0.01', '0.01', '-0.00', '-0.00', '-0.00']\n",
      "According to the model, C1 has a prediction probability of 99.45 percent, C2 has a prediction probability of 0.47 percent, C4 has a prediction probability of 0.04 percent, and C3 has a prediction probability of 0.05 percent, therefore, the most likely class is C1. F8 and F5 positively influence the above-mentioned label decision in favour of C1, but F7 has the opposite effect, favouring a different label. F9 and F18 both have a similar negative impact on the C1 prediction, whereas F16 has a positive impact. In this case, F4, F1, F13, and F20 have little influence on the labelling result. All in all, the model is confident in its assignment of the C1 class as shown by the predicted probabilities across the classes.\n",
      "\n",
      "['F3', 'F25', 'F16', 'F33', 'F6']\n",
      "['0.03', '0.02', '-0.01', '-0.01', '0.00']\n",
      "The prediction likelihoods across the two classes are 15.35% for class C1 and 84.65% for C2, it can be concluded that C2 is the most probable class label for the given data instance. According to the attribution analysis conducted, the different input variables have varying degrees of influence on the model's decision here. The most influential set of variables is F18, F31, F19, F36, F35, F20, and F38, while the variables with the least influence include F37, F3, F25, F16, F33, and F6. The following or subsequent analysis performed to understand the direction of contribution of of the features  will focus on the most influential ones controlling the label selection here. Among the top influential features, F18, F31, F19, F36, and F38, only F18 and F31 have negative contributions, decreasing the probability that C2 is the correct label, and they strongly support labelling the case as C1 instead. Pushing the classification decision in favour of C2 are the positive variables such as F19, F36, and F38. The contributions of the remaining variables, including F35, F20, and F5, have moderate to low influence. All in all, the marginal uncertainty in the decision here is mainly due to the negative influences of F18, F31, F9, and F23, but the positive contributions of F19, F36, F5, F35, F20, and F38 drive the decision higher towards C2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(not_null2[i]['feature_nums'][-5:])\n",
    "    print(not_null2[i]['values'][-5:])\n",
    "    print(not_null2[i]['narration'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F2', 'F5', 'F7', 'F4', 'F11']\n",
      "['-0.01', '0.01', '-0.01', '-0.01', '0.00']\n",
      "According to the machine learning model, it is more likely that the case's label is C2, with a certainty of 100.0%, and this prediction decision is mainly based on the effects of the following features: F8, F10, F6, F9, and F1 on the model. Apart from F1 and F9, all the other variables mentioned above have a strong positive influence, improving the odds of the prediction class, C2. Together with F1 and F9, the values of variables F3 and F2 indicate that C1 could be the correct label instead. Unlike the top positive variables, F8, F10, and F6, each of these negative variables has a moderate contribution to the final decision. The features F5, F7, F11, and F4 are shown to have made minor contributions to the model's decision in this case. In summary, with only the positive contributions from F8, F10, F6, F11, and F5, the model is very certain of the classification output as indicated by the predicted probabilities across C2 and C1.\n",
      "\n",
      "['F2', 'F9', 'F7', 'F8', 'F6']\n",
      "['-0.02', '0.02', '0.02', '-0.01', '-0.01']\n",
      "The model is very confident that C3 is the most probable class for the given case, with a probability of 90.48% which means that the other labels are very unlikely. F12 and F1 are the most important variables with respect to this classification verdict while all other variables are shown to have a medium or low impact. Fortunately, the top variables, F12 and F1, have the same direction of influence, increasing the likelihood of C3. Furthermore, while F4 and F11 push the model to predict C3, those pushing for the assignment of a different label are F3, F8, and F2. Finally, many features have a fairly small impact on the final prediction made by the model here, but F7, F8, and F6 have the least impact.\n",
      "\n",
      "['F8', 'F6', 'F4', 'F9', 'F5']\n",
      "['0.03', '0.02', '0.01', '0.00', '0.00']\n",
      "This case's label has a 70.83 percent chance of being C3 and per the predicted likelihoods across the alternative labels, C1 has a 29.71 percent chance of being the correct label, however, the model is certain that C2 is not the true label. The most important variables are F1, F7, F3, and F2, whereas the remaining influential variables are listed in order of the magnitude of their contributions: F8, F6, F4, F9, and F5. Three of the nine variables have values that push towards the prediction of label C1 while the other attributes are referred to as positive since their values inspire the prediction of class C3. F1, F7, and F3 are the three attributes that have a negative influence on the prediction judgement, pushing it away from C3 towards the label C1. Finally, it is essential to highlight that the cumulative effect of positive attributes is greater than that of negative attributes, F3, F7, and F1.\n",
      "\n",
      "['F17', 'F1', 'F9', 'F6', 'F15']\n",
      "['0.00', '0.00', '0.00', '0.00', '-0.00']\n",
      "Because the prediction probability of C2 is barely 0.70 percent, the classifier outputs the label C1 with near 100 percent confidence based on the values of the input attributes. The effects of F8, F4, and F2 on the aforementioned classification decision are significant. The values of these features are given greater emphasis by the classifier than the others. F2 is has a negative impact among these top features, pushing the prediction judgement towards the least likely class, C2 whereas on the other hand, F8 and F4 are referred to as positive features since they improve the likelihood of the C1 label rather than the C2 label. Finally, unlike the others, the values of F1, F9, F6, and F15 have only a little influence on the label selection made here.\n",
      "\n",
      "['F15', 'F5', 'F9', 'F13', 'F12']\n",
      "['-0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Judging based on the values of the variables passed to the model with respect to the case under consideration, the output labelling decision is as follows: there is about an 83.98% chance that C2 is the correct label, whereas the likelihood of C1 is only 16.02%, hence the label choice with a higher confidence level is C2. The top-variables influencing this decision are F2, F4, F3, and F14, while the least important variables are F9, F12, and F13. According to the variable contributions analysis performed, only the input variables F8, F16, F19, and F15 exhibit negative attributions, pushing the prediction decision towards the alternative label, C1. The other variables positively support the C2 prediction, shifting the verdict strongly away from the C1 class. In conclusion, positive variables such as F2, F4, F3, F14, F7, and F17 have a higher joint contribution compared to the negative features, which can explain why the model is certain that C2 is the most probable label.\n",
      "\n",
      "['F3', 'F5', 'F4', 'F7', 'F1']\n",
      "['0.01', '0.01', '-0.00', '-0.00', '-0.00']\n",
      "The given case is likely C2 with a confidence level of 87.50% judged based on the values of the input features supplied to the classifier and according to the attributions analysis, F9 and F2 have a high degree of impact. F6, F8, F3, F4, and F5 have a moderate degree of impact while on the contrary F7 and F1 have little impact. Examining further, the values of F9, F2, F6, and F8 all have a positive influence on the classifier supporting the label assignment decision for the given test case. F3 and F5 are also positively supporting features, whereas F4 has a negative influence on the final classification. Finally, F7 and F1 both have very little contributions, though F1 has significantly less than even F7.\n",
      "\n",
      "['F3', 'F9', 'F1', 'F7', 'F4']\n",
      "['0.02', '0.01', '-0.01', '-0.01', '-0.01']\n",
      "The model has classified the instance as C2 due to the effects of the following features: F5, F8, F6, and F2. Based on the values of these variables, the likelihood of the C2 label is 65.51 percent. F2 and F6 are the top positively contributing variables, whereas F5 and F8 are the most adversely contributing variables. Unlike F2 and F6, which have greater influences on the model's prediction choice in this situation, F3 and F9 have fairly modest positive influences. Finally, F1, F7, and F4 show negative predictive effects, however, as compared to F5, their attributions are modest.\n",
      "\n",
      "['F15', 'F8', 'F13', 'F19', 'F10']\n",
      "['-0.00', '-0.00', '-0.00', '-0.00', '-0.00']\n",
      "The classification output is C1, however, the classifier is somewhat unsure about this prediction decision because the corresponding predicted probability is only 55.19%. F11 is by far the most influential feature whereas F4, F6, and F17 have been recognised as having the biggest effect on prediction output here after F11. The combination of F11, F4, F6, F17, and F3 features has resulted in the classification choice being altered from C1 to C2. While F5, F2, and F16 all have a minor influence on the classification, F5 is the only one that has a positive impact on the C1 classification. In this case, many features had lower influence on the prediction, with F15, F8, F13, F19, and F10 having a marginal effect.\n",
      "\n",
      "['F4', 'F5', 'F8', 'F3', 'F6']\n",
      "['0.01', '0.01', '-0.00', '0.00', '-0.00']\n",
      "The classification algorithm predicts class C1 with a confidence level of 61.55% and this implies that the probability of the alternative label is only 38.45%. In this case, the top features driving the prediction decision are F7, F9, F1, and F2, followed by F4, F5, F8, F3, and finally F6. Based on the inspections performed to understand the direction of influence of the input features, it can be concluded that F7 has the strongest positive contribution, while F1 has the strongest negative contribution and conversely, all the remaining features have moderate contributions. The other positive features are F9, F4, F5, and F3, whereas the remaining negatives are F2, F8, and F6. All things considered, the influence of the negative features indicates that the likelihood of the C2 label is 38.45% while the positive contributions push the prediction higher towards C1 resulting in the 61.55% prediction confidence.\n",
      "\n",
      "['F8', 'F1', 'F7', 'F14', 'F6']\n",
      "['-0.02', '-0.02', '-0.02', '0.01', '-0.00']\n",
      "Because the confidence level associated with the other class, C1, is just 2.29%, the model predicts that the given example is likely C2 and to be specific, the model is quite certain that the right label for the given case is C2. All the features are shown to have some degree of influence on the decision above, with F14 and F6 being the least relevant features, while F5 and F9 are the top features. From the analysis performed to understand how each feature contributes to the above prediction assertion, only  the features F13, F12, F1, F8, F7, and F6, have negative influences, shifting the prediction verdict towards C1.  The remaining features all contribute positively, strongly shifting the prediction towards the assigned label which could explain the prediction confidence level associated with label C2. The most positive features are F9, F2, and F5 with stronger push in favour of the output label and they are supported by other positive features such as F4, F10, F3, and F11 have a moderate degree of influence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    print(not_null2[i]['feature_nums'][-5:])\n",
    "    print(not_null2[i]['values'][-5:])\n",
    "    print(not_null2[i]['narration'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 14:34:31.097552: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 14:34:31.644296: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/home/james/Downloads/TensorRT-8.5.1.7/lib\n",
      "2023-01-17 14:34:31.644388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/home/james/Downloads/TensorRT-8.5.1.7/lib\n",
      "2023-01-17 14:34:31.644393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from src.utils import linearise_input, convert_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 15 t5-base 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/CodingProjects/Local_level_model_explanations/env/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 629.24it/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 7887.03ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 7217.00ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 6231.46ex/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 2339.85ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2442.36ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2562.89ex/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.06ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.80ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "text 15 t5-base 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/CodingProjects/Local_level_model_explanations/env/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 861.61it/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 8167.50ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 7365.58ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 7539.67ex/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 2798.15ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2728.17ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2759.41ex/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.98ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.86ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.94ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "text 20 t5-base 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1007.84it/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 7986.47ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 6816.47ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 8063.99ex/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 2537.00ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2489.11ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2462.43ex/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.27ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.97ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.86ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "text 20 t5-base 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 394.92it/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 7643.50ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 7913.15ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 8091.13ex/s]\n",
      "100%|██████████| 375/375 [00:00<00:00, 2097.50ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2534.32ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2575.51ex/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.85ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.19ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.96ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "lin = 'text'\n",
    "max_fts = 30\n",
    "model = 't5-base'\n",
    "max_input_len = 500\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "for lin in ['text']:\n",
    "    for max_fts in [15, 20]:\n",
    "        for max_input_len in [250,300]:\n",
    "            for model in ['t5-base']:\n",
    "                print(lin, max_fts, model, max_input_len)\n",
    "\n",
    "                tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "                dataset = load_dataset(\"james-burton/textual-explanations\")\n",
    "\n",
    "                dataset = dataset.map(lambda x: simplify_narr_question(label_qs(x)),\n",
    "                                        load_from_cache_file=False)\n",
    "\n",
    "                # Form the linearised or stepwise (and linearised) input\n",
    "                dataset = dataset.map(\n",
    "                    lambda x: linearise_input(x, lin, max_fts),\n",
    "                    load_from_cache_file=False\n",
    "                    ) \n",
    "\n",
    "                # Convert to tokens\n",
    "                dataset = dataset.map(\n",
    "                    lambda x: convert_to_features(x, tokenizer, max_input_len), \n",
    "                    batched=True, load_from_cache_file=False\n",
    "                    )\n",
    "                decoded_train = tokenizer.batch_decode(dataset['train']['input_ids'], skip_special_tokens=False)\n",
    "\n",
    "                [len(d) for d in decoded_train]\n",
    "                # Count number of times the string '<pad>' appears in the string \n",
    "                # (i.e. the number of padding tokens)\n",
    "                max_outs = sum([len(re.findall('<pad>', d))==0 for d in decoded_train])\n",
    "                output_dict[(lin, max_fts, model, max_input_len)] = max_outs\n",
    "                print(max_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['model_name', 'predicted_class', 'task_name', 'narration', 'values', 'sign', 'narrative_id', 'unique_id', 'classes_dict', 'narrative_questions', 'feature_nums', 'ft_num2name', 'old2new_ft_nums', 'old2new_classes', 'narr_q_label', 'narr_q_label_group', 'original_narrative_questions'],\n",
       "    num_rows: 375\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
