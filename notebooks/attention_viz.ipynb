{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/CodingProjects/Local_level_model_explanations/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-16 16:06:40.859826: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 16:06:41.343846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/home/james/Downloads/TensorRT-8.5.1.7/lib\n",
      "2023-01-16 16:06:41.343895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/home/james/Downloads/TensorRT-8.5.1.7/lib\n",
      "2023-01-16 16:06:41.343900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 47/47 [00:00<00:00, 7364.75ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2322.04ex/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.15ba/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForSeq2SeqLM\n",
    "from datasets.load import load_dataset\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "from src.utils import (\n",
    "    linearise_input, convert_to_features, form_stepwise_input, \n",
    "    simplify_feat_names,\n",
    "    label_qs,\n",
    "    simplify_narr_question\n",
    ")\n",
    "import torch\n",
    "\n",
    "lin = 'ord_first'\n",
    "max_fts = 40\n",
    "max_input_len = 500\n",
    "model_name = \"../models/t5-base/sleek-haze-118/checkpoint-1880\"\n",
    "\n",
    "# Load model, tokenizer and dataset\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "dataset = load_dataset(\"james-burton/textual-explanations\", split='test')\n",
    "\n",
    "dataset = dataset.map(lambda x: simplify_narr_question(label_qs(x)),\n",
    "                        load_from_cache_file=False)\n",
    "\n",
    "# Form the linearised or stepwise (and linearised) input\n",
    "dataset = dataset.map(\n",
    "    lambda x: linearise_input(x, lin, max_fts),\n",
    "    load_from_cache_file=False\n",
    "    ) \n",
    "\n",
    "# Convert to tokens\n",
    "dataset = dataset.map(\n",
    "    lambda x: convert_to_features(x, tokenizer, max_input_len), \n",
    "    batched=True, load_from_cache_file=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:22<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "from bertviz import model_view\n",
    "from nltk import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = \"../models/t5-base/sleek-haze-118/checkpoint-1880\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, output_attentions=True).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "squeezed_list = []\n",
    "for k in tqdm(range(len(dataset['input']))):\n",
    "    input_text = dataset['input'][k]\n",
    "    inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    encoder_input = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True).to('cuda')\n",
    "    encoder_input_ids, encoder_input_att_mask = encoder_input.input_ids,encoder_input.attention_mask\n",
    "\n",
    "    decoder_input_ids = model.generate(input_ids=encoder_input_ids,\n",
    "                                            attention_mask=encoder_input_att_mask,\n",
    "                                            no_repeat_ngram_size=2,\n",
    "                                            num_return_sequences=1,\n",
    "                                            do_sample=True,\n",
    "                                            early_stopping=True,\n",
    "                                            use_cache=False,\n",
    "                                            max_length=250,\n",
    "                                            num_beams=5)\n",
    "\n",
    "\n",
    "    outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "    encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "    decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n",
    "\n",
    "\n",
    "    sents = sent_tokenize(tokenizer.decode(decoder_input_ids[0]))\n",
    "    lens = [len(tokenizer.tokenize(i)) for i in sents]\n",
    "\n",
    "    output_splits = [0]\n",
    "    for i in range(len(sents)-1):\n",
    "        if i == 0:\n",
    "            output_splits.append(lens[i])\n",
    "        else:\n",
    "            output_splits.append(lens[i]+output_splits[i])\n",
    "\n",
    "    output_splits.extend([-1, None])\n",
    "            \n",
    "    splits = []\n",
    "    start_idx = 0\n",
    "    for i in range(4):\n",
    "        start_idx = encoder_text.index('▁|', start_idx + 1)\n",
    "\n",
    "    input_splits = [0, start_idx, encoder_text.index('▁1.'), encoder_text.index('▁2.'), encoder_text.index('▁3.'), encoder_text.index('▁4.'), -1, None]\n",
    "\n",
    "    unsqueezed = outputs.cross_attentions[11][0].mean(dim=0)\n",
    "    squeezed = torch.zeros(len(output_splits)-1, len(input_splits)-1)\n",
    "\n",
    "    # Take an average from the ith:ith+1 output to the jth: jth+1 input\n",
    "    for i in range(len(output_splits)-1):\n",
    "        for j in range(len(input_splits)-1):\n",
    "            squeezed[i, j] = unsqueezed[output_splits[i]:output_splits[i+1], input_splits[j]:input_splits[j+1]].sum(axis=1).mean()\n",
    "\n",
    "    squeezed_list.append(squeezed)\n",
    "    \n",
    "    # Squeezed now represents an n x m matrix where n is the number of output sentences and m is the number of input splits\n",
    "    # Outputs are split into however many sentences there are, plus the final special token\n",
    "    # inputs are split into Classification info, Feature info, each of the 4 question infos and the final special token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(i) for i in squeezed_list])\n",
    "new_squeezed_list = squeezed_list.copy()\n",
    "# Expand the list to the max lenght\n",
    "# Create a mask to indicate which elements are valid        \n",
    "mask = torch.zeros(len(new_squeezed_list),max_len)\n",
    "for i in range(len(new_squeezed_list)):\n",
    "    mask[i, :len(new_squeezed_list[i])] = 1\n",
    "    if len(new_squeezed_list[i]) < max_len:\n",
    "        new_squeezed_list[i] = torch.cat((new_squeezed_list[i], torch.zeros(max_len-len(new_squeezed_list[i]), 7)), dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the mean of torch.stack(new_squeezed_list) only when the mask is 1\n",
    "# This is a bit of a hack to avoid having to pad the list\n",
    "mean = torch.sum(torch.stack(new_squeezed_list)*mask.unsqueeze(-1), dim=0)/torch.sum(mask, dim=0).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2257, 0.2076, 0.1093, 0.1044, 0.1093, 0.0892, 0.1846],\n",
       "        [0.0885, 0.2810, 0.1122, 0.1353, 0.1504, 0.0978, 0.1723],\n",
       "        [0.0556, 0.3062, 0.1052, 0.1290, 0.1713, 0.1084, 0.1640],\n",
       "        [0.0755, 0.2905, 0.1112, 0.1298, 0.1611, 0.1081, 0.1607],\n",
       "        [0.0547, 0.3602, 0.1118, 0.1176, 0.1331, 0.0977, 0.1718],\n",
       "        [0.0378, 0.3942, 0.1091, 0.0872, 0.1719, 0.0836, 0.1778]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(7.1704, grad_fn=<SumBackward0>),\n",
       " tensor(4., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(6., grad_fn=<SumBackward0>),\n",
       " tensor(4.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(4., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(6., grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(6.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(9.3340, grad_fn=<SumBackward0>),\n",
       " tensor(8.6834, grad_fn=<SumBackward0>),\n",
       " tensor(6.0000, grad_fn=<SumBackward0>),\n",
       " tensor(4., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(4.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(4., grad_fn=<SumBackward0>),\n",
       " tensor(6.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(6., grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>),\n",
       " tensor(5.0000, grad_fn=<SumBackward0>),\n",
       " tensor(6.0000, grad_fn=<SumBackward0>),\n",
       " tensor(5., grad_fn=<SumBackward0>)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Something is wrong here with the 2nd element\n",
    "[s.sum() for s in squeezed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(new_squeezed_list).sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 18, 88, 96, 105, 119, -1, None]\n",
      "[0, 30, 66, 100, -1, None]\n"
     ]
    }
   ],
   "source": [
    "print(input_splits)\n",
    "print(output_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "# i = -1\n",
    "# for j in range(len(input_splits)-1):\n",
    "#     squeezed[len(output_splits)-1, j] = unsqueezed[i, input_splits[j]:input_splits[j+1]].sum()\n",
    "# j = -1\n",
    "# for i in range(len(output_splits)-1):\n",
    "#     squeezed[i, len(input_splits)-1] = unsqueezed[output_splits[i]:output_splits[i+1], j].mean()\n",
    "\n",
    "# j, i = -1, -1\n",
    "\n",
    "# squeezed[i,j] = unsqueezed[i, j]\n",
    "# squeezed = squeezed*100\n",
    "# assert squeezed.sum() == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1284e-01, 1.5995e-01, 1.4048e-01, 1.2926e-01, 1.2642e-01, 5.3404e-04,\n",
       "         2.3052e-01],\n",
       "        [1.1505e-01, 2.3920e-01, 1.4098e-01, 1.4032e-01, 1.6454e-01, 3.2060e-03,\n",
       "         1.9670e-01],\n",
       "        [5.8429e-02, 2.3242e-01, 1.3984e-01, 1.5255e-01, 2.0289e-01, 2.4868e-03,\n",
       "         2.1139e-01],\n",
       "        [1.4218e-01, 2.0422e-01, 1.5156e-01, 1.4292e-01, 1.5703e-01, 1.9598e-03,\n",
       "         2.0013e-01],\n",
       "        [9.4377e-02, 2.6244e-01, 1.5525e-01, 1.4809e-01, 1.3989e-01, 9.2435e-05,\n",
       "         1.9987e-01]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 121])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed[-1:None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3357], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed[i, input_splits[j]:input_splits[j+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      2\u001b[0m j \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m squeezed[\u001b[39mlen\u001b[39m(output_splits)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, j] \u001b[39m=\u001b[39m unsqueezed[i, input_splits[j]:input_splits[j\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m]]\u001b[39m.\u001b[39;49msum(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "i = -1\n",
    "j = 0\n",
    "squeezed[len(output_splits)-1, j] = unsqueezed[i, input_splits[j]:input_splits[j+1]].sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed[i, input_splits[j]:input_splits[j+1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.01, 0.00, 0.01, 0.01, 0.00, 0.02, 0.18],\n",
       "        [0.00, 0.00, 0.01, 0.02, 0.01, 0.02, 0.15],\n",
       "        [0.00, 0.00, 0.02, 0.01, 0.01, 0.02, 0.20],\n",
       "        [0.00, 0.00, 0.01, 0.02, 0.00, 0.02, 0.15],\n",
       "        [0.00, 0.00, 0.01, 0.01, 0.00, 0.02, 0.15],\n",
       "        [0.00, 0.00, 0.01, 0.01, 0.00, 0.02, 0.16]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39, 65, 87, 114, 128]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.cross_attentions[11][0].mean(dim=0).shape\n",
    "\n",
    "# Average across the splits output_splits and input_splits\n",
    "for sp in range(len(output_splits)):\n",
    "    if sp == 0:\n",
    "        start = 0\n",
    "        end = output_splits[sp]\n",
    "    else:\n",
    "        start = output_splits[sp-1]\n",
    "        end = output_splits[sp]\n",
    "    print(start, end)\n",
    "    print(decoder_text[start:end])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19, 259,   1,   1,  12, 259, 259, 262, 259, 259,   6,   2, 238,   2,\n",
       "        259, 160, 259, 259, 259, 259, 259,   1, 259, 259, 259, 261, 262, 259,\n",
       "        259, 262, 259, 239,   2, 262, 259, 259,   3, 259, 259, 262, 262, 259,\n",
       "        259, 248, 248, 259, 259, 262,   0, 248, 261, 259,   2, 239, 259,  24,\n",
       "        259, 259,  24, 262, 259, 262,  24, 259, 259,  24, 262, 259, 262, 262,\n",
       "        262, 262, 259, 262, 259, 258, 259, 259, 247, 262,  12, 259, 259,  13,\n",
       "        257,  12, 259, 262, 244, 262, 259, 238, 262, 239, 262, 259,   2, 248,\n",
       "        259, 259, 262, 259, 257, 262, 214, 259,   2, 189,   2, 259, 259,   2,\n",
       "        259, 237, 259, 259, 262, 259, 259, 262, 259, 262, 262, 247, 258, 248,\n",
       "        259, 262], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.cross_attentions[0][0][11].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 263])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.cross_attentions[11][0][11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_view(\n",
    "#     encoder_attention=outputs.encoder_attentions,\n",
    "#     decoder_attention=outputs.decoder_attentions,\n",
    "#     cross_attention=outputs.cross_attentions,\n",
    "#     encoder_tokens= encoder_text,\n",
    "#     decoder_tokens = decoder_text,\n",
    "#     include_layers=[11]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
