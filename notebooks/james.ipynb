{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hotel Satisfaction',\n",
       " 'Music Concert Attendance',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Customer Churn Modelling',\n",
       " 'Concrete Strength Classification',\n",
       " 'Car Acceptability Valuation',\n",
       " 'Student Job Placement',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Student Job Placement',\n",
       " 'Concrete Strength Classification',\n",
       " 'Student Job Placement',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'House Price Classification',\n",
       " 'Advertisement Prediction',\n",
       " 'Music Concert Attendance',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Advertisement Prediction',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Water Quality Classification',\n",
       " 'Employee Attrition',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'House Price Classification',\n",
       " 'E-Commerce Shipping',\n",
       " 'Printer Sales',\n",
       " 'Hotel Satisfaction',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Real Estate Investment',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Insurance Churn',\n",
       " 'Student Job Placement',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Insurance Churn',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Student Job Placement',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Water Quality Classification',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Student Job Placement',\n",
       " 'Student Job Placement',\n",
       " 'Employee Attrition',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Wine Quality Prediction',\n",
       " 'Printer Sales',\n",
       " 'Credit Risk Classification',\n",
       " 'Car Acceptability Valuation',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Credit Risk Classification',\n",
       " 'Australian Credit Approval',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Printer Sales',\n",
       " 'Concrete Strength Classification',\n",
       " 'Cab Surge Pricing System',\n",
       " 'House Price Classification',\n",
       " 'Suspicious Bidding Identification',\n",
       " 'Wine Quality Prediction',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Credit Risk Classification',\n",
       " 'Bike Sharing Demand',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Personal Loan Modelling',\n",
       " 'German Credit Evaluation',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Suspicious Bidding Identification',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Bike Sharing Demand',\n",
       " 'German Credit Evaluation',\n",
       " 'House Price Classification',\n",
       " 'Customer Churn Modelling',\n",
       " 'Insurance Churn',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Real Estate Investment',\n",
       " 'Australian Credit Approval',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Annual Income Earnings',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Paris House Classification',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Annual Income Earnings',\n",
       " 'Real Estate Investment',\n",
       " 'Personal Loan Modelling',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'E-Commerce Shipping',\n",
       " 'Annual Income Earnings',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'German Credit Evaluation',\n",
       " 'Paris House Classification',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Customer Churn Modelling',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Air Quality Prediction',\n",
       " 'Wine Quality Prediction',\n",
       " 'Wine Quality Prediction',\n",
       " 'Real Estate Investment',\n",
       " 'Concrete Strength Classification',\n",
       " 'Employee Attrition',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Credit Risk Classification',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Real Estate Investment',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Hotel Satisfaction',\n",
       " 'Advertisement Prediction',\n",
       " 'Advertisement Prediction',\n",
       " 'House Price Classification',\n",
       " 'Suspicious Bidding Identification',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Annual Income Earnings',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'E-Commerce Shipping',\n",
       " 'Australian Credit Approval',\n",
       " 'Car Acceptability Valuation',\n",
       " 'Employee Attrition',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Customer Churn Modelling',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Australian Credit Approval',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'House Price Classification',\n",
       " 'Bike Sharing Demand',\n",
       " 'Job Change of Data Scientists',\n",
       " 'Personal Loan Modelling',\n",
       " 'Bike Sharing Demand',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Employee Attrition',\n",
       " 'German Credit Evaluation',\n",
       " 'German Credit Evaluation',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Wine Quality Prediction',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Water Quality Classification',\n",
       " 'Personal Loan Modelling',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Printer Sales',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Printer Sales',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Australian Credit Approval',\n",
       " 'Personal Loan Modelling',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Insurance Churn',\n",
       " 'Advertisement Prediction',\n",
       " 'House Price Classification',\n",
       " 'Concrete Strength Classification',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Job Change of Data Scientists',\n",
       " 'Employee Attrition',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Advertisement Prediction',\n",
       " 'Employee Attrition',\n",
       " 'Paris House Classification',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Bike Sharing Demand',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Annual Income Earnings',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Concrete Strength Classification',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Employee Promotion Prediction',\n",
       " 'House Price Classification',\n",
       " 'Car Acceptability Valuation',\n",
       " 'Hotel Satisfaction',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Flight Price-Range Classification',\n",
       " 'German Credit Evaluation',\n",
       " 'Wine Quality Prediction',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Customer Churn Modelling',\n",
       " 'Australian Credit Approval',\n",
       " 'Bike Sharing Demand',\n",
       " 'Water Quality Classification',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'German Credit Evaluation',\n",
       " 'Wine Quality Prediction',\n",
       " 'Student Job Placement',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Australian Credit Approval',\n",
       " 'Concrete Strength Classification',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Employee Attrition',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Student Job Placement',\n",
       " 'Paris House Classification',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Concrete Strength Classification',\n",
       " 'Hotel Satisfaction',\n",
       " 'Printer Sales',\n",
       " 'Car Acceptability Valuation',\n",
       " 'Concrete Strength Classification',\n",
       " 'Hotel Satisfaction',\n",
       " 'Concrete Strength Classification',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Employee Attrition',\n",
       " 'Real Estate Investment',\n",
       " 'Wine Quality Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'German Credit Evaluation',\n",
       " 'Annual Income Earnings',\n",
       " 'E-Commerce Shipping',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Paris House Classification',\n",
       " 'Paris House Classification',\n",
       " 'House Price Classification',\n",
       " 'House Price Classification',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Printer Sales',\n",
       " 'Printer Sales',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Printer Sales',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'E-Commerce Shipping',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Customer Churn Modelling',\n",
       " 'E-Commerce Shipping',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Advertisement Prediction',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Annual Income Earnings',\n",
       " 'Real Estate Investment',\n",
       " 'Advertisement Prediction',\n",
       " 'Customer Churn Modelling',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Student Job Placement',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Customer Churn Modelling',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Annual Income Earnings',\n",
       " 'Annual Income Earnings',\n",
       " 'Credit Risk Classification',\n",
       " 'Credit Risk Classification',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Insurance Churn',\n",
       " 'Insurance Churn',\n",
       " 'Credit Risk Classification',\n",
       " 'Credit Risk Classification',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Credit Risk Classification',\n",
       " 'Credit Risk Classification',\n",
       " 'Air Quality Prediction',\n",
       " 'Air Quality Prediction',\n",
       " 'Music Concert Attendance',\n",
       " 'Music Concert Attendance',\n",
       " 'Personal Loan Modelling',\n",
       " 'Personal Loan Modelling',\n",
       " 'Suspicious Bidding Identification',\n",
       " 'Suspicious Bidding Identification',\n",
       " 'German Credit Evaluation',\n",
       " 'German Credit Evaluation',\n",
       " 'Hotel Satisfaction',\n",
       " 'Australian Credit Approval',\n",
       " 'Australian Credit Approval',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'German Credit Evaluation',\n",
       " 'Tic-Tac-Toe Strategy',\n",
       " 'Customer Churn Modelling',\n",
       " 'Car Acceptability Valuation',\n",
       " 'Student Job Placement',\n",
       " 'Student Job Placement',\n",
       " 'Personal Loan Modelling',\n",
       " 'Personal Loan Modelling',\n",
       " 'Australian Credit Approval',\n",
       " 'Australian Credit Approval',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Printer Sales',\n",
       " 'Printer Sales',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Printer Sales',\n",
       " 'Printer Sales',\n",
       " 'Credit Card Fraud Classification',\n",
       " 'Personal Loan Modelling',\n",
       " 'Water Quality Classification',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Wine Quality Prediction',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Bike Sharing Demand',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Paris House Classification',\n",
       " 'Paris House Classification',\n",
       " 'Advertisement Prediction',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Job Change of Data Scientists',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Advertisement Prediction',\n",
       " 'House Price Classification',\n",
       " 'Concrete Strength Classification',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Employee Attrition',\n",
       " 'Insurance Churn',\n",
       " 'Company Bankruptcy Prediction',\n",
       " 'Employee Attrition',\n",
       " 'Ethereum Fraud Detection',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Concrete Strength Classification',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Real Estate Investment',\n",
       " 'Air Quality Prediction',\n",
       " 'Air Quality Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Credit Risk Classification',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Food Ordering Customer Churn Prediction',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Basketball Players Career Length Prediction',\n",
       " 'Hotel Satisfaction',\n",
       " 'Hotel Satisfaction',\n",
       " 'Job Change of Data Scientists',\n",
       " 'Job Change of Data Scientists',\n",
       " 'E-Commerce Shipping',\n",
       " 'E-Commerce Shipping',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Employee Promotion Prediction',\n",
       " 'Employee Attrition',\n",
       " 'Employee Attrition',\n",
       " 'Employee Attrition',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Advertisement Prediction',\n",
       " 'Advertisement Prediction',\n",
       " 'Printer Sales',\n",
       " 'Printer Sales',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Annual Income Earnings',\n",
       " 'Annual Income Earnings',\n",
       " 'Annual Income Earnings',\n",
       " 'Annual Income Earnings',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Airline Passenger Satisfaction',\n",
       " 'Advertisement Prediction',\n",
       " 'Advertisement Prediction',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Vehicle Insurance Claims',\n",
       " 'Cab Surge Pricing System',\n",
       " 'House Price Classification',\n",
       " 'Broadband Sevice Signup',\n",
       " 'Mobile Price-Range Classification',\n",
       " 'Health Care Services Satisfaction Prediction',\n",
       " 'Credit Risk Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'E-Commerce Shipping',\n",
       " 'German Credit Evaluation',\n",
       " 'Personal Loan Modelling',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " 'Air Quality Prediction',\n",
       " 'Air Quality Prediction',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Cab Surge Pricing System',\n",
       " 'Water Quality Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Flight Price-Range Classification',\n",
       " 'Used Cars Price-Range Prediction',\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open('raw_data/all_train.json',encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_name', 'deleted', 'mturk_id', 'predicted_class', 'narrative_status', 'predicted_class_label', 'date_submitted', 'id', 'feature_division', 'date_approved', 'test_instance', 'features_placeholder', 'is_paid', 'task_name', 'prediction_confidence', 'redeem_code', 'narrator', 'narration', 'user_ip', 'narrative_question', 'prediction_confidence_level'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.get('task_name', None) for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([9, 4, 11, 9, 12, 6, 12, 15, 11, 12, 14, 14, 15, 22, 6, 14, 9, 15, 11, 8, 7, 8, 13, 13, 12, 9, 12, 11, 10, 5, 7, 11, 12, 10, 8, 13, 8, 11, 7, 5, 109])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count = Counter([i.get('task_name', None) for i in data])\n",
    "(count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([85, 72, 4, 10, 21, 34, 4, 37, 6, 50, 20, 3, 13, 33, 6, 11, 1, 5, 4, 2, 109])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter([i.get('model_name', None) for i in data])\n",
    "(count.most_common())\n",
    "count.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_task = [x for x in data if x.get('narrative_question', None) == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(no_task, open('no_task.json', 'w', encoding='utf-8'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_approved, date_submitted, deleted, feature_division, features_placeholder, id, is_paid, model_name, mturk_id, narration, narrative_question, narrative_status, narrator, predicted_class, predicted_class_label, prediction_confidence, prediction_confidence_level, redeem_code, task_name, test_instance, user_ip',\n",
       " 'date_approved, date_submitted, deleted, feature_division, features_placeholder, id, is_paid, model_name, mturk_id, narration, narrative_question, narrative_status, narrator, predicted_class, predicted_class_label, prediction_confidence_level, redeem_code, task_name, test_instance, user_ip',\n",
       " 'feature_division, narration, narration3, predicted_class, prediction_confidence_level',\n",
       " 'feature_division, narration, predicted_class, prediction_confidence_level'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([', '.join(sorted(list(task.keys()))) for task in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one instance of narration3. I think this must have been an instance where there was 2 narrations for one thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feature_division, narration, predicted_class, prediction_confidence_level',\n",
       "  108),\n",
       " ('feature_division, narration, narration3, predicted_class, prediction_confidence_level',\n",
       "  1)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([', '.join(sorted(list(task.keys()))) for task in no_task]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([(len(d['prediction_confidence_level'].split(','))) for d in no_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = [x for x in data if x.get('task_name', None) != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(len(d['prediction_confidence_level'].split(','))) for d in task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_class': 'C3',\n",
       " 'prediction_confidence_level': 'C1:40.36%, C2:10.15%, C3:49.49%',\n",
       " 'feature_division': {'ranks': [['F14', 0],\n",
       "   ['F8', 1],\n",
       "   ['F15', 2],\n",
       "   ['F28', 3],\n",
       "   ['F2', 4],\n",
       "   ['F36', 5],\n",
       "   ['F30', 6],\n",
       "   ['F9', 7],\n",
       "   ['F26', 8],\n",
       "   ['F3', 9],\n",
       "   ['F18', 10],\n",
       "   ['F13', 11],\n",
       "   ['F35', 12],\n",
       "   ['F33', 13],\n",
       "   ['F32', 14],\n",
       "   ['F34', 15],\n",
       "   ['F38', 16],\n",
       "   ['F42', 17],\n",
       "   ['F23', 18],\n",
       "   ['F43', 19],\n",
       "   ['F12', 20],\n",
       "   ['F31', 21],\n",
       "   ['F4', 22],\n",
       "   ['F24', 23],\n",
       "   ['F5', 24],\n",
       "   ['F39', 25],\n",
       "   ['F21', 26],\n",
       "   ['F22', 27],\n",
       "   ['F37', 28],\n",
       "   ['F20', 29],\n",
       "   ['F16', 30],\n",
       "   ['F25', 31],\n",
       "   ['F40', 32],\n",
       "   ['F11', 33],\n",
       "   ['F10', 34],\n",
       "   ['F41', 35],\n",
       "   ['F17', 36],\n",
       "   ['F29', 37],\n",
       "   ['F6', 38],\n",
       "   ['F1', 39],\n",
       "   ['F7', 40],\n",
       "   ['F19', 41],\n",
       "   ['F27', 42]],\n",
       "  'contradict': ['F8',\n",
       "   'F28',\n",
       "   'F2',\n",
       "   'F36',\n",
       "   'F30',\n",
       "   'F3',\n",
       "   'F18',\n",
       "   'F13',\n",
       "   'F32',\n",
       "   'F34',\n",
       "   'F38',\n",
       "   'F43',\n",
       "   'F12',\n",
       "   'F31',\n",
       "   'F4',\n",
       "   'F24',\n",
       "   'F22',\n",
       "   'F16',\n",
       "   'F25'],\n",
       "  'support': ['F14',\n",
       "   'F15',\n",
       "   'F9',\n",
       "   'F26',\n",
       "   'F35',\n",
       "   'F33',\n",
       "   'F42',\n",
       "   'F23',\n",
       "   'F5',\n",
       "   'F39',\n",
       "   'F21',\n",
       "   'F37',\n",
       "   'F20',\n",
       "   'F40'],\n",
       "  'ignore': ['F11',\n",
       "   'F10',\n",
       "   'F41',\n",
       "   'F17',\n",
       "   'F29',\n",
       "   'F6',\n",
       "   'F1',\n",
       "   'F7',\n",
       "   'F19',\n",
       "   'F27']},\n",
       " 'narration': 'According to the classifier, C3 is the most probable label, followed by C1 and C2. To be specific, the predicted likelihoods across the classes C1, C3, and C2, respectively are 40.36%, 49.49%, and  10.15%. The moderately high classification confidence could largely be due to the impact of certain input features supplied to the classifier. In fact the attribution analysis indicates that F14, F8, F15, and F28 are the most relevant features resulting in the predicted probabilities across the labels. Other features with moderate contributions include F2, F36, F30, F26, F3, F18, and F9.  Among these top influential features, F8, F28, F2, F36, F30, F3, and F18 have negative contributions that shift the decision in a different direction towards the other possible label. On the contrary, the top positive features encouraging the classifier to label the case as C3 are F14, F15, F9, F26, F35, and F33. Considering the attributions across the positive and negative features, it is not surprising that there is such predicted probabilities for the different classes.'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = json.load(open('raw_data/test_set_new.json',encoding='utf-8'))\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('date_approved, date_submitted, deleted, feature_division, features_placeholder, id, is_paid, model_name, mturk_id, narration, narrative_question, narrative_status, narrator, predicted_class, predicted_class_label, prediction_confidence, prediction_confidence_level, redeem_code, task_name, test_instance, user_ip',\n",
       "  24),\n",
       " ('date_approved, date_submitted, deleted, feature_division, features_placeholder, id, is_paid, model_name, mturk_id, narration, narrative_question, narrative_status, narrator, predicted_class, predicted_class_label, prediction_confidence_level, redeem_code, task_name, test_instance, user_ip',\n",
       "  24)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([', '.join(sorted(list(task.keys()))) for task in test]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter([i.get('task_name', None) for i in test])\n",
    "len(count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = json.load(open('raw_data/all.json',encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [x['model_name']+x['task_name'] for x in all if x.get('test_instance', None) != None]\n",
    "train = [x['model_name']+x['task_name'] for x in all if x.get('test_instance', None) == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegressionUsed Cars Price-Range Prediction', 9),\n",
       " ('LogisticRegressionFlight Price-Range Classification', 9),\n",
       " ('BernoulliNBPersonal Loan Modelling', 8),\n",
       " ('SGDClassifierHouse Price Classification', 8),\n",
       " ('RandomForestClassifierFlight Price-Range Classification', 7),\n",
       " ('RandomForestClassifierCompany Bankruptcy Prediction', 6),\n",
       " ('RandomForestClassifierStudent Job Placement', 6),\n",
       " ('SVM_polyMobile Price-Range Classification', 6),\n",
       " ('DecisionTreeClassifierInsurance Churn', 6),\n",
       " ('GradientBoostingClassifierBasketball Players Career Length Prediction', 6),\n",
       " ('SVMClassifier_polyEmployee Attrition', 6),\n",
       " ('SVM_linearEmployee Promotion Prediction', 6),\n",
       " ('KNeighborsClassifierCredit Risk Classification', 6),\n",
       " ('RandomForestClassifierMobile Price-Range Classification', 6),\n",
       " ('LogisticRegressionAirline Passenger Satisfaction', 6),\n",
       " ('GradientBoostingClassifierParis House Classification', 6),\n",
       " ('KNeighborsClassifierCab Surge Pricing System', 6),\n",
       " ('RandomForestClassifierPrinter Sales', 6),\n",
       " ('LogisticRegressionConcrete Strength Classification', 5),\n",
       " ('SVCAdvertisement Prediction', 5),\n",
       " ('LogisticRegressionCab Surge Pricing System', 5),\n",
       " ('KNeighborsClassifierAdvertisement Prediction', 5),\n",
       " ('SGDClassifierFlight Price-Range Classification', 5),\n",
       " ('RandomForestClassifierCab Surge Pricing System', 5),\n",
       " ('DecisionTreeClassifierCredit Risk Classification', 5),\n",
       " ('SVCGerman Credit Evaluation', 5),\n",
       " ('RandomForestClassifierAnnual Income Earnings', 5),\n",
       " ('MLPClassifierAnnual Income Earnings', 5),\n",
       " ('MLPClassifierEthereum Fraud Detection', 5),\n",
       " ('BernoulliNBCustomer Churn Modelling', 5),\n",
       " ('RandomForestClassifierUsed Cars Price-Range Prediction', 5),\n",
       " ('LogisticRegressionFood Ordering Customer Churn Prediction', 5),\n",
       " ('RandomForestClassifierEmployee Attrition', 5),\n",
       " ('GradientBoostingClassifierFood Ordering Customer Churn Prediction', 5),\n",
       " ('SVMCustomer Churn Modelling', 4),\n",
       " ('DNNConcrete Strength Classification', 4),\n",
       " ('DecisionTreeClassifierCar Acceptability Valuation', 4),\n",
       " ('BernoulliNBStudent Job Placement', 4),\n",
       " ('GaussianNBTic-Tac-Toe Strategy', 4),\n",
       " ('LogisticRegressionMusic Concert Attendance', 4),\n",
       " ('BernoulliNBHotel Satisfaction', 4),\n",
       " ('LogisticRegressionReal Estate Investment', 4),\n",
       " ('SVCVehicle Insurance Claims', 4),\n",
       " ('BernoulliNBCredit Card Fraud Classification', 4),\n",
       " ('KNeighborsClassifierWine Quality Prediction', 4),\n",
       " ('GradientBoostingClassifierPrinter Sales', 4),\n",
       " ('DecisionTreeClassifierConcrete Strength Classification', 4),\n",
       " ('KNeighborsClassifierSuspicious Bidding Identification', 4),\n",
       " ('SGDClassifierAirline Passenger Satisfaction', 4),\n",
       " ('GradientBoostingClassifierHealth Care Services Satisfaction Prediction', 4),\n",
       " ('RandomForestClassifierHealth Care Services Satisfaction Prediction', 4),\n",
       " ('RandomForestClassifierE-Commerce Shipping', 4),\n",
       " ('SVM_linearWine Quality Prediction', 4),\n",
       " ('SVCAustralian Credit Approval', 4),\n",
       " ('GradientBoostingClassifierGerman Credit Evaluation', 4),\n",
       " ('DNNCredit Card Fraud Classification', 4),\n",
       " ('LogisticRegressionHotel Satisfaction', 3),\n",
       " ('LogisticRegressionHouse Price Classification', 3),\n",
       " ('KNeighborsClassifierWater Quality Classification', 3),\n",
       " ('SVMClassifier_linerEmployee Attrition', 3),\n",
       " ('LogisticRegressionE-Commerce Shipping', 3),\n",
       " ('KNeighborsClassifierPrinter Sales', 3),\n",
       " ('DecisionTreeClassifierVehicle Insurance Claims', 3),\n",
       " ('MLPClassifierVehicle Insurance Claims', 3),\n",
       " ('KNeighborsClassifierFood Ordering Customer Churn Prediction', 3),\n",
       " ('LogisticRegressionAustralian Credit Approval', 3),\n",
       " ('GradientBoostingClassifierBroadband Sevice Signup', 3),\n",
       " ('SGDClassifierCompany Bankruptcy Prediction', 3),\n",
       " ('SVCReal Estate Investment', 3),\n",
       " ('BernoulliNBEmployee Promotion Prediction', 3),\n",
       " ('LogisticRegressionBasketball Players Career Length Prediction', 3),\n",
       " ('KNeighborsClassifierGerman Credit Evaluation', 3),\n",
       " ('AdaBoostClassifierAir Quality Prediction', 3),\n",
       " ('RandomForestClassifierCredit Risk Classification', 3),\n",
       " ('KNNClassifierAustralian Credit Approval', 3),\n",
       " ('SVCBroadband Sevice Signup', 3),\n",
       " ('KNeighborsClassifierTic-Tac-Toe Strategy', 3),\n",
       " ('BernoulliNBJob Change of Data Scientists', 3),\n",
       " ('LogisticRegressionEmployee Promotion Prediction', 3),\n",
       " ('SVCWater Quality Classification', 3),\n",
       " ('KNNClassifierCar Acceptability Valuation', 3),\n",
       " ('DNNEthereum Fraud Detection', 3),\n",
       " ('LogisticRegressionAir Quality Prediction', 3),\n",
       " ('SVCJob Change of Data Scientists', 3),\n",
       " ('LogisticRegressionPrinter Sales', 3),\n",
       " ('RandomForestClassifierMusic Concert Attendance', 2),\n",
       " ('LogisticRegressionStudent Job Placement', 2),\n",
       " ('BernoulliNBUsed Cars Price-Range Prediction', 2),\n",
       " ('RandomForestClassifierCredit Card Fraud Classification', 2),\n",
       " ('RandomForestClassifierHouse Price Classification', 2),\n",
       " ('KNeighborsClassifierBike Sharing Demand', 2),\n",
       " ('SVCParis House Classification', 2),\n",
       " ('RandomForestClassifierBroadband Sevice Signup', 2),\n",
       " ('SVCFood Ordering Customer Churn Prediction', 2),\n",
       " ('KNeighborsClassifierReal Estate Investment', 2),\n",
       " ('DecisionTreeClassifierHotel Satisfaction', 2),\n",
       " ('SVCTic-Tac-Toe Strategy', 2),\n",
       " ('KNeighborsClassifierE-Commerce Shipping', 2),\n",
       " ('LogisticRegressionBike Sharing Demand', 2),\n",
       " ('SVM_linearMobile Price-Range Classification', 2),\n",
       " ('LogisticRegressionTic-Tac-Toe Strategy', 2),\n",
       " ('RandomForestClassifierEthereum Fraud Detection', 2),\n",
       " ('LGBMClassifierEmployee Promotion Prediction', 2),\n",
       " ('LogisticRegressionAdvertisement Prediction', 2),\n",
       " ('AdaBoostClassifierBasketball Players Career Length Prediction', 2),\n",
       " ('SVCBike Sharing Demand', 2),\n",
       " ('KNeighborsClassifierEthereum Fraud Detection', 2),\n",
       " ('LogisticRegressionBroadband Sevice Signup', 2),\n",
       " ('SVCFlight Price-Range Classification', 2),\n",
       " ('BernoulliNBGerman Credit Evaluation', 2),\n",
       " ('RandomForestClassifierWine Quality Prediction', 2),\n",
       " ('KNeighborsClassifierCompany Bankruptcy Prediction', 2),\n",
       " ('RandomForestClassifierParis House Classification', 2),\n",
       " ('LogisticRegressionVehicle Insurance Claims', 2),\n",
       " ('LogisticRegressionMobile Price-Range Classification', 2),\n",
       " ('KNeighborsClassifierBasketball Players Career Length Prediction', 2),\n",
       " ('RandomForestClassifierAdvertisement Prediction', 2),\n",
       " ('LogisticRegressionAnnual Income Earnings', 2),\n",
       " ('SVCHealth Care Services Satisfaction Prediction', 2),\n",
       " ('RandomForestClassifierPersonal Loan Modelling', 2),\n",
       " ('SGDClassifierJob Change of Data Scientists', 2),\n",
       " ('MLPClassifierHotel Satisfaction', 2),\n",
       " ('BernoulliNBSuspicious Bidding Identification', 1),\n",
       " ('DNNInsurance Churn', 1),\n",
       " ('GradientBoostingClassifierAustralian Credit Approval', 1),\n",
       " ('SVC_linearPersonal Loan Modelling', 1),\n",
       " ('LogisticRegressionSuspicious Bidding Identification', 1),\n",
       " ('SGDClassifierCar Acceptability Valuation', 1),\n",
       " ('RandomForestClassifierBike Sharing Demand', 1),\n",
       " ('LogisticRegressionPersonal Loan Modelling', 1),\n",
       " ('RandomForestClassifierGerman Credit Evaluation', 1),\n",
       " ('GradientBoostingClassifierAnnual Income Earnings', 1),\n",
       " ('LogisticRegressionCustomer Churn Modelling', 1),\n",
       " ('SVCStudent Job Placement', 1),\n",
       " ('GradientBoostingClassifierAir Quality Prediction', 1),\n",
       " ('BernoulliNBWater Quality Classification', 1),\n",
       " ('SVCE-Commerce Shipping', 1),\n",
       " ('KNeighborsClassifierAir Quality Prediction', 1),\n",
       " ('BernoulliNBCab Surge Pricing System', 1),\n",
       " ('DNNBroadband Sevice Signup', 1),\n",
       " ('GradientBoostingClassifierWater Quality Classification', 1),\n",
       " ('BernoulliNBCredit Risk Classification', 1),\n",
       " ('DecisionTreeClassifierAirline Passenger Satisfaction', 1)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(\"james-burton/textual-explanations\", split='train')\n",
    "test = load_dataset(\"james-burton/textual-explanations\", split='test')\n",
    "val = load_dataset(\"james-burton/textual-explanations\", split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(fs) for fs in  train['feature_nums']], bins=50)\n",
    "plt.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving test narrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../jb_data/narrations_only_test.txt', 'w') as f:\n",
    "    for item in test['narration']:\n",
    "        f.writelines(item + '\\n')\n",
    "                \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics for the train set (length 375)\n",
    "\n",
    "The first question is either:\n",
    "* Summarise the prediction (336 times)\n",
    "* Summarise the ranking of the features (39 times)\n",
    "\n",
    "The second question is either:\n",
    "* Give an overview of the top features (250 times)\n",
    "* Give direction of influence of the following features (86 times)\n",
    "* Summarise the ranking of the features (39 times) ACCOUNTED FOR\n",
    "\n",
    "The third question is either:\n",
    "* Compare and contrast the following features (355 times)\n",
    "* 'For these top features, what are the respective directions of influence on the prediction?'(20 times)\n",
    "\n",
    "198 have 4 or more questions\n",
    "* Describe the direction of the following features (121 times)\n",
    "* Summarise the unimportant features (73 times)\n",
    "* 'Describe the degree of impact of the following features: [blank]?' (4 times)\n",
    "\n",
    "39 have 5 or more questions\n",
    "* 'Provide a statement on the features with the least impact on the prediction made for this test case.' (39 times) ACCOUNTED FOR\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "reg = re.compile(r'F\\d+')\n",
    "Counter([l['narrative_questions'][1] for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the prediction made for the test case.']).most_common()\n",
    "[[' '.join(reg.findall(n)) for n in l['narrative_questions']] for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the prediction made for the test case.']\n",
    "[' '.join(l['feature_nums']) for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the prediction made for the test case.']\n",
    "```\n",
    "A. For 99 cases the format is:\n",
    "* 'In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).'\n",
    "* \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\"\n",
    "* 'Describe the degree of impact of the following features: [0-4 fts (after first 7-9)]?' (3 times there are 0)\n",
    "\n",
    "B. For 78 cases the format is:\n",
    "* \"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\" -->\n",
    "* \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\"\n",
    "* 'Summarize the direction of influence of the features [the next 3-4 features (after first 2-4)] with moderate impact on the prediction made for this test case.'\n",
    "\n",
    "C. For 53 cases the format is:\n",
    "* 'Summarize the prediction for the given test example?'\n",
    "* \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\"\n",
    "* 'Compare and contrast the impact of the following attributes  [3-4 seemingly random features] on the models prediction of [C1/C2].'\n",
    "* 'Summarize the set of features has little to no impact on the prediction?'\n",
    "\n",
    "D. For 20 cases the format is:\n",
    "* 'Summarize the prediction for the given test example?'\n",
    "* 'For this test case, summarize the top features influencing the model's decision.'\n",
    "* 'For these top features, what are the respective directions of influence on the prediction?'\n",
    "* 'Provide a statement on the set of features has limited impact on the prediction of [C1/C2] by the model for the given test example?'\n",
    "\n",
    "E. For 39 cases the format is:\n",
    "* 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.'\n",
    "* 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.'\n",
    "* 'Compare the direction of impact of the features: [2-5 top features].'\n",
    "* 'Summarize the direction of influence of the features [the next 3-4 features] with moderate impact on the prediction made for this test case.'\n",
    "* 'Provide a statement on the features with the least impact on the prediction made for this test case.'\n",
    "\n",
    "F. For 44 cases the format is:\n",
    "* 'Provide a statement summarizing the prediction made for the test case.'\n",
    "* 'For the current test instance, describe the direction of influence of the following features: [2-5 top features]'\n",
    "* 'Compare and contrast the impact of the following features [the next 3-4 features] on the models prediction of [C1/C2].'\n",
    "* 'Describe the degree of impact of the following features: [the next 0-4 features]?' (usually 4 unless there are not enough features)\n",
    "\n",
    "G. For 39 cases the format is:\n",
    "* 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.'\n",
    "* 'Summarize the direction of influence of the features [2-5 top features] on the prediction made for this test case.'\n",
    "* 'Compare the direction of impact of the features: [the next 3-4 features].'\n",
    "* 'Describe the degree of impact of the following features:[the next 0-4 features]'\n",
    "\n",
    "H. For 3 cases the format is:\n",
    "* 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.'\n",
    "* 'Summarize the direction of influence of the variables [2-3 top features] on the prediction made for this test case.' -->\n",
    "* 'Compare the direction of impact of the variables: [the next 3-4 features].'\n",
    "* 'Describe the degree of impact of the following variables: [the next 3-4 features]?'\n",
    "\n",
    "| Q | A | New Q |\n",
    "| ---- | ---- | ---- |\n",
    "| Summarise the prediction | Note: In E (39) this question is asked across 2 sentences | Summarise the prediction |\n",
    "| Summarise the top features | A-D (250): Top features aren't named, just says 'top features' | a) Summarise the top features |\n",
    "|   | E-H  (125) specifies 2-5 top features | b) Summarise these top features ([fts]) |\n",
    "|   | Note: In D (20) this question is asked across 2 sentences |   |\n",
    "| Summarise moderate fts | A (99): 3-4 named fts (after first 7-9) | Summarise these moderate features ([fts]) |\n",
    "|   | B, C (131): 3-4 named fts (after first 2-4) |   |\n",
    "|   | E-H (125) named fts (the next 3-4) |   |\n",
    "|   | Note: D (20) does not have this Q\n",
    "| Summarise more/lower fts | C-E (112) describe fts with little to no impact (fts not named) | a) Summarise the negligible features |\n",
    "|   | F-H (86) 0-4 named fts | b) Summarise these negligible features ([fts]) |\n",
    "|   | Note: A,B (177) do not have a 4th Q |   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  99),\n",
       " (\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  78),\n",
       " ('Summarize the prediction for the given test example?', 73),\n",
       " ('Provide a statement summarizing the prediction made for the test case.',\n",
       "  44),\n",
       " ('Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  42),\n",
       " ('Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  39)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([l['narrative_questions'][0] for l in train ]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', 'F5 F18 F1', ''],\n",
       " ['', '', 'F10 F12 F2 F21', ''],\n",
       " ['', '', 'F3 F10 F2 F6', ''],\n",
       " ['', '', 'F11 F2 F10 F15', ''],\n",
       " ['', '', 'F31 F15 F7', ''],\n",
       " ['', '', 'F4 F13 F16 F14', ''],\n",
       " ['', '', 'F3 F14 F11 F8', ''],\n",
       " ['', '', 'F2 F4 F5', ''],\n",
       " ['', '', 'F3 F13 F15', ''],\n",
       " ['', '', 'F12 F11 F19', ''],\n",
       " ['', '', 'F9 F59 F63', ''],\n",
       " ['', '', 'F13 F7 F18 F21', ''],\n",
       " ['', '', 'F24 F14 F30 F18', ''],\n",
       " ['', '', 'F4 F7 F5 F2', ''],\n",
       " ['', '', 'F4 F1 F14', ''],\n",
       " ['', '', 'F17 F26 F15', ''],\n",
       " ['', '', 'F8 F7 F1 F4', ''],\n",
       " ['', '', 'F11 F9 F4', ''],\n",
       " ['', '', 'F7 F2 F8', ''],\n",
       " ['', '', 'F15 F5 F4', ''],\n",
       " ['', '', 'F2 F10 F1 F4', ''],\n",
       " ['', '', 'F18 F12 F30 F10', ''],\n",
       " ['', '', 'F8 F7 F9 F1', ''],\n",
       " ['', '', 'F4 F10 F5 F9', ''],\n",
       " ['', '', 'F7 F6 F8', ''],\n",
       " ['', '', 'F4 F9 F7', ''],\n",
       " ['', '', 'F19 F22 F4', ''],\n",
       " ['', '', 'F8 F6 F4 F3', ''],\n",
       " ['', '', 'F9 F3 F2 F10', ''],\n",
       " ['', '', 'F2 F4 F6', ''],\n",
       " ['', '', 'F5 F6 F7', ''],\n",
       " ['', '', 'F8 F5 F7 F1', ''],\n",
       " ['', '', 'F9 F8 F16 F15', ''],\n",
       " ['', '', 'F3 F9 F12', ''],\n",
       " ['', '', 'F10 F3 F1', ''],\n",
       " ['', '', 'F2 F8 F4 F1', ''],\n",
       " ['', '', 'F9 F15 F1', ''],\n",
       " ['', '', 'F7 F4 F3 F2', ''],\n",
       " ['', '', 'F9 F7 F8', ''],\n",
       " ['', '', 'F1 F5 F7 F8', ''],\n",
       " ['', '', 'F16 F1 F5 F9', ''],\n",
       " ['', '', 'F1 F8 F7 F6', ''],\n",
       " ['', '', 'F29 F4 F45', ''],\n",
       " ['', '', 'F21 F20 F1', ''],\n",
       " ['', '', 'F10 F1 F7 F9', ''],\n",
       " ['', '', 'F12 F22 F20', ''],\n",
       " ['', '', 'F31 F42 F43', ''],\n",
       " ['', '', 'F3 F5 F7 F6', ''],\n",
       " ['', '', 'F10 F4 F6 F3', ''],\n",
       " ['', '', 'F3 F7 F1', ''],\n",
       " ['', '', 'F11 F8 F10 F7', ''],\n",
       " ['', '', 'F20 F30 F12', ''],\n",
       " ['', '', 'F6 F3 F2 F4', '']]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[' '.join(reg.findall(n)) for n in l['narrative_questions']] for l in train if all((l['narrative_questions'][1] == \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\", 1==1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F3 F20 F10 F5 F18 F1 F17 F4 F15 F14 F19 F9 F16 F12 F6 F2 F7 F11 F8 F13',\n",
       " 'F22 F12 F23 F9 F5 F26 F21 F3 F1 F13 F15 F25 F8 F10 F17 F20 F14 F24 F6 F7 F11 F18 F16 F19 F2 F4',\n",
       " 'F11 F7 F3 F10 F2 F6 F9 F1 F8 F12 F4 F5',\n",
       " 'F8 F14 F11 F2 F10 F15 F6 F16 F3 F12 F7 F4 F1 F13 F9 F5 F17',\n",
       " 'F11 F46 F8 F36 F31 F15 F7 F29 F10 F35 F16 F38 F39 F6 F24 F30 F1 F26 F44 F14 F17 F9 F13 F19 F45 F18 F12 F42 F5 F34 F2 F37 F28 F23 F20 F4 F25 F32 F40 F22 F21 F27 F43 F33 F3 F41',\n",
       " 'F8 F2 F4 F13 F16 F14 F7 F3 F11 F12 F10 F5 F17 F1 F9 F6 F15',\n",
       " 'F2 F4 F3 F14 F11 F8 F17 F7 F10 F6 F16 F19 F18 F1 F15 F5 F9 F13 F12',\n",
       " 'F7 F9 F1 F2 F4 F5 F8 F3 F6',\n",
       " 'F12 F6 F8 F3 F13 F15 F5 F1 F10 F2 F9 F14 F7 F11 F4',\n",
       " 'F26 F6 F16 F18 F4 F12 F11 F19 F22 F25 F23 F24 F2 F3 F13 F21 F17 F7 F20 F1 F5 F8 F9 F10 F14 F15',\n",
       " 'F51 F26 F4 F55 F9 F59 F63 F6 F32 F28 F89 F50 F10 F43 F57 F65 F54 F19 F8 F42 F67 F45 F11 F71 F39 F87 F56 F73 F17 F22 F16 F23 F80 F60 F62 F88 F38 F91 F36 F52 F47 F5 F46 F49 F81 F68 F90 F2 F40 F1 F77 F93 F76 F75 F24 F21 F74 F35 F53 F85 F58 F83 F78 F14 F79 F33 F82 F20 F3 F64 F31 F27 F70 F18 F72 F7 F66 F13 F41 F84 F69 F29 F34 F92 F15 F48 F12 F44 F86 F30 F25 F61 F37',\n",
       " 'F1 F24 F13 F7 F18 F21 F17 F14 F2 F16 F19 F20 F6 F5 F10 F11 F12 F22 F3 F23 F25 F26 F9 F4 F15 F8',\n",
       " 'F27 F12 F24 F14 F30 F18 F26 F2 F20 F22 F13 F21 F17 F23 F10 F28 F25 F5 F6 F8 F15 F7 F9 F29 F11 F1 F16 F19 F3 F4',\n",
       " 'F12 F11 F4 F7 F5 F2 F6 F9 F1 F3 F10 F8',\n",
       " 'F5 F12 F11 F4 F1 F14 F3 F6 F2 F8 F13 F9 F7 F10',\n",
       " 'F1 F7 F2 F8 F3 F17 F26 F15 F4 F19 F6 F24 F25 F13 F10 F23 F21 F12 F11 F16 F14 F18 F9 F20 F5 F22',\n",
       " 'F6 F5 F8 F7 F1 F4 F2 F3 F10 F9',\n",
       " 'F16 F15 F5 F3 F12 F11 F9 F4 F6 F1 F13 F2 F14 F10 F8 F7',\n",
       " 'F9 F6 F10 F5 F4 F7 F2 F8 F1 F3',\n",
       " 'F11 F10 F3 F15 F5 F4 F9 F2 F7 F6 F14 F12 F8 F13 F1',\n",
       " 'F12 F8 F2 F10 F1 F4 F6 F7 F3 F9 F11 F5',\n",
       " 'F23 F1 F18 F12 F30 F10 F11 F16 F29 F24 F8 F15 F7 F28 F9 F17 F14 F6 F25 F26 F5 F2 F4 F27 F21 F13 F20 F22 F3 F19',\n",
       " 'F5 F2 F8 F7 F9 F1 F10 F6 F3 F4',\n",
       " 'F7 F3 F4 F10 F5 F9 F12 F1 F6 F2 F8 F11',\n",
       " 'F4 F11 F9 F7 F6 F8 F5 F2 F12 F10 F1 F14 F3 F13',\n",
       " 'F5 F3 F8 F4 F9 F7 F1 F2 F6',\n",
       " 'F15 F2 F6 F9 F18 F19 F22 F4 F8 F10 F11 F7 F23 F25 F3 F12 F24 F14 F21 F20 F13 F16 F1 F26 F17 F5',\n",
       " 'F10 F9 F8 F6 F4 F3 F11 F2 F5 F7 F1',\n",
       " 'F1 F7 F9 F3 F2 F10 F4 F8 F5 F6',\n",
       " 'F13 F1 F9 F14 F16 F2 F4 F6 F8 F5 F7 F15 F10 F3 F11 F12',\n",
       " 'F1 F3 F9 F5 F6 F7 F11 F10 F8 F2 F4',\n",
       " 'F11 F6 F8 F5 F7 F1 F4 F9 F2 F3 F10',\n",
       " 'F12 F3 F9 F8 F16 F15 F5 F7 F17 F13 F10 F4 F1 F14 F6 F2 F11',\n",
       " 'F8 F10 F16 F3 F9 F12 F4 F1 F20 F14 F15 F18 F13 F11 F6 F2 F7 F17 F19 F5',\n",
       " 'F4 F5 F13 F6 F10 F3 F1 F9 F8 F2 F12 F11 F7',\n",
       " 'F7 F10 F2 F8 F4 F1 F9 F3 F6 F5',\n",
       " 'F14 F11 F6 F8 F10 F9 F15 F1 F5 F3 F12 F7 F2 F4 F16 F13',\n",
       " 'F6 F1 F7 F4 F3 F2 F9 F5 F8',\n",
       " 'F1 F5 F10 F12 F9 F7 F8 F3 F2 F11 F4 F6 F13',\n",
       " 'F4 F2 F1 F5 F7 F8 F9 F3 F6',\n",
       " 'F2 F7 F16 F1 F5 F9 F14 F18 F17 F19 F8 F15 F4 F10 F3 F20 F12 F13 F6 F11',\n",
       " 'F5 F2 F1 F8 F7 F6 F3 F9 F4',\n",
       " 'F40 F8 F5 F22 F6 F29 F4 F45 F27 F36 F7 F35 F42 F2 F23 F21 F13 F9 F33 F1 F30 F32 F28 F39 F14 F37 F46 F19 F43 F17 F12 F16 F3 F10 F26 F18 F20 F15 F44 F11 F38 F31 F24 F34 F25 F41',\n",
       " 'F6 F5 F11 F26 F25 F21 F20 F1 F15 F7 F24 F3 F14 F4 F18 F13 F16 F2 F19 F23 F10 F8 F9 F22 F17 F12',\n",
       " 'F2 F11 F10 F1 F7 F9 F3 F5 F12 F8 F4 F6',\n",
       " 'F27 F1 F29 F12 F22 F20 F8 F15 F10 F3 F2 F5 F7 F28 F23 F11 F14 F21 F30 F19 F6 F25 F9 F16 F4 F26 F13 F18 F17 F24',\n",
       " 'F38 F19 F46 F40 F17 F31 F42 F43 F5 F37 F39 F28 F7 F1 F10 F16 F3 F25 F6 F27 F9 F44 F22 F34 F33 F30 F14 F32 F4 F8 F26 F20 F45 F21 F29 F13 F36 F41 F35 F18 F23 F15 F12 F2 F24 F11',\n",
       " 'F11 F9 F3 F5 F7 F6 F1 F12 F8 F4 F10 F2',\n",
       " 'F9 F5 F10 F4 F6 F3 F15 F13 F7 F16 F8 F1 F2 F11 F14 F17 F12',\n",
       " 'F9 F8 F4 F5 F10 F3 F7 F1 F6 F2',\n",
       " 'F5 F1 F11 F8 F10 F7 F3 F4 F12 F9 F2 F6',\n",
       " 'F28 F13 F1 F20 F30 F12 F10 F6 F14 F16 F15 F21 F3 F22 F18 F8 F11 F9 F24 F29 F25 F5 F27 F23 F7 F19 F2 F17 F4 F26',\n",
       " 'F5 F1 F6 F3 F2 F4']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(l['feature_nums']) for l in train if all((l['narrative_questions'][1] == , 1==1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Provide a statement on the features with the least impact on the prediction made for this test case.',\n",
       "  39)]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([l['narrative_questions'][4] for l in train if all((l['narrative_questions'][0] == 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.', l['narrative_questions'][1]=='Provide a statement summarizing the ranking of the features as shown in the feature impact plot.'))]).most_common()\n",
    "# Counter([len(l['narrative_questions']) for l in train if l['narrative_questions'][0] == 'In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.42 F2 -0.24 F4 -0.11 F6 -0.09 F1 -0.05 F3 -0.04 F5',\n",
       " '0.08 F16 0.06 F19 -0.00 F1 0.00 F12 0.00 F17 -0.00 F6 0.00 F8 0.00 F7 -0.00 F4 0.00 F15 -0.00 F9 0.00 F11 0.00 F5 0.00 F18 0.00 F14 0.00 F3 0.00 F13 -0.00 F10 0.00 F2',\n",
       " '0.10 F24 0.07 F14 0.06 F16 0.06 F1 0.03 F21 0.03 F13 -0.02 F26 0.02 F25 0.02 F5 -0.02 F11 -0.02 F22 0.02 F18 0.02 F2 0.01 F10 -0.01 F20 -0.01 F6 -0.01 F19 0.01 F17 0.01 F8 0.01 F15 0.00 F3 0.00 F9 0.00 F7 0.00 F4 0.00 F12 0.00 F23',\n",
       " '0.78 F19 0.14 F12 0.11 F17 -0.04 F4 -0.03 F15 0.03 F14 0.03 F8 0.02 F18 -0.02 F5 -0.02 F11 0.02 F2 -0.02 F3 -0.01 F6 -0.01 F7 0.01 F13 0.01 F20 -0.01 F1 -0.01 F9 -0.00 F16 -0.00 F10',\n",
       " '0.53 F10 0.32 F2 0.18 F5 0.15 F8 0.13 F6 0.05 F1 -0.04 F3 -0.03 F9 -0.00 F4 0.00 F7',\n",
       " '-0.38 F6 0.26 F7 0.26 F3 0.22 F1 -0.22 F9 -0.16 F4 -0.16 F2 0.16 F5 -0.01 F8',\n",
       " '0.47 F5 0.22 F7 0.20 F3 0.19 F2 0.05 F6 0.01 F4 0.01 F1',\n",
       " '0.47 F2 0.23 F8 0.20 F4 0.08 F9 -0.07 F7 0.05 F3 0.05 F6 -0.02 F5 -0.01 F1',\n",
       " '0.12 F1 -0.12 F3 -0.09 F2 0.09 F6 -0.08 F10 0.06 F4 -0.06 F7 0.05 F12 -0.04 F8 -0.02 F9 0.01 F5 -0.00 F11',\n",
       " '0.14 F1 0.10 F8 -0.07 F6 0.07 F2 -0.04 F3 -0.03 F12 -0.02 F11 0.02 F9 -0.01 F10 0.01 F5 0.01 F7 -0.00 F4',\n",
       " '0.13 F27 -0.07 F4 -0.04 F17 0.04 F22 0.04 F7 0.03 F14 0.03 F11 -0.03 F15 0.03 F23 0.02 F16 0.02 F24 0.02 F26 0.02 F12 0.02 F30 0.01 F21 -0.01 F18 0.01 F10 0.01 F25 0.01 F9 -0.01 F8 0.00 F19 0.00 F3 0.00 F1 0.00 F6 0.00 F5 0.00 F20 0.00 F29 0.00 F28 0.00 F2 0.00 F13',\n",
       " '-0.01 F7 -0.01 F2 0.01 F9 0.01 F8 -0.01 F1 0.00 F3 0.00 F6 0.00 F4 0.00 F5',\n",
       " '0.14 F12 0.10 F17 -0.08 F8 -0.07 F16 -0.07 F9 0.07 F24 0.06 F14 -0.06 F34 -0.06 F23 0.06 F29 -0.05 F1 -0.05 F38 -0.05 F37 0.03 F18 -0.02 F6 -0.02 F22 0.02 F25 0.02 F7 -0.01 F10 0.01 F4 0.00 F32 0.00 F28 0.00 F13 0.00 F27 0.00 F26 0.00 F36 0.00 F15 0.00 F11 0.00 F2 0.00 F33 0.00 F35 0.00 F20 0.00 F3 0.00 F30 0.00 F19 0.00 F5 0.00 F21 0.00 F31',\n",
       " '0.33 F14 -0.06 F7 0.03 F17 -0.02 F18 -0.02 F15 0.02 F24 -0.02 F32 -0.02 F30 0.02 F10 -0.01 F6 0.01 F1 -0.01 F12 0.01 F20 0.01 F27 -0.01 F2 -0.01 F11 -0.01 F16 -0.01 F28 0.01 F13 -0.01 F33 0.00 F4 0.00 F3 0.00 F8 0.00 F9 0.00 F19 0.00 F31 0.00 F5 0.00 F22 0.00 F21 0.00 F26 0.00 F29 0.00 F23 0.00 F25',\n",
       " '0.24 F4 0.20 F3 0.06 F9 -0.06 F7 0.04 F8 -0.04 F1 -0.04 F6 -0.03 F10 -0.03 F2 -0.02 F12 -0.01 F11 -0.00 F5',\n",
       " '0.32 F4 0.28 F12 0.07 F16 0.01 F1 -0.01 F8 0.01 F17 -0.01 F7 0.01 F14 0.00 F10 0.00 F9 0.00 F2 -0.00 F5 0.00 F6 0.00 F3 -0.00 F11 0.00 F15 -0.00 F13',\n",
       " '0.78 F3 -0.07 F8 0.06 F9 -0.06 F12 -0.02 F5 0.02 F10 0.02 F17 -0.02 F19 -0.01 F11 -0.01 F14 -0.01 F15 -0.01 F20 0.01 F6 -0.01 F18 -0.01 F4 0.01 F7 0.00 F1 -0.00 F16 -0.00 F13 0.00 F2',\n",
       " '0.15 F2 0.14 F9 -0.11 F1 -0.07 F3 -0.02 F8 -0.02 F5 0.01 F6 0.01 F7 0.00 F4 -0.00 F10',\n",
       " '0.10 F12 0.07 F19 0.06 F20 0.06 F26 0.03 F10 0.03 F22 -0.02 F9 0.02 F7 0.02 F23 -0.02 F15 -0.02 F24 0.02 F16 0.02 F6 0.01 F25 -0.01 F11 -0.01 F21 -0.01 F4 0.01 F13 0.01 F2 0.01 F17 0.00 F18 0.00 F3 0.00 F1 0.00 F8 0.00 F14 0.00 F5',\n",
       " '0.10 F7 -0.02 F3 0.01 F11 -0.01 F4 0.01 F1 0.01 F2 -0.00 F8 -0.00 F6 -0.00 F10 -0.00 F9 -0.00 F5',\n",
       " '0.36 F6 0.24 F3 -0.17 F10 0.15 F8 -0.09 F9 0.09 F4 0.04 F1 0.03 F7 -0.02 F11 -0.01 F2 -0.00 F12 -0.00 F5',\n",
       " '0.46 F9 -0.11 F7 -0.10 F3 0.07 F10 0.07 F5 -0.04 F11 -0.04 F4 -0.03 F2 0.03 F6 0.01 F8 0.01 F1 0.00 F12',\n",
       " '-0.16 F5 0.12 F4 0.07 F10 -0.05 F6 -0.05 F7 0.02 F9 -0.01 F3 0.01 F1 0.01 F8 0.00 F2',\n",
       " '0.34 F1 -0.04 F5 0.04 F6 0.02 F2 -0.02 F8 0.01 F9 0.01 F4 -0.00 F3 -0.00 F7',\n",
       " '0.14 F23 0.10 F4 -0.08 F31 -0.07 F9 -0.07 F35 0.07 F14 0.06 F5 -0.06 F25 -0.06 F3 0.06 F8 -0.05 F18 -0.05 F36 -0.05 F34 0.03 F1 -0.02 F22 -0.02 F10 0.02 F33 0.02 F29 -0.01 F16 0.01 F11 0.00 F17 0.00 F13 0.00 F30 0.00 F7 0.00 F27 0.00 F38 0.00 F26 0.00 F32 0.00 F2 0.00 F19 0.00 F24 0.00 F15 0.00 F6 0.00 F20 0.00 F37 0.00 F21 0.00 F12 0.00 F28',\n",
       " '0.10 F25 0.07 F5 0.06 F3 0.06 F7 0.03 F4 0.03 F20 -0.02 F26 0.02 F15 0.02 F9 -0.02 F18 -0.02 F2 0.02 F11 0.02 F6 0.01 F17 -0.01 F16 -0.01 F23 -0.01 F10 0.01 F22 0.01 F8 0.01 F21 0.00 F1 0.00 F13 0.00 F12 0.00 F24 0.00 F14 0.00 F19',\n",
       " '-0.10 F11 -0.09 F6 0.09 F2 0.07 F10 0.04 F3 -0.03 F7 0.02 F4 0.02 F8 -0.01 F1 0.01 F9 -0.01 F5 0.00 F12',\n",
       " '0.33 F9 -0.04 F20 -0.03 F2 -0.03 F22 -0.03 F12 0.03 F1 -0.02 F21 -0.02 F17 -0.02 F28 -0.02 F15 0.02 F18 0.02 F13 0.02 F5 0.01 F19 -0.01 F7 -0.01 F27 0.01 F29 0.01 F24 0.01 F14 0.01 F4 0.00 F33 0.00 F23 0.00 F32 0.00 F6 0.00 F16 0.00 F31 0.00 F25 0.00 F11 0.00 F8 0.00 F10 0.00 F26 0.00 F3 0.00 F30',\n",
       " '0.29 F4 0.24 F1 0.17 F7 0.05 F9 -0.04 F5 0.04 F6 0.02 F11 -0.02 F12 -0.02 F3 0.01 F2 -0.00 F10 -0.00 F8',\n",
       " '0.18 F8 0.13 F12 0.09 F4 -0.09 F6 -0.08 F7 0.07 F9 -0.07 F3 -0.06 F1 0.06 F2 -0.04 F5 0.04 F10 -0.03 F11',\n",
       " '-0.46 F3 0.21 F6 0.15 F2 -0.06 F4 0.05 F7 0.03 F5 -0.03 F8 -0.01 F9 -0.00 F1',\n",
       " '0.01 F63 0.01 F49 0.01 F64 -0.01 F67 0.00 F90 0.00 F93 0.00 F45 0.00 F20 0.00 F48 0.00 F23 0.00 F13 0.00 F73 0.00 F35 -0.00 F30 -0.00 F50 -0.00 F3 0.00 F14 -0.00 F52 0.00 F9 0.00 F69 0.00 F38 0.00 F65 0.00 F72 0.00 F87 0.00 F58 0.00 F57 0.00 F11 0.00 F37 0.00 F61 0.00 F21 0.00 F32 0.00 F6 0.00 F80 0.00 F36 0.00 F44 0.00 F17 0.00 F19 0.00 F2 0.00 F8 0.00 F47 0.00 F77 0.00 F68 0.00 F43 0.00 F66 0.00 F54 0.00 F76 0.00 F34 0.00 F25 0.00 F41 0.00 F89 0.00 F5 0.00 F88 0.00 F16 0.00 F81 0.00 F51 0.00 F31 0.00 F55 0.00 F53 0.00 F91 0.00 F12 0.00 F75 0.00 F39 0.00 F62 0.00 F82 0.00 F24 0.00 F71 0.00 F42 0.00 F86 0.00 F70 0.00 F78 0.00 F26 0.00 F79 0.00 F33 0.00 F84 0.00 F10 0.00 F59 0.00 F7 0.00 F18 0.00 F40 0.00 F29 0.00 F74 0.00 F15 0.00 F85 0.00 F46 0.00 F22 0.00 F83 0.00 F1 0.00 F56 0.00 F60 0.00 F28 0.00 F27 0.00 F4 0.00 F92',\n",
       " '0.12 F4 0.09 F21 -0.09 F9 0.08 F30 0.07 F25 0.07 F12 0.07 F5 0.06 F20 0.05 F10 0.05 F8 -0.05 F6 -0.02 F1 0.02 F28 0.02 F15 -0.02 F24 0.02 F2 0.01 F11 0.01 F23 0.01 F26 -0.01 F14 -0.00 F17 -0.00 F29 0.00 F13 0.00 F18 -0.00 F3 -0.00 F16 -0.00 F7 0.00 F27 -0.00 F22 -0.00 F19',\n",
       " '0.12 F4 0.07 F1 0.07 F7 -0.05 F15 0.04 F6 -0.04 F14 -0.03 F25 0.03 F21 -0.02 F11 -0.02 F13 0.02 F29 -0.02 F10 -0.02 F26 -0.02 F20 -0.02 F22 -0.01 F5 -0.01 F8 -0.01 F17 0.01 F12 -0.01 F24 0.00 F9 0.00 F2 0.00 F16 0.00 F23 0.00 F27 0.00 F3 0.00 F28 0.00 F30 0.00 F18 0.00 F19',\n",
       " '0.20 F2 0.17 F7 0.12 F8 0.11 F6 -0.10 F10 -0.04 F1 0.04 F5 0.02 F3 0.01 F4 0.00 F9',\n",
       " '0.38 F9 0.36 F13 0.13 F5 0.03 F1 -0.02 F12 0.01 F6 -0.01 F3 -0.01 F16 -0.01 F14 -0.01 F17 0.00 F2 -0.00 F11 -0.00 F8 -0.00 F7 -0.00 F4 -0.00 F10 0.00 F15',\n",
       " '0.29 F6 0.24 F11 0.17 F12 0.05 F1 -0.04 F10 0.04 F4 0.02 F2 -0.02 F8 -0.02 F3 0.01 F9 -0.00 F5 -0.00 F7',\n",
       " '0.20 F30 0.03 F5 -0.03 F33 0.03 F10 -0.03 F11 -0.03 F9 -0.03 F6 0.02 F25 0.02 F12 0.02 F15 0.02 F27 -0.02 F1 0.02 F24 -0.02 F31 -0.01 F22 -0.01 F7 -0.01 F32 -0.01 F4 0.01 F20 0.01 F18 0.00 F23 0.00 F14 0.00 F19 0.00 F28 0.00 F29 0.00 F26 0.00 F13 0.00 F2 0.00 F16 0.00 F17 0.00 F3 0.00 F8 0.00 F21',\n",
       " '0.34 F4 -0.04 F3 0.04 F8 0.02 F1 -0.02 F5 0.01 F2 0.01 F7 -0.00 F6 -0.00 F9',\n",
       " '0.27 F10 -0.22 F2 -0.14 F14 -0.07 F15 0.06 F8 0.05 F11 -0.05 F12 0.03 F4 0.02 F5 -0.02 F1 -0.01 F13 -0.01 F7 -0.00 F9 -0.00 F3 0.00 F6',\n",
       " '0.53 F2 0.38 F13 0.32 F19 -0.11 F20 0.09 F10 0.08 F14 0.08 F3 -0.07 F15 0.06 F17 -0.06 F11 -0.06 F9 0.05 F18 0.05 F22 -0.04 F16 0.04 F5 0.04 F4 -0.03 F7 -0.02 F21 0.02 F8 -0.01 F6 0.00 F1 0.00 F12',\n",
       " '-0.38 F1 0.26 F3 0.26 F6 0.22 F9 -0.22 F2 -0.16 F7 -0.16 F8 0.16 F4 -0.01 F5',\n",
       " '0.28 F8 0.12 F9 -0.07 F11 0.05 F10 0.03 F4 0.03 F2 -0.01 F6 -0.01 F3 0.01 F1 -0.01 F5 0.00 F7',\n",
       " '0.43 F2 0.25 F6 0.13 F3 0.07 F1 0.07 F5 -0.03 F4 -0.02 F7',\n",
       " '-0.01 F3 -0.01 F2 0.01 F5 0.01 F4 -0.01 F6 0.00 F8 0.00 F1 0.00 F7 0.00 F9',\n",
       " '0.62 F1 0.40 F2 -0.21 F8 -0.10 F5 0.09 F3 -0.09 F7 0.01 F4 0.00 F6',\n",
       " '0.19 F23 -0.14 F13 -0.14 F24 0.14 F30 0.10 F43 0.10 F18 -0.09 F27 0.08 F5 -0.08 F21 -0.08 F31 0.07 F6 0.06 F39 0.06 F38 -0.06 F19 -0.06 F20 -0.05 F8 0.05 F2 0.05 F16 -0.04 F9 0.04 F33 0.00 F26 0.00 F4 0.00 F7 0.00 F25 0.00 F3 0.00 F22 0.00 F42 0.00 F46 0.00 F15 0.00 F40 0.00 F44 0.00 F34 0.00 F10 0.00 F45 0.00 F41 0.00 F17 0.00 F36 0.00 F12 0.00 F14 0.00 F37 0.00 F11 0.00 F1 0.00 F29 0.00 F32 0.00 F35 0.00 F28',\n",
       " '-0.43 F12 0.27 F6 -0.24 F7 -0.20 F4 0.13 F5 -0.08 F2 -0.06 F1 -0.03 F8 0.02 F3 0.01 F11 -0.01 F10 -0.01 F9',\n",
       " '0.38 F14 0.36 F7 0.13 F1 0.03 F13 -0.02 F12 0.01 F17 -0.01 F11 -0.01 F6 -0.01 F4 -0.01 F5 0.00 F15 -0.00 F10 -0.00 F3 -0.00 F16 -0.00 F9 -0.00 F2 0.00 F8',\n",
       " '0.43 F10 0.43 F2 -0.28 F1 0.17 F7 -0.08 F3 -0.03 F4 0.03 F5 0.02 F8 0.01 F9 0.00 F6',\n",
       " '0.30 F26 -0.17 F22 0.12 F11 0.07 F14 -0.06 F13 -0.06 F10 0.05 F18 -0.05 F12 0.05 F15 -0.04 F5 -0.03 F6 0.03 F4 0.02 F21 0.02 F7 0.02 F3 0.02 F17 0.02 F1 0.01 F23 -0.01 F24 0.01 F9 0.00 F16 0.00 F25 0.00 F19 0.00 F2 0.00 F8 0.00 F20',\n",
       " '-0.28 F25 0.26 F3 0.17 F12 0.13 F8 -0.13 F20 0.10 F21 0.07 F19 -0.06 F1 0.05 F18 0.04 F24 -0.03 F17 0.03 F11 -0.03 F15 -0.03 F7 -0.02 F22 0.02 F10 0.02 F2 0.02 F13 0.02 F5 -0.02 F14 0.00 F16 0.00 F23 0.00 F4 0.00 F9 0.00 F6 0.00 F26',\n",
       " '0.21 F5 -0.02 F11 -0.02 F3 -0.02 F9 0.02 F6 0.01 F4 -0.01 F12 0.01 F2 0.01 F1 0.01 F8 0.00 F10 0.00 F7',\n",
       " '0.04 F8 0.02 F12 0.02 F9 -0.01 F5 -0.01 F10 -0.01 F2 0.01 F7 -0.01 F1 -0.00 F3 0.00 F4 0.00 F11 -0.00 F6',\n",
       " '0.04 F1 0.04 F12 0.03 F15 -0.03 F14 -0.02 F3 0.02 F4 0.01 F13 0.01 F8 -0.01 F2 -0.01 F11 -0.01 F16 0.01 F5 0.00 F10 0.00 F9 0.00 F6 -0.00 F7',\n",
       " '0.39 F3 0.09 F1 -0.05 F9 -0.02 F12 -0.02 F8 -0.02 F11 -0.02 F5 -0.01 F7 0.01 F10 0.01 F6 -0.00 F4 0.00 F2',\n",
       " '-0.32 F2 -0.14 F4 -0.08 F8 0.07 F10 0.04 F1 0.03 F11 -0.02 F9 -0.02 F3 0.01 F7 -0.01 F5 0.01 F6',\n",
       " '0.12 F5 0.09 F6 -0.09 F10 0.08 F13 0.07 F28 0.07 F3 0.07 F25 0.06 F22 0.05 F23 0.05 F7 -0.05 F18 -0.02 F1 0.02 F26 0.02 F8 -0.02 F2 0.02 F4 0.01 F15 0.01 F29 0.01 F20 -0.01 F21 -0.00 F24 -0.00 F27 0.00 F16 0.00 F11 -0.00 F17 -0.00 F14 -0.00 F19 0.00 F30 -0.00 F9 -0.00 F12',\n",
       " '0.10 F5 -0.02 F6 0.01 F8 -0.01 F9 0.01 F1 0.01 F3 -0.00 F4 -0.00 F10 -0.00 F7 -0.00 F2 -0.00 F11',\n",
       " '0.34 F9 -0.04 F4 0.04 F5 0.02 F8 -0.02 F6 0.01 F7 0.01 F1 -0.00 F3 -0.00 F2',\n",
       " '0.48 F12 0.48 F15 0.11 F1 -0.10 F2 -0.07 F6 0.07 F11 0.06 F4 0.05 F13 0.05 F5 0.05 F9 -0.04 F14 -0.04 F3 0.02 F8 0.01 F10 -0.00 F7',\n",
       " '0.32 F5 0.18 F7 0.17 F6 0.07 F1 0.05 F8 0.05 F4 0.04 F3 0.03 F2',\n",
       " '-0.04 F16 0.03 F8 0.03 F2 0.03 F12 0.03 F13 -0.03 F10 -0.02 F9 0.02 F11 0.02 F14 0.02 F5 -0.02 F7 -0.01 F1 0.01 F6 -0.01 F4 0.00 F15 -0.00 F3',\n",
       " '-0.31 F13 0.05 F4 -0.04 F14 0.04 F2 -0.03 F12 0.02 F8 0.02 F9 0.02 F6 -0.01 F3 0.01 F15 0.01 F11 -0.01 F1 0.01 F10 -0.00 F5 -0.00 F16 -0.00 F7',\n",
       " '0.34 F9 -0.04 F8 0.04 F4 0.02 F3 -0.02 F5 0.01 F1 0.01 F2 -0.00 F6 -0.00 F7',\n",
       " '0.33 F23 -0.06 F22 0.03 F7 -0.02 F30 -0.02 F14 0.02 F13 -0.02 F20 -0.02 F8 0.02 F6 -0.01 F18 0.01 F29 -0.01 F12 0.01 F10 0.01 F19 -0.01 F16 -0.01 F2 -0.01 F1 -0.01 F11 0.01 F17 -0.01 F24 0.00 F31 0.00 F15 0.00 F33 0.00 F25 0.00 F26 0.00 F9 0.00 F21 0.00 F4 0.00 F27 0.00 F32 0.00 F3 0.00 F5 0.00 F28',\n",
       " '0.62 F7 0.40 F8 -0.21 F6 -0.10 F2 0.09 F5 -0.09 F3 0.01 F4 0.00 F1',\n",
       " '-0.14 F3 -0.13 F5 0.11 F7 0.07 F1 -0.03 F4 0.03 F9 0.03 F8 -0.03 F10 -0.00 F6 -0.00 F2',\n",
       " '0.42 F3 -0.24 F6 -0.11 F5 -0.09 F4 -0.05 F2 -0.04 F1',\n",
       " '0.14 F33 0.10 F5 -0.08 F24 -0.07 F10 -0.07 F22 0.07 F21 0.06 F11 -0.06 F23 -0.06 F32 0.06 F29 -0.05 F9 -0.05 F17 -0.05 F28 0.03 F20 -0.02 F38 -0.02 F19 0.02 F1 0.02 F4 -0.01 F6 0.01 F31 0.00 F2 0.00 F35 0.00 F8 0.00 F37 0.00 F13 0.00 F34 0.00 F36 0.00 F12 0.00 F27 0.00 F25 0.00 F30 0.00 F14 0.00 F15 0.00 F7 0.00 F3 0.00 F18 0.00 F16 0.00 F26',\n",
       " '0.01 F61 0.01 F15 0.01 F1 -0.01 F89 0.00 F86 0.00 F23 0.00 F83 0.00 F4 0.00 F37 0.00 F28 0.00 F2 0.00 F46 0.00 F6 -0.00 F65 -0.00 F77 -0.00 F13 0.00 F80 -0.00 F90 0.00 F21 0.00 F32 0.00 F35 0.00 F3 0.00 F51 0.00 F9 0.00 F8 0.00 F85 0.00 F58 0.00 F91 0.00 F81 0.00 F60 0.00 F62 0.00 F64 0.00 F54 0.00 F11 0.00 F74 0.00 F38 0.00 F53 0.00 F79 0.00 F7 0.00 F73 0.00 F30 0.00 F22 0.00 F82 0.00 F48 0.00 F25 0.00 F18 0.00 F40 0.00 F93 0.00 F67 0.00 F19 0.00 F88 0.00 F20 0.00 F14 0.00 F17 0.00 F10 0.00 F69 0.00 F41 0.00 F43 0.00 F70 0.00 F66 0.00 F47 0.00 F29 0.00 F36 0.00 F33 0.00 F27 0.00 F31 0.00 F12 0.00 F50 0.00 F24 0.00 F87 0.00 F44 0.00 F72 0.00 F75 0.00 F59 0.00 F84 0.00 F68 0.00 F52 0.00 F42 0.00 F57 0.00 F92 0.00 F16 0.00 F26 0.00 F56 0.00 F45 0.00 F39 0.00 F76 0.00 F63 0.00 F49 0.00 F71 0.00 F55 0.00 F34 0.00 F5 0.00 F78',\n",
       " '0.35 F10 0.27 F11 0.21 F5 0.18 F2 -0.16 F8 0.07 F7 0.07 F1 0.06 F9 -0.04 F4 0.03 F12 -0.02 F3 0.01 F6 0.00 F13',\n",
       " '-0.00 F20 -0.00 F5 -0.00 F1 0.00 F14 0.00 F4 0.00 F13 0.00 F6 0.00 F23 0.00 F3 0.00 F12 0.00 F25 0.00 F10 0.00 F8 -0.00 F29 -0.00 F21 -0.00 F19 0.00 F26 -0.00 F18 -0.00 F17 -0.00 F15 0.00 F16 0.00 F9 0.00 F30 0.00 F7 0.00 F22 0.00 F24 0.00 F11 0.00 F2 0.00 F27 0.00 F28',\n",
       " '0.54 F2 0.13 F8 -0.13 F4 -0.04 F9 0.03 F5 -0.03 F6 -0.02 F11 -0.01 F3 -0.01 F1 0.01 F10 0.01 F7',\n",
       " '0.45 F6 0.25 F8 -0.12 F3 0.11 F18 -0.03 F19 -0.03 F5 0.03 F14 -0.03 F16 -0.02 F1 0.02 F17 -0.01 F20 -0.01 F9 0.01 F2 -0.01 F12 0.01 F10 -0.01 F11 0.00 F4 0.00 F7 0.00 F13 -0.00 F15',\n",
       " '-0.32 F10 -0.14 F8 -0.08 F1 0.07 F4 0.04 F6 0.03 F3 -0.02 F5 -0.02 F2 0.01 F7 -0.01 F9 0.01 F11',\n",
       " '0.54 F11 0.13 F3 -0.13 F4 -0.04 F5 0.03 F1 -0.03 F6 -0.02 F10 -0.01 F8 -0.01 F2 0.01 F7 0.01 F9',\n",
       " '0.25 F1 -0.08 F8 0.06 F3 -0.02 F10 -0.01 F9 0.01 F6 -0.01 F7 0.01 F2 0.00 F4 -0.00 F5',\n",
       " '0.53 F4 0.32 F9 0.18 F10 0.15 F8 0.13 F2 0.05 F1 -0.04 F3 -0.03 F6 -0.00 F7 0.00 F5',\n",
       " '0.43 F4 0.25 F3 0.13 F7 0.07 F1 0.07 F6 -0.03 F5 -0.02 F2',\n",
       " '0.08 F15 0.06 F14 -0.00 F9 0.00 F2 0.00 F13 -0.00 F19 0.00 F11 0.00 F17 -0.00 F5 0.00 F12 -0.00 F10 0.00 F3 0.00 F7 0.00 F4 0.00 F8 0.00 F6 0.00 F16 -0.00 F18 0.00 F1',\n",
       " '0.36 F2 0.24 F3 -0.17 F7 0.15 F1 -0.09 F6 0.09 F12 0.04 F4 0.03 F9 -0.02 F5 -0.01 F10 -0.00 F11 -0.00 F8',\n",
       " '-0.14 F18 0.05 F28 0.04 F17 0.04 F24 -0.03 F26 -0.03 F23 0.02 F1 -0.02 F3 0.02 F2 0.01 F16 -0.01 F19 0.01 F15 -0.01 F5 -0.01 F25 0.01 F27 -0.01 F10 0.00 F20 0.00 F21 -0.00 F6 -0.00 F22 0.00 F14 0.00 F9 0.00 F7 0.00 F12 0.00 F30 0.00 F29 0.00 F4 0.00 F13 0.00 F11 0.00 F8',\n",
       " '0.19 F2 -0.14 F44 -0.14 F7 0.14 F8 0.10 F39 0.10 F33 -0.09 F11 0.08 F20 -0.08 F36 -0.08 F9 0.07 F27 0.06 F25 0.06 F43 -0.06 F46 -0.06 F24 -0.05 F1 0.05 F22 0.05 F30 -0.04 F26 0.04 F42 0.00 F21 0.00 F17 0.00 F41 0.00 F18 0.00 F10 0.00 F35 0.00 F5 0.00 F16 0.00 F32 0.00 F28 0.00 F23 0.00 F34 0.00 F3 0.00 F29 0.00 F15 0.00 F19 0.00 F37 0.00 F6 0.00 F38 0.00 F4 0.00 F14 0.00 F13 0.00 F12 0.00 F45 0.00 F40 0.00 F31',\n",
       " '1.85 F14 0.82 F19 0.68 F29 0.63 F6 0.62 F38 0.61 F20 0.56 F4 -0.37 F12 -0.29 F36 -0.27 F16 -0.23 F27 0.22 F7 0.19 F39 0.17 F18 0.15 F32 0.13 F3 -0.13 F26 0.12 F9 -0.12 F35 -0.11 F34 0.09 F37 -0.08 F15 0.08 F23 -0.07 F30 0.06 F25 -0.06 F1 -0.04 F31 0.04 F17 0.03 F22 -0.02 F10 0.02 F11 0.02 F42 0.02 F24 0.02 F40 0.02 F21 0.02 F2 0.01 F33 -0.01 F13 -0.01 F5 -0.00 F41 -0.00 F8 -0.00 F28',\n",
       " '0.32 F4 0.18 F1 0.17 F7 0.07 F6 0.05 F2 0.05 F8 0.04 F5 0.03 F3',\n",
       " '0.78 F13 0.14 F3 0.11 F12 -0.04 F11 -0.03 F19 0.03 F4 0.03 F20 0.02 F14 -0.02 F2 -0.02 F1 0.02 F16 -0.02 F5 -0.01 F15 -0.01 F18 0.01 F8 0.01 F7 -0.01 F10 -0.01 F9 -0.00 F6 -0.00 F17',\n",
       " '0.78 F19 -0.07 F4 0.06 F17 -0.06 F13 -0.02 F12 0.02 F1 0.02 F14 -0.02 F15 -0.01 F5 -0.01 F16 -0.01 F3 -0.01 F9 0.01 F2 -0.01 F7 -0.01 F6 0.01 F18 0.00 F10 -0.00 F11 -0.00 F20 0.00 F8',\n",
       " '-0.16 F1 0.12 F5 0.07 F2 -0.05 F3 -0.05 F8 0.02 F6 -0.01 F10 0.01 F4 0.01 F7 0.00 F9',\n",
       " '0.38 F10 0.36 F11 0.13 F13 0.03 F6 -0.02 F5 0.01 F15 -0.01 F2 -0.01 F7 -0.01 F1 -0.01 F16 0.00 F8 -0.00 F9 -0.00 F3 -0.00 F17 -0.00 F4 -0.00 F12 0.00 F14',\n",
       " '0.23 F1 0.12 F4 0.04 F3 0.04 F5 -0.01 F2 0.00 F6',\n",
       " '0.23 F5 0.19 F6 0.17 F9 0.06 F2 -0.06 F11 0.05 F10 0.04 F8 0.01 F7 0.01 F4 -0.01 F3 -0.01 F12 0.00 F1',\n",
       " '0.20 F17 0.03 F26 -0.03 F25 0.03 F2 -0.03 F10 -0.03 F32 -0.03 F21 0.02 F3 0.02 F9 0.02 F23 0.02 F7 -0.02 F13 0.02 F19 -0.02 F14 -0.01 F18 -0.01 F24 -0.01 F20 -0.01 F27 0.01 F4 0.01 F15 0.00 F28 0.00 F6 0.00 F5 0.00 F1 0.00 F11 0.00 F12 0.00 F30 0.00 F31 0.00 F22 0.00 F16 0.00 F29 0.00 F8 0.00 F33',\n",
       " '0.01 F29 0.01 F9 0.01 F88 -0.01 F53 0.00 F17 0.00 F77 0.00 F30 0.00 F3 0.00 F7 0.00 F85 0.00 F20 0.00 F81 0.00 F26 -0.00 F44 -0.00 F69 -0.00 F31 0.00 F1 -0.00 F27 0.00 F89 0.00 F8 0.00 F49 0.00 F21 0.00 F36 0.00 F87 0.00 F18 0.00 F63 0.00 F46 0.00 F32 0.00 F48 0.00 F56 0.00 F5 0.00 F78 0.00 F62 0.00 F82 0.00 F92 0.00 F12 0.00 F70 0.00 F65 0.00 F33 0.00 F39 0.00 F55 0.00 F19 0.00 F23 0.00 F84 0.00 F86 0.00 F54 0.00 F42 0.00 F57 0.00 F14 0.00 F11 0.00 F43 0.00 F83 0.00 F67 0.00 F13 0.00 F60 0.00 F38 0.00 F24 0.00 F6 0.00 F28 0.00 F76 0.00 F37 0.00 F66 0.00 F47 0.00 F68 0.00 F15 0.00 F61 0.00 F58 0.00 F4 0.00 F59 0.00 F64 0.00 F52 0.00 F45 0.00 F80 0.00 F50 0.00 F25 0.00 F34 0.00 F51 0.00 F73 0.00 F93 0.00 F22 0.00 F16 0.00 F74 0.00 F90 0.00 F10 0.00 F2 0.00 F71 0.00 F35 0.00 F91 0.00 F41 0.00 F40 0.00 F72 0.00 F79 0.00 F75',\n",
       " '0.16 F19 -0.09 F11 -0.09 F6 0.07 F16 -0.05 F26 0.04 F2 0.04 F22 0.04 F8 0.04 F1 0.03 F9 0.03 F13 0.02 F18 0.02 F28 0.02 F25 0.02 F5 -0.02 F15 -0.01 F14 0.01 F21 0.01 F12 -0.01 F3 0.00 F24 0.00 F27 0.00 F4 0.00 F10 0.00 F20 0.00 F30 0.00 F7 0.00 F23 0.00 F29 0.00 F17',\n",
       " '0.12 F22 0.07 F24 0.07 F2 -0.05 F30 0.04 F1 -0.04 F6 -0.03 F17 0.03 F19 -0.02 F7 -0.02 F3 0.02 F8 -0.02 F20 -0.02 F4 -0.02 F9 -0.02 F26 -0.01 F13 -0.01 F28 -0.01 F14 0.01 F21 -0.01 F10 0.00 F29 0.00 F27 0.00 F18 0.00 F11 0.00 F5 0.00 F15 0.00 F23 0.00 F25 0.00 F12 0.00 F16',\n",
       " '0.10 F11 -0.02 F2 0.01 F9 -0.01 F6 0.01 F3 0.01 F1 -0.00 F4 -0.00 F5 -0.00 F8 -0.00 F7 -0.00 F10',\n",
       " '0.06 F5 0.04 F3 -0.03 F2 -0.03 F4 -0.03 F9 -0.03 F11 -0.02 F6 -0.02 F8 0.01 F7 -0.01 F1 0.00 F10',\n",
       " '0.33 F1 -0.04 F31 -0.03 F14 -0.03 F10 -0.03 F6 0.03 F16 -0.02 F5 -0.02 F4 -0.02 F20 -0.02 F7 0.02 F26 0.02 F22 0.02 F21 0.01 F11 -0.01 F23 -0.01 F2 0.01 F3 0.01 F18 0.01 F9 0.01 F15 0.00 F19 0.00 F30 0.00 F28 0.00 F29 0.00 F12 0.00 F8 0.00 F17 0.00 F32 0.00 F24 0.00 F33 0.00 F27 0.00 F13 0.00 F25']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [' '.join([num+' ' +ft for num, ft in zip(l['values'], l['feature_nums'])]) for l in train if l['narrative_questions'][0] == 'In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['model_name', 'predicted_class', 'task_name', 'narration', 'values', 'sign', 'narrative_id', 'unique_id', 'classes_dict', 'narrative_questions', 'feature_nums', 'ft_num_to_name', 'old2new_ft_nums', 'old2new_classes'],\n",
       "    num_rows: 375\n",
       "})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analysis performed to understand the contribution of each input feature revealed that: F7, F9, and F3 are the most influential features when assigning a label to the given case',\n",
       " 'Apart from F1 and F9, all the other variables mentioned above have a strong positive influence, improving the odds of the prediction class, C2',\n",
       " 'F6, F8, F3, F4, and F5 have a moderate degree of impact while on the contrary F7 and F1 have little impact',\n",
       " 'Based on the values of these variables, the likelihood of the C2 label is 65.51 percent',\n",
       " 'This means, there is a 32.46% chance that C1 could be the label and the classification assertion above is influenced mainly by the variables F11, F4, F7, and F9',\n",
       " 'Specifically, there is about an 80.0% chance that C2 is the correct label',\n",
       " 'Therefore, the most probable class for the given case is C2',\n",
       " 'F12, F1, F17, and F28 are the four features with the most impact',\n",
       " 'Therefore, the most likely label is identified as C2 and the attribution analysis shows that all the variables contributed to some extent to the final decision by the algorithm with respect to the given case',\n",
       " 'This assessment decision is mainly based on the inpacts of features such as F2, F7, F4, F3, and F8',\n",
       " 'The most significant feature is F1, while the least important attributes are F8, F7, and F3',\n",
       " 'Undoubtedly, the model estimated that the likelihood of the true label being equal to C2 is 99.92%',\n",
       " 'The class label in this case is forecasted to be C3 out of the four possible labels, with a probability of around 83.08 percent',\n",
       " 'The variables F4, F1, F5, and F6 all contribute a lot to the classification decision above',\n",
       " 'According to the input features attribution analysis conducted, the features with the most influence on the decision are F1, F8, F15, and F10, all of which increase the probability that C1 is indeed the true label',\n",
       " 'The predicted probability of the less probable class, C2, reflects the fact that the model is a bit doubtful about the output label',\n",
       " 'The variables F2, F11, F9, and F1 have the most impact on the prediction judgement here',\n",
       " 'For the case under consideration, F1, F7, F11, and F9 are the sets of features significantly influencing the decision made by the classifier',\n",
       " 'The classification verdict is as follows: C2 is the most probable label with respect to the case under consideration, since the prediction likelihood of the other label, C1, is only 12.50%',\n",
       " 'The features with the largest impact driving the algorithm to arrive at the above decision are F8, F1, and F15 which are followed in the decreasing order of influence by F14, F4, F13, F7, F3, F6, F11, F2, F5, F12, F9, and F10',\n",
       " 'The classification above is mainly due to the contributions of different features such as F39, F13, F24, F38, F22, and F26',\n",
       " 'The most important variables are F10, F6, F9, and F5, whose values lead to the aforesaid classification conclusion',\n",
       " 'This prediction decision is based primarily on the attribution of the following features: F3, F9, F4, and F5',\n",
       " 'Among the top influential feature-set, F10 has a value shifting the label choice in favour of C1, while the others, F11, F5, and F18, all have a positive impact supporting the decision made by the model to assign the label C2',\n",
       " 'The classifier, on the other hand, says that C1 and C2 are equally likely, with a predicted probability of 25.0 percent',\n",
       " 'The features considered most relevant by the model for the above decision are F1, F3, F11, and F4, while those with the least consideration are F10, F9, and F12',\n",
       " 'However, the classifier indicates that C2 and C1 are equally likely, with a predicted probability of 25.0%',\n",
       " 'Since the confidence level with respect to this C3 is not 100.0%, it is possible that one of the other labels is the true or correct label, and C2 is the next most likely label',\n",
       " 'The classification output decision with regards to the given case boils down to the values of the features F5, F4, F6, and F3, which are shown to have the most significant influence on the model',\n",
       " 'According to the algorithm, there is no possibility that C2 is the correct label',\n",
       " \"In this case, the feature with the most significant influence on the model's decision is F11, with a very strong positive contribution in support of the C1 prediction\",\n",
       " 'The above prediction by the classifier is mainly based on the values of the features F4, F6, F11, and F7, which, according to the analysis performed, offer very strong positive support for the prediction',\n",
       " 'F7, F10, F9, and F1 are shown to be the most relevant features, with values leading to the verdict above',\n",
       " 'The most relevant features in terms of the classification above are F14, F8, F1, F12, and F4',\n",
       " 'It is important to note that there is about a 35.89% chance that the alternative label could be the true label',\n",
       " 'The feature with the most influence on the decision is F7, while the least relevant features  and those with little contributions to the decision are F5, F6, and F1',\n",
       " 'The contributions of the input features can be ranked as follows: the most powerful set of features is F2, F5, F8, F7, and F10,  the effects of F9, F4, and F11 are moderate, and The F1, F12, F6, and F3 have little or no effect on the prediction above',\n",
       " 'The values of the input features have an impact on the classification above and the classifier ranks the features based on the strength of impact as follows: F1, F3, F4, F7, F2, F6, F5, indicating that F1 is the most significant feature and F5 is the least essential',\n",
       " 'Based on the values of these features, the likelihood of the C1 label is 65.51%']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l['narration'].split(\". \")[0] for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating answers to the questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Summarise the ranking of the features\n",
    "What does this mean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The classifier is 69.02% certain that the given case is under the class label C1, implying that the likelihood of C2 is only 30.98%',\n",
       " \"According to the machine learning model, it is more likely that the case's label is C2, with a certainty of 100.0%, and this prediction decision is mainly based on the effects of the following features: F8, F10, F6, F9, and F1 on the model\",\n",
       " 'The given case is likely C2 with a confidence level of 87.50% judged based on the values of the input features supplied to the classifier and according to the attributions analysis, F9 and F2 have a high degree of impact',\n",
       " 'The model has classified the instance as C2 due to the effects of the following features: F5, F8, F6, and F2',\n",
       " 'The likelihood of C2 being the correct label for the selected case or instance is 67.54% according to the classifier',\n",
       " 'The confidence level score with respect to each class label suggests that this case should be labelled as C2',\n",
       " 'The prediction probability of C1 is 17.93% and that of C2 is 82.07%',\n",
       " 'All features are shown to have a positive impact on the classification to class C1 or to have no impact at all',\n",
       " \"Deciding the most probable label for the given case on the basis of the values of the input variables, the classification algorithm's output decision is that:  the probability of C2 being the correct label is 79.78%, the probability of C1 is 20.22%\",\n",
       " 'According to the model employed, the label for the case is more likely to be C1',\n",
       " 'With a certainty of 100.0%, the model labels this case as C2 and from the predicted likelihoods across the classes, it can be inferred that the model verdict is that there is a zero chance that the case is under C1',\n",
       " 'According to the classification model employed here, there is a marginal chance that the true label for this test example is C1',\n",
       " 'The classification output observations that follow are based on the information supplied about this specific case',\n",
       " 'For the given case or instance, the model assigns the label C2, with the prediction confidence equal to 56.56%',\n",
       " 'The prediction made for this case by the model is that C1 is most likely the true label, with a confidence level of 72.03% higher than the 27.97% of the C2 label',\n",
       " 'Tasked with labelling cases, the classification model labels the case under consideration as C1 since the probability of C2 is only 20.22%',\n",
       " 'The classifier says that C1 has a 67.54 percent chance of being the correct label for the given example or case; consequently the label C2 has a 33.46 percent chance of being the chosen class',\n",
       " 'The classifier assigns the label C2 since the probability associated with C2 is greater than that of C1',\n",
       " \"It is important to note that the classifier's labelling decision is based solely on the information supplied\",\n",
       " 'According to the classification algorithm, there is 77.69% chance that the given case is part of the C1 population',\n",
       " 'The case given is labelled as C2 with close to an 82.07% confidence level, implying that the likelihood of C1 being the correct label is only 17.93%',\n",
       " \"The classifier's anticipated label for this case is C2 which is a decision that it is highly confident about since the predicted likelihood is 100.0%\",\n",
       " \"According to the model, there is a higher chance that the case's label is C1\",\n",
       " \"The model's prediction for this test case is C2 with an almost 100% confidence level which implies that the likelihood of it being a different class label is closer to 0%\",\n",
       " 'With a moderate likelihood of 50.0%, the label for this case is judged to be C3',\n",
       " 'C2 is the label predicted by the classification model employed and looking at the prediction probabilities, it valid to concluded that the model is very certain about the selected label',\n",
       " 'C3, out of the three potential classes, is the the label assigned with a high probability of 50.0%',\n",
       " 'The label assigned in this case by the classifier is C3, with a moderately high prediction confidence of 66.11%',\n",
       " 'The classification output decision is based solely on the information supplied to the model and it predicts class C4 with a higher confidence level, equal to 94.10%, indicating the model is very confident that the correct label for the given case is not either class C3 or class C1 or class C2',\n",
       " 'Based on the values of the input variables resulting in the predicted likelihoods across the classes, the classification algorithm is confident that the right label for the provided data is C1',\n",
       " 'The predicted label is C1 at a confidence level of 92.11%, insinuating that there is a 7.89% chance that the label could be C2',\n",
       " 'The case is labelled as C2 by the classifier, with the likelihood of this being correct equal to 94.37%, suggesting that there is a slight chance of about 5.63% that this decision could be wrong',\n",
       " 'C2 is the predicted label from the model for this case, and the model is very confident about it since the associated predicted likelihood of C2 is 100.0%',\n",
       " 'There is a high level of uncertainty when it comes to classifying the case here and this is mainly because the label with the highest possibility of 58.75% is C2, while there is a 41.25% chance that it could be C1',\n",
       " 'The prediction by the model for the given observation or case is C2, with the likelihood of being correct equal to 64.11%',\n",
       " 'This case labelled as C2 with 100.0% certainty by the algorithm or model employed here for this classification task hence there is little chance that C1 is the right label choice',\n",
       " 'The label assigned to this test case by the classification model has a 98.21% chance of being C2 and this means that C1 is only about 1.79% likely to be the appropriate class',\n",
       " 'Since the likelihood of C1 is only 9.70%, the classifier generates the label C2 with a confidence level of roughly 91.30% for the provided data or instance',\n",
       " 'The case is labelled as C1 by the model, mainly based on the influence of the following features: F9, F1, F5, and F8']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l['narration'].split(\". \")[0] for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Answers to this question are almost always still the same as what we would have got for the other question: A statement on the prediction of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Summarise the ranking of the features\n",
    "\n",
    "Is this the same as when asked in Q1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Regarding the classifier's decision, there is close to an even split on the probability of either of the possible labels is the correct label but the classifier chooses the label as C2\",\n",
       " 'F6 and F10 are deemed the most important features whereas on the other hand all the other features have moderate to minimal amounts of influence',\n",
       " 'The most relevant features that led to the C1 classification verdict are F5, F30, F26, F17, and F15',\n",
       " \"According to the attribution analysis conducted, the different input variables have varying degrees of influence on the model's decision here\",\n",
       " 'F12 and F1 are the most important variables with respect to this classification verdict while all other variables are shown to have a medium or low impact',\n",
       " 'F24 had the largest impact, followed by F23, F9, F18, F14, F10, F11, F2, F8, F21, F20, F27, F4, F12, F15, F19, F13, F16, F30, and finally, F29, which had the smallest non-zero impact',\n",
       " 'F11 is by far the most influential feature whereas F4, F6, and F17 have been recognised as having the biggest effect on prediction output here after F11',\n",
       " 'The prediction probability distribution across the classes C2 and C1 is 2.40% and 97.60%, respectively',\n",
       " 'Not all of the features are found to contribute to the label given here',\n",
       " 'Analysis shows that only 20 of the 46 input variables contribute to the prediction assertion above',\n",
       " 'The above classification decision is largely due to the values of F4, F8, F3, and F14',\n",
       " 'To explain the above prediction conclusion, the analysis revealed that the majority of the features have negative influences or attributions, pushing the prediction away from C2 in favour of C1',\n",
       " 'The decision above is based on the prediction probabilities for the two possible labels, C1 and C2, which are 94.25% and 5.75%, respectively',\n",
       " 'Not all the features are shown to contribute either positively or negatively towards the label assigned here',\n",
       " \"Based on the aforementioned, C1 is the most likely class label for the presented data instance, and according to the attribution analysis, the various input variables had varying degrees of impact on the model's classification judgement\",\n",
       " 'The order of importance of the features for the above classification verdict is F1, F4, F2, F6, F5, F7, F3, and F8',\n",
       " 'F12, F38, and F75 are the key variables that contributed to the classification choice',\n",
       " 'Ranking the contributions of the features to the prediction above, from the most relevant to the least relevant, is as follows: F2, F5, F1, F3, F4, F6, and F7',\n",
       " \"The top two variables with the greatest control over the model in terms of this case's label assignment are F11 and F4 but on the contrary, the rest of the variables have moderate-to-lower influence\",\n",
       " 'C1 has a 90.48% chance of being correct, implying that any of the other labels is highly unlikely',\n",
       " 'However, according to the model, there is a 45.34% chance that C2 could be the label, presenting some level of uncertainty in the classification verdict made here',\n",
       " 'The features are ranked in order of their respective impacts, from most important to least relevant: F10, F11, F9, F7, F12, F3, F6, F4, F8, F2, F1, and F5',\n",
       " 'By analysing the attributions of the input features, they can be ranked according to the level of impact, from the most important feature to the least relevant, as follows: F11, F1, F5, F2, F8, F12, F7, F10, F6, F9, F3, and F4',\n",
       " 'The in-depth analysis found that the bulk of the attributes had negative impacts, driving the prediction away from C1 and toward C2',\n",
       " ' Judging based on the predicted probabilities associated with the other remaining labels, the classifier is 75.0% confident that C3 is the correct label',\n",
       " 'By far, feature F12 had the most impact and following F12 are F5, F15, and F6 have been identified as having the comparable influence on classification',\n",
       " 'According to the model, there is an almost equal distribution in terms of the probability that any one of C1 and C2 is an appropriate label',\n",
       " \"Among the features employed for this classification, F4, F8, F10, F11, F12, and F9 are the top features influencing the model's prediction decision\",\n",
       " 'Just few features out of the entire input features are shown to have control over the prediction made here',\n",
       " 'This is because the probability of the other label, C1, is only 1.03%',\n",
       " 'The most relevant attribute is F5, followed by F7, F1, F6, F8, F9, F3, F4 and finally F2, which is the least relevant',\n",
       " 'The most influential features were F3, F5, and F14',\n",
       " 'First of all, the classification is performed with negligible contributions from the variables F23, F30, F15, F8, and F12 since their attributions are very close to zero',\n",
       " 'For this classification scenario, the input features that have the greatest influence on the end outcome are F22, F20, F37, and F10',\n",
       " 'Based on this, the model assigned the given case the label C2',\n",
       " 'It is fairly confident of its C3 classification and is very certain that the given case is not class C2',\n",
       " 'With the contribution of different variables, the most important variables in this classification decision are F27, F15, F2, F7, and F21',\n",
       " 'The top features contributing either positively or negatively to the labelling decision above include F11, F6, F1, and F3 with the strongest contribution to the prediction of C1 from F11, followed by F3, F6, and F1',\n",
       " 'In terms of the contributions from the different features, the most important features for this classification decision include F44, F8, F3, and F27']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l['narration'].split(\". \")[1] for l in train if l['narrative_questions'][1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to just be a 2 sentence question asking the same thing as the single sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: 'For these top features, what are the respective directions of influence on the prediction?' Are these top features named?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these 20 instances,\n",
    "* 'Summarize the prediction for the given test example?'\n",
    "* 'For this test case, summarize the top features influencing the model's decision.'\n",
    "* 'For these top features, what are the respective directions of influence on the prediction?'\n",
    "* 'Provide a statement on the set of features has limited impact on the prediction of [C1/C2] by the model for the given test example?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 20)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = re.compile(r'F\\d+')\n",
    "[[reg.findall(n) for n in l['narrative_questions']] for l in train if l['narrative_questions'][2] == 'For these top features, what are the respective directions of influence on the prediction?']\n",
    "Counter([len(l['narrative_questions']) for l in train if l['narrative_questions'][2] == 'For these top features, what are the respective directions of influence on the prediction?']).most_common()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to separate the narrative answers into the questions that they ask\n",
    "Can do this, at least initially, by finding noting whether the sentence has F# in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[],\n",
       "  [],\n",
       "  ['F4', 'F11', 'F3', 'F15', 'F7', 'F19', 'F1'],\n",
       "  [],\n",
       "  ['F3', 'F15', 'F8', 'F20'],\n",
       "  ['F4', 'F11', 'F12', 'F2'],\n",
       "  ['F4', 'F11']],\n",
       " [[],\n",
       "  ['F6', 'F10'],\n",
       "  ['F6', 'F10'],\n",
       "  ['F4', 'F1', 'F9', 'F12', 'F8'],\n",
       "  ['F3', 'F8', 'F2']],\n",
       " [[],\n",
       "  ['F5', 'F30', 'F26', 'F17', 'F15'],\n",
       "  ['F3', 'F4', 'F13', 'F27'],\n",
       "  [],\n",
       "  ['F5', 'F30', 'F26', 'F17', 'F15'],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['F18',\n",
       "   'F31',\n",
       "   'F19',\n",
       "   'F36',\n",
       "   'F35',\n",
       "   'F20',\n",
       "   'F38',\n",
       "   'F37',\n",
       "   'F3',\n",
       "   'F25',\n",
       "   'F16',\n",
       "   'F33',\n",
       "   'F6'],\n",
       "  [],\n",
       "  ['F18', 'F31', 'F19', 'F36', 'F38', 'F18', 'F31'],\n",
       "  ['F19', 'F36', 'F38'],\n",
       "  ['F35', 'F20', 'F5'],\n",
       "  ['F18', 'F31', 'F9', 'F23', 'F19', 'F36', 'F5', 'F35', 'F20', 'F38']],\n",
       " [[],\n",
       "  ['F12', 'F1'],\n",
       "  ['F12', 'F1'],\n",
       "  ['F4', 'F11', 'F3', 'F8', 'F2'],\n",
       "  ['F7', 'F8', 'F6']],\n",
       " [[],\n",
       "  ['F24',\n",
       "   'F23',\n",
       "   'F9',\n",
       "   'F18',\n",
       "   'F14',\n",
       "   'F10',\n",
       "   'F11',\n",
       "   'F2',\n",
       "   'F8',\n",
       "   'F21',\n",
       "   'F20',\n",
       "   'F27',\n",
       "   'F4',\n",
       "   'F12',\n",
       "   'F15',\n",
       "   'F19',\n",
       "   'F13',\n",
       "   'F16',\n",
       "   'F30',\n",
       "   'F29'],\n",
       "  ['F24', 'F23', 'F9', 'F18', 'F14'],\n",
       "  ['F11', 'F2', 'F10'],\n",
       "  ['F22', 'F6', 'F1', 'F5']],\n",
       " [[],\n",
       "  ['F11', 'F4', 'F6', 'F17', 'F11'],\n",
       "  ['F11', 'F4', 'F6', 'F17', 'F3'],\n",
       "  ['F5', 'F2', 'F16', 'F5'],\n",
       "  ['F15', 'F8', 'F13', 'F19', 'F10']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F18', 'F3', 'F12', 'F15', 'F1', 'F8', 'F19', 'F9'],\n",
       "  ['F18', 'F3', 'F15'],\n",
       "  ['F12', 'F14', 'F4'],\n",
       "  ['F17', 'F11', 'F13', 'F7', 'F2']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F36',\n",
       "   'F8',\n",
       "   'F26',\n",
       "   'F35',\n",
       "   'F3',\n",
       "   'F12',\n",
       "   'F24',\n",
       "   'F9',\n",
       "   'F21',\n",
       "   'F6',\n",
       "   'F20',\n",
       "   'F5',\n",
       "   'F4',\n",
       "   'F25',\n",
       "   'F19',\n",
       "   'F27',\n",
       "   'F7',\n",
       "   'F23',\n",
       "   'F37',\n",
       "   'F31'],\n",
       "  ['F30', 'F33', 'F13'],\n",
       "  ['F36', 'F8', 'F26', 'F35', 'F3', 'F26'],\n",
       "  ['F24', 'F12', 'F9'],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['F17', 'F9', 'F18', 'F19'],\n",
       "  ['F43', 'F23', 'F32', 'F33', 'F29', 'F20'],\n",
       "  ['F17', 'F19', 'F29', 'F33'],\n",
       "  ['F9', 'F23', 'F20', 'F18', 'F43', 'F32'],\n",
       "  ['F14', 'F31', 'F7', 'F38']],\n",
       " [[],\n",
       "  ['F4', 'F8', 'F3', 'F14'],\n",
       "  ['F6', 'F1'],\n",
       "  [],\n",
       "  [],\n",
       "  ['F3', 'F5', 'F13', 'F2', 'F9', 'F1', 'F4', 'F8', 'F7', 'F14']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F8', 'F6', 'F17', 'F4', 'F10'],\n",
       "  ['F5', 'F19', 'F15', 'F16'],\n",
       "  ['F11', 'F12', 'F3']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F4', 'F10', 'F1', 'F2', 'F7', 'F9', 'F8', 'F6', 'F3', 'F5'],\n",
       "  ['F10', 'F4'],\n",
       "  ['F6', 'F8'],\n",
       "  [],\n",
       "  ['F7', 'F1', 'F2', 'F3', 'F5']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F8',\n",
       "   'F21',\n",
       "   'F27',\n",
       "   'F24',\n",
       "   'F14',\n",
       "   'F25',\n",
       "   'F28',\n",
       "   'F17',\n",
       "   'F26',\n",
       "   'F15',\n",
       "   'F22',\n",
       "   'F12',\n",
       "   'F20',\n",
       "   'F4',\n",
       "   'F19',\n",
       "   'F7',\n",
       "   'F16',\n",
       "   'F35',\n",
       "   'F6',\n",
       "   'F30'],\n",
       "  ['F36', 'F9', 'F38'],\n",
       "  ['F8', 'F21', 'F27', 'F24', 'F14', 'F27'],\n",
       "  ['F28', 'F25', 'F17', 'F28', 'F25', 'F17'],\n",
       "  []],\n",
       " [[],\n",
       "  [],\n",
       "  ['F33',\n",
       "   'F8',\n",
       "   'F17',\n",
       "   'F37',\n",
       "   'F29',\n",
       "   'F32',\n",
       "   'F4',\n",
       "   'F25',\n",
       "   'F18',\n",
       "   'F26',\n",
       "   'F15',\n",
       "   'F13',\n",
       "   'F3'],\n",
       "  [],\n",
       "  ['F33', 'F8', 'F33', 'F8', 'F17', 'F37', 'F4'],\n",
       "  ['F17', 'F37', 'F4'],\n",
       "  ['F29', 'F32', 'F2'],\n",
       "  ['F33', 'F8', 'F31', 'F11', 'F17', 'F37', 'F2', 'F29', 'F32', 'F4']],\n",
       " [[],\n",
       "  ['F1', 'F4', 'F2', 'F6', 'F5', 'F7', 'F3', 'F8'],\n",
       "  ['F4', 'F5', 'F7'],\n",
       "  ['F1', 'F2', 'F6', 'F3', 'F8'],\n",
       "  []],\n",
       " [[],\n",
       "  ['F12', 'F38', 'F75'],\n",
       "  ['F58', 'F24', 'F57', 'F63'],\n",
       "  ['F75',\n",
       "   'F19',\n",
       "   'F64',\n",
       "   'F23',\n",
       "   'F12',\n",
       "   'F38',\n",
       "   'F61',\n",
       "   'F72',\n",
       "   'F7',\n",
       "   'F26',\n",
       "   'F92']],\n",
       " [[],\n",
       "  ['F2', 'F5', 'F1', 'F3', 'F4', 'F6', 'F7'],\n",
       "  ['F4', 'F6'],\n",
       "  ['F2', 'F5', 'F1']],\n",
       " [[],\n",
       "  ['F11', 'F4'],\n",
       "  ['F4'],\n",
       "  ['F11', 'F2', 'F1'],\n",
       "  ['F7', 'F6', 'F9', 'F3'],\n",
       "  ['F8', 'F12', 'F5', 'F10']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F10', 'F4'],\n",
       "  ['F4', 'F10'],\n",
       "  ['F1', 'F5', 'F8', 'F11', 'F9', 'F6'],\n",
       "  ['F12', 'F9', 'F6']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F7', 'F15', 'F8', 'F16', 'F2', 'F1', 'F33', 'F10', 'F25', 'F13', 'F4'],\n",
       "  ['F15', 'F5', 'F16', 'F21'],\n",
       "  ['F9', 'F17', 'F26', 'F20'],\n",
       "  ['F7', 'F8', 'F1', 'F2', 'F28', 'F19', 'F23'],\n",
       "  ['F7']],\n",
       " [[],\n",
       "  ['F10', 'F11', 'F9', 'F7', 'F12', 'F3', 'F6', 'F4', 'F8', 'F2', 'F1', 'F5'],\n",
       "  [],\n",
       "  ['F6', 'F3', 'F7', 'F9', 'F4', 'F10'],\n",
       "  ['F8', 'F2', 'F1', 'F5']],\n",
       " [[],\n",
       "  ['F11', 'F1', 'F5', 'F2', 'F8', 'F12', 'F7', 'F10', 'F6', 'F9', 'F3', 'F4'],\n",
       "  [],\n",
       "  ['F5', 'F2', 'F7', 'F12', 'F10'],\n",
       "  ['F11'],\n",
       "  ['F6', 'F9', 'F3', 'F4']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F4', 'F15', 'F3', 'F12', 'F17'],\n",
       "  ['F14', 'F2', 'F8', 'F13'],\n",
       "  ['F1', 'F7', 'F6']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F6', 'F8', 'F1', 'F5', 'F4', 'F2', 'F7', 'F11', 'F12', 'F3', 'F10', 'F9'],\n",
       "  [],\n",
       "  ['F1', 'F5', 'F7', 'F2', 'F11'],\n",
       "  ['F6', 'F12', 'F3', 'F10', 'F9']],\n",
       " [[],\n",
       "  ['F12', 'F12', 'F5', 'F15', 'F6'],\n",
       "  ['F12', 'F5', 'F15', 'F6', 'F1'],\n",
       "  ['F13', 'F16', 'F10', 'F13', 'F2', 'F18', 'F11'],\n",
       "  ['F19', 'F14', 'F8', 'F7', 'F9']],\n",
       " [[],\n",
       "  [],\n",
       "  [],\n",
       "  ['F6', 'F9', 'F12', 'F3', 'F10', 'F2', 'F5'],\n",
       "  ['F3', 'F12', 'F19', 'F1'],\n",
       "  ['F6', 'F13', 'F8', 'F9'],\n",
       "  ['F6', 'F9']],\n",
       " [[],\n",
       "  ['F4', 'F8', 'F10', 'F11', 'F12', 'F9'],\n",
       "  ['F4', 'F8'],\n",
       "  ['F11', 'F12', 'F2', 'F13', 'F9'],\n",
       "  ['F10', 'F3', 'F14', 'F6', 'F7'],\n",
       "  ['F5', 'F16', 'F15']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F16', 'F43', 'F35', 'F14'],\n",
       "  ['F17', 'F44', 'F3', 'F21', 'F5', 'F40'],\n",
       "  ['F16', 'F14', 'F5', 'F21', 'F43', 'F35', 'F17', 'F44', 'F40', 'F3'],\n",
       "  ['F15', 'F39', 'F4', 'F18']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F1', 'F2', 'F4', 'F8', 'F5', 'F3', 'F7', 'F6'],\n",
       "  ['F2', 'F5', 'F3'],\n",
       "  ['F1', 'F4', 'F8', 'F7', 'F6'],\n",
       "  []],\n",
       " [[],\n",
       "  ['F5', 'F7', 'F1', 'F6', 'F8', 'F9', 'F3', 'F4', 'F2'],\n",
       "  ['F8', 'F3', 'F5', 'F1'],\n",
       "  ['F6', 'F4', 'F7', 'F9'],\n",
       "  ['F2']],\n",
       " [[],\n",
       "  ['F3', 'F5', 'F14'],\n",
       "  ['F20',\n",
       "   'F1',\n",
       "   'F12',\n",
       "   'F7',\n",
       "   'F33',\n",
       "   'F18',\n",
       "   'F10',\n",
       "   'F17',\n",
       "   'F27',\n",
       "   'F26',\n",
       "   'F19',\n",
       "   'F32',\n",
       "   'F11',\n",
       "   'F16',\n",
       "   'F31',\n",
       "   'F21'],\n",
       "  ['F3', 'F5', 'F14'],\n",
       "  ['F20', 'F1', 'F12'],\n",
       "  ['F4', 'F22', 'F24', 'F9', 'F15']],\n",
       " [[],\n",
       "  ['F23', 'F30', 'F15', 'F8', 'F12'],\n",
       "  ['F14', 'F25', 'F7', 'F13', 'F16'],\n",
       "  ['F19', 'F3', 'F26', 'F24', 'F22', 'F1', 'F2'],\n",
       "  ['F14', 'F7', 'F13', 'F3', 'F26'],\n",
       "  ['F22', 'F1', 'F18', 'F10'],\n",
       "  ['F25', 'F16', 'F10', 'F24', 'F2']],\n",
       " [[],\n",
       "  ['F22', 'F20', 'F37', 'F10'],\n",
       "  ['F16', 'F23', 'F24', 'F5', 'F19'],\n",
       "  ['F4', 'F27', 'F1', 'F18'],\n",
       "  ['F22', 'F20', 'F37', 'F10', 'F22', 'F37', 'F20', 'F10'],\n",
       "  ['F3', 'F14', 'F14', 'F28', 'F29', 'F3', 'F9', 'F31', 'F12']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F3', 'F1'],\n",
       "  ['F11', 'F13', 'F5', 'F14'],\n",
       "  ['F3', 'F4', 'F7', 'F12'],\n",
       "  ['F8', 'F14', 'F1']],\n",
       " [[],\n",
       "  [],\n",
       "  ['F10', 'F8', 'F2', 'F9'],\n",
       "  ['F10', 'F8', 'F2', 'F9'],\n",
       "  ['F7', 'F1'],\n",
       "  ['F4', 'F6']],\n",
       " [[],\n",
       "  ['F27', 'F15', 'F2', 'F7', 'F21'],\n",
       "  ['F12', 'F33', 'F14', 'F30'],\n",
       "  ['F27', 'F2', 'F15', 'F21'],\n",
       "  ['F7', 'F5', 'F38', 'F24'],\n",
       "  ['F6', 'F9']],\n",
       " [[],\n",
       "  ['F11', 'F6', 'F1', 'F3', 'F11', 'F3', 'F6', 'F1'],\n",
       "  ['F3', 'F8', 'F4', 'F10', 'F9'],\n",
       "  ['F11', 'F6', 'F7', 'F2', 'F1'],\n",
       "  ['F5']],\n",
       " [[],\n",
       "  ['F44', 'F8', 'F3', 'F27'],\n",
       "  ['F44', 'F3', 'F8', 'F27'],\n",
       "  ['F10', 'F40', 'F46', 'F28'],\n",
       "  ['F33', 'F37'],\n",
       "  ['F7', 'F12', 'F41', 'F18']]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = re.compile(r'F\\d+')\n",
    "[[bool(reg.search(n)) for n in sent_tokenize(l['narration'])] for l in train if l['narrative_questions'][1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']\n",
    "[[reg.search(n) for n in sent_tokenize(l['narration'])] for l in train if l['narrative_questions'][1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']\n",
    "# Store all matches as a list of strings\n",
    "[[reg.findall(n) for n in sent_tokenize(l['narration'])] for l in train if l['narrative_questions'][1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], ['F4', 'F11'], ['F3', 'F15', 'F8', 'F12'], []],\n",
       " [[], [], ['F6', 'F10'], ['F4', 'F1', 'F9', 'F11'], []],\n",
       " [[], [], ['F5', 'F30'], ['F26', 'F17', 'F15', 'F28'], []],\n",
       " [[], [], ['F18', 'F31', 'F19', 'F36', 'F38'], ['F35', 'F20', 'F5'], []],\n",
       " [[], [], ['F12', 'F1'], ['F11', 'F4', 'F3', 'F5'], []],\n",
       " [[], [], ['F24', 'F23', 'F9', 'F18', 'F14'], ['F10', 'F11', 'F2'], []],\n",
       " [[], [], ['F11', 'F4', 'F6', 'F17', 'F3'], ['F5', 'F2', 'F16'], []],\n",
       " [[], [], ['F18', 'F3', 'F12'], ['F15', 'F14', 'F4'], []],\n",
       " [[], [], ['F36', 'F8', 'F26', 'F35', 'F3'], ['F12', 'F24', 'F9'], []],\n",
       " [[], [], ['F17', 'F9'], ['F19', 'F18', 'F43', 'F23'], []],\n",
       " [[], [], ['F4', 'F8'], ['F3', 'F14', 'F5', 'F7'], []],\n",
       " [[], [], ['F8', 'F6', 'F17'], ['F4', 'F10', 'F5'], []],\n",
       " [[], [], ['F4', 'F10', 'F1', 'F2', 'F7'], ['F9', 'F8', 'F6'], []],\n",
       " [[], [], ['F8', 'F21', 'F27', 'F24', 'F14'], ['F25', 'F28', 'F17'], []],\n",
       " [[], [], ['F33', 'F8', 'F17', 'F37', 'F4'], ['F29', 'F32', 'F2'], []],\n",
       " [[], [], ['F1', 'F4', 'F2'], ['F6', 'F5', 'F7'], []],\n",
       " [[], [], ['F12', 'F38'], ['F75', 'F61', 'F92', 'F23'], []],\n",
       " [[], [], ['F2', 'F5', 'F1', 'F3', 'F4'], ['F6', 'F7'], []],\n",
       " [[], [], ['F11', 'F4', 'F2', 'F1'], ['F9', 'F7', 'F6'], []],\n",
       " [[], [], ['F4', 'F10'], ['F5', 'F1', 'F8', 'F7'], []],\n",
       " [[], [], ['F7', 'F15'], ['F8', 'F16', 'F1', 'F2'], []],\n",
       " [[], [], ['F10', 'F11'], ['F9', 'F7', 'F12', 'F3'], []],\n",
       " [[], [], ['F11', 'F1'], ['F5', 'F2', 'F8', 'F12'], []],\n",
       " [[], [], ['F4', 'F15', 'F3'], ['F12', 'F17', 'F14'], []],\n",
       " [[], [], ['F6', 'F8'], ['F1', 'F5', 'F4', 'F2'], []],\n",
       " [[], [], ['F12', 'F5', 'F15', 'F6', 'F1'], ['F13', 'F16', 'F10'], []],\n",
       " [[], [], ['F6', 'F9'], ['F12', 'F3', 'F1', 'F13'], []],\n",
       " [[], [], ['F4', 'F8'], ['F10', 'F11', 'F12', 'F9'], []],\n",
       " [[], [], ['F16', 'F43'], ['F14', 'F35', 'F17', 'F44'], []],\n",
       " [[], [], ['F1', 'F2', 'F4'], ['F8', 'F5', 'F3'], []],\n",
       " [[], [], ['F5', 'F1'], ['F6', 'F4', 'F7', 'F9'], []],\n",
       " [[], [], ['F3', 'F5', 'F14'], ['F20', 'F1', 'F12'], []],\n",
       " [[], [], ['F14', 'F25'], ['F7', 'F13', 'F16', 'F19'], []],\n",
       " [[], [], ['F22', 'F20', 'F37', 'F10'], ['F16', 'F23', 'F24'], []],\n",
       " [[], [], ['F3', 'F4', 'F7', 'F12'], ['F10', 'F2', 'F11'], []],\n",
       " [[], [], ['F10', 'F8', 'F9'], ['F2', 'F3', 'F7'], []],\n",
       " [[], [], ['F27', 'F15', 'F2', 'F21'], ['F7', 'F9', 'F5'], []],\n",
       " [[], [], ['F11', 'F3', 'F6'], ['F1', 'F7', 'F8'], []],\n",
       " [[], [], ['F44', 'F8', 'F3', 'F27'], ['F10', 'F37', 'F40'], []]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store all matches as a list of strings\n",
    "[[reg.findall(n) for n in l['narrative_questions']] for l in train if l['narrative_questions'][1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The classifier is very uncertain about the correct label for the case given',\n",
       "  \" Regarding the classifier's decision, there is close to an even split on the probability of either of the possible labels is the correct label but the classifier chooses the label as C2\"],\n",
       " ['The model is confident in its prediction, as it predicted class C1 with a likelihood of 90.48% and hence, for the given case, there is a smaller chance of it being any other class label',\n",
       "  'F6 and F10 are deemed the most important features whereas on the other hand all the other features have moderate to minimal amounts of influence'],\n",
       " ['The most likely label for the given case is C1 since the predicted probability of C2 is only 34.27% and this means that the likelihood of C1 is 65.73%',\n",
       "  'The most relevant features that led to the C1 classification verdict are F5, F30, F26, F17, and F15'],\n",
       " ['The prediction likelihoods across the two classes are 15.35% for class C1 and 84.65% for C2, it can be concluded that C2 is the most probable class label for the given data instance',\n",
       "  \"According to the attribution analysis conducted, the different input variables have varying degrees of influence on the model's decision here\"],\n",
       " ['The model is very confident that C3 is the most probable class for the given case, with a probability of 90.48% which means that the other labels are very unlikely',\n",
       "  'F12 and F1 are the most important variables with respect to this classification verdict while all other variables are shown to have a medium or low impact'],\n",
       " ['The model predicted class C1 with an 81.98% prediction likelihood',\n",
       "  'F24 had the largest impact, followed by F23, F9, F18, F14, F10, F11, F2, F8, F21, F20, F27, F4, F12, F15, F19, F13, F16, F30, and finally, F29, which had the smallest non-zero impact'],\n",
       " ['The classification output is C1, however, the classifier is somewhat unsure about this prediction decision because the corresponding predicted probability is only 55.19%',\n",
       "  'F11 is by far the most influential feature whereas F4, F6, and F17 have been recognised as having the biggest effect on prediction output here after F11'],\n",
       " ['For the selected case, the model assigns the label C1',\n",
       "  'The prediction probability distribution across the classes C2 and C1 is 2.40% and 97.60%, respectively'],\n",
       " ['According to the classification algorithm, the best label for the given case is C2, because there is little to no chance that C1 is the correct label',\n",
       "  'Not all of the features are found to contribute to the label given here'],\n",
       " ['The model labels the case as C2 with fairly high confidence equal to 89.73%, whereas the likelihood of C1 is only 10.27%',\n",
       "  'Analysis shows that only 20 of the 46 input variables contribute to the prediction assertion above'],\n",
       " ['The label predicted for this case is C1 with very high confidence of approximately 97.71% which insinuates that there is a marginal possibility that C2 could be the label',\n",
       "  'The above classification decision is largely due to the values of F4, F8, F3, and F14'],\n",
       " ['The case is labelled as C2 by the model but looking at the predicted probabilities across the different classes, there is a 33.63% chance that the label could be C1',\n",
       "  'To explain the above prediction conclusion, the analysis revealed that the majority of the features have negative influences or attributions, pushing the prediction away from C2 in favour of C1'],\n",
       " ['The most likely label chosen by the model in this case is C1',\n",
       "  'The decision above is based on the prediction probabilities for the two possible labels, C1 and C2, which are 94.25% and 5.75%, respectively'],\n",
       " ['The best choice of label for the given case is C2 according to the classification algorithm, since there is little to no chance that C1 is the right class',\n",
       "  'Not all the features are shown to contribute either positively or negatively towards the label assigned here'],\n",
       " ['The prediction probabilities for classes C2 and C1, respectively, are 15.35% and 84.65%',\n",
       "  \"Based on the aforementioned, C1 is the most likely class label for the presented data instance, and according to the attribution analysis, the various input variables had varying degrees of impact on the model's classification judgement\"],\n",
       " ['Probably C1 is the right label for this case since the probability of the alternative label, C3 and C2, are only 1.03% and 0.0%',\n",
       "  'The order of importance of the features for the above classification verdict is F1, F4, F2, F6, F5, F7, F3, and F8'],\n",
       " ['The following is the classification for the provided data:  C1 is the most likely class label and C2 cannot possibly be the correct label given the likelihood is 0.0%',\n",
       "  'F12, F38, and F75 are the key variables that contributed to the classification choice'],\n",
       " ['For the given instance, the model generated the label C1 with a very high predicted probability equal to 99.66% which implies that the model is very confident that C2 is not the correct label',\n",
       "  'Ranking the contributions of the features to the prediction above, from the most relevant to the least relevant, is as follows: F2, F5, F1, F3, F4, F6, and F7'],\n",
       " ['According to the model, C3 is the least probable class, while the most probable class for the given case is identified as C2',\n",
       "  \"The top two variables with the greatest control over the model in terms of this case's label assignment are F11 and F4 but on the contrary, the rest of the variables have moderate-to-lower influence\"],\n",
       " ['The model is quite certain that C1 is the most likely class for the current scenario',\n",
       "  'C1 has a 90.48% chance of being correct, implying that any of the other labels is highly unlikely'],\n",
       " ['The case under consideration is labelled as C1 by the model employed for this classification problem',\n",
       "  'However, according to the model, there is a 45.34% chance that C2 could be the label, presenting some level of uncertainty in the classification verdict made here'],\n",
       " ['The probability that C2 is the label for the given case is zero and judging by the predicted probability associated with the remaining classes, the classifier is fairly certain that the correct label is C3 given its likelihood of 75.0%',\n",
       "  'The features are ranked in order of their respective impacts, from most important to least relevant: F10, F11, F9, F7, F12, F3, F6, F4, F8, F2, F1, and F5'],\n",
       " ['The correct label, according to the classifier,  is neither C3 nor C2, but C1, with a prediction likelihood of about 75.0%',\n",
       "  'By analysing the attributions of the input features, they can be ranked according to the level of impact, from the most important feature to the least relevant, as follows: F11, F1, F5, F2, F8, F12, F7, F10, F6, F9, F3, and F4'],\n",
       " ['The model identifies the case as C1 since, the true label has just 33.63 percent chance of being C2 when the prediction probability is calculated',\n",
       "  'The in-depth analysis found that the bulk of the attributes had negative impacts, driving the prediction away from C1 and toward C2'],\n",
       " ['0.0% is the predicted probability that C2 is the true label for the test example under consideration according to the classifier',\n",
       "  ' Judging based on the predicted probabilities associated with the other remaining labels, the classifier is 75.0% confident that C3 is the correct label'],\n",
       " ['The final classification made was C2, but with a likelihood of only 55.19%, the model is uncertain about this prediction',\n",
       "  'By far, feature F12 had the most impact and following F12 are F5, F15, and F6 have been identified as having the comparable influence on classification'],\n",
       " ['Based on the information available about the case under consideration, the classification model is very uncertain about the appropriate labels for the case',\n",
       "  'According to the model, there is an almost equal distribution in terms of the probability that any one of C1 and C2 is an appropriate label'],\n",
       " [\"The likelihood of the true label for the given test case being equal to the model's output prediction, C2, is 85.71% and since it's not 100%, there is a small chance of about 14.29% that the model could be wrong\",\n",
       "  \"Among the features employed for this classification, F4, F8, F10, F11, F12, and F9 are the top features influencing the model's prediction decision\"],\n",
       " ['For the case under consideration, the model outputs C2 with high confidence level since the associated predicted class label is 89.73% whilst that of C1 is just 10.27%',\n",
       "  'Just few features out of the entire input features are shown to have control over the prediction made here'],\n",
       " ['The odds are in favour of C2 being the correct label for the given case',\n",
       "  'This is because the probability of the other label, C1, is only 1.03%'],\n",
       " ['The model selects C2 as the correct label with a probability of 57.58%, while the other class, C1, has a slightly lower probability of 42.42%',\n",
       "  'The most relevant attribute is F5, followed by F7, F1, F6, F8, F9, F3, F4 and finally F2, which is the least relevant'],\n",
       " ['C2 was assigned to the given case by the classifier with a likelihood of 93.32%, leaving thhe likelihood of the C1 equal to only 6.68%',\n",
       "  'The most influential features were F3, F5, and F14'],\n",
       " ['The prediction output decision by the model is that the likelihood of label C2 is 94.15% and that of class C1 is only around 5.85%, meaning the model is certain that C2 is likely the true label for the given case',\n",
       "  'First of all, the classification is performed with negligible contributions from the variables F23, F30, F15, F8, and F12 since their attributions are very close to zero'],\n",
       " ['Because the prediction probability of C2 is equal to 0.0%, the presented case is labelled as C1 with a very high level of confidence',\n",
       "  'For this classification scenario, the input features that have the greatest influence on the end outcome are F22, F20, F37, and F10'],\n",
       " ['The prediction likelihoods across the two classes, C2 and C1, is 97.82% and 2.18%, respectively',\n",
       "  'Based on this, the model assigned the given case the label C2'],\n",
       " [\"The case's predicted class is C3, with a likelihood of around 68.12%, C1, with around 29.87%, and C2 with around 2.01%\",\n",
       "  'It is fairly confident of its C3 classification and is very certain that the given case is not class C2'],\n",
       " ['The probability that the true label is C1 according to the machine learning model or algorithm based on the input variables is about 80.0% highlighting that the model is fairly confident in the classification decision made here',\n",
       "  'With the contribution of different variables, the most important variables in this classification decision are F27, F15, F2, F7, and F21'],\n",
       " ['The likelihood of the different classes is 40.0% and 60.0% meaning there is a 60.0% chance that the label for this case should be C1, while there is a 40% chance that it is not',\n",
       "  'The top features contributing either positively or negatively to the labelling decision above include F11, F6, F1, and F3 with the strongest contribution to the prediction of C1 from F11, followed by F3, F6, and F1'],\n",
       " ['There is about an 82.0% chance that the true label of the test observation is C1, therefore, the model is quite confident about this labelling decision',\n",
       "  'In terms of the contributions from the different features, the most important features for this classification decision include F44, F8, F3, and F27']]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l['narration'].split(\". \")[:2] for l in train if l['narrative_questions'][1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Provide a statement on the features with the least impact on the prediction made for this test case.',\n",
       "  39)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([l[4] for l in train['narrative_questions'] if l[1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F4 F11 F3 F15 F8 F12 F2 F20 F10 F9 F14 F16 F18 F6 F5 F17 F13 F7 F19 F1',\n",
       " 'F6 F10 F4 F1 F9 F11 F5 F12 F7 F3 F8 F2',\n",
       " 'F5 F30 F26 F17 F15 F28 F14 F1 F23 F9 F2 F20 F19 F29 F21 F18 F22 F6 F12 F10 F3 F4 F13 F27 F16 F7 F24 F11 F25 F8',\n",
       " 'F18 F31 F19 F36 F38 F35 F20 F5 F9 F23 F22 F17 F7 F28 F8 F21 F24 F10 F1 F32 F30 F15 F26 F2 F13 F34 F27 F4 F11 F14 F29 F12 F37 F3 F25 F16 F33 F6',\n",
       " 'F12 F1 F11 F4 F3 F5 F10 F2 F9 F7 F8 F6',\n",
       " 'F24 F23 F9 F18 F14 F10 F11 F2 F8 F21 F20 F27 F4 F12 F15 F19 F13 F16 F30 F29 F22 F6 F1 F5 F26 F3 F25 F7 F17 F28',\n",
       " 'F11 F4 F6 F17 F3 F5 F2 F16 F9 F14 F12 F1 F7 F18 F15 F8 F13 F19 F10',\n",
       " 'F18 F3 F12 F15 F14 F4 F17 F11 F13 F2 F7 F20 F6 F10 F16 F5 F1 F8 F19 F9',\n",
       " 'F36 F8 F26 F35 F3 F12 F24 F9 F21 F6 F20 F5 F4 F25 F19 F27 F7 F23 F37 F31 F30 F33 F13 F28 F11 F10 F22 F2 F29 F15 F1 F38 F14 F32 F16 F34 F17 F18',\n",
       " 'F17 F9 F19 F18 F43 F23 F32 F20 F33 F29 F24 F46 F42 F5 F26 F13 F15 F34 F30 F1 F14 F7 F31 F38 F12 F11 F37 F28 F10 F27 F21 F40 F6 F25 F2 F4 F44 F36 F39 F41 F16 F8 F3 F22 F45 F35',\n",
       " 'F4 F8 F3 F14 F5 F7 F12 F11 F10 F13 F2 F9 F6 F1',\n",
       " 'F8 F6 F17 F4 F10 F5 F1 F7 F14 F18 F19 F2 F15 F9 F13 F16 F11 F12 F3',\n",
       " 'F4 F10 F1 F2 F7 F9 F8 F6 F3 F5',\n",
       " 'F8 F21 F27 F24 F14 F25 F28 F17 F26 F15 F22 F12 F20 F4 F19 F7 F16 F35 F6 F30 F36 F9 F38 F3 F2 F37 F23 F31 F11 F10 F34 F13 F1 F29 F33 F18 F5 F32',\n",
       " 'F33 F8 F17 F37 F4 F29 F32 F2 F31 F11 F24 F16 F38 F1 F22 F5 F12 F35 F23 F27 F7 F19 F21 F14 F9 F10 F28 F30 F20 F36 F34 F6 F26 F18 F25 F3 F13 F15',\n",
       " 'F1 F4 F2 F6 F5 F7 F3 F8',\n",
       " 'F12 F38 F75 F61 F92 F23 F72 F7 F19 F64 F26 F77 F29 F37 F78 F42 F14 F1 F16 F43 F58 F24 F57 F63 F93 F39 F6 F18 F25 F34 F86 F47 F17 F65 F85 F4 F56 F13 F84 F74 F69 F30 F73 F89 F46 F20 F9 F33 F11 F52 F32 F91 F82 F40 F48 F2 F67 F35 F15 F8 F41 F81 F60 F5 F90 F83 F80 F79 F68 F50 F36 F59 F44 F66 F70 F76 F10 F71 F45 F51 F53 F28 F31 F22 F55 F88 F87 F54 F21 F27 F62 F3 F49',\n",
       " 'F2 F5 F1 F3 F4 F6 F7',\n",
       " 'F11 F4 F2 F1 F9 F7 F6 F3 F8 F12 F5 F10',\n",
       " 'F4 F10 F5 F1 F8 F7 F2 F11 F3 F12 F9 F6',\n",
       " 'F7 F15 F8 F16 F1 F2 F5 F21 F28 F23 F9 F20 F17 F26 F19 F30 F24 F3 F27 F14 F10 F33 F25 F13 F4 F11 F18 F12 F29 F22 F31 F6 F32',\n",
       " 'F10 F11 F9 F7 F12 F3 F6 F4 F8 F2 F1 F5',\n",
       " 'F11 F1 F5 F2 F8 F12 F7 F10 F6 F9 F3 F4',\n",
       " 'F4 F15 F3 F12 F17 F14 F10 F11 F9 F5 F2 F19 F8 F18 F16 F13 F1 F7 F6',\n",
       " 'F6 F8 F1 F5 F4 F2 F7 F11 F12 F3 F10 F9',\n",
       " 'F12 F5 F15 F6 F1 F13 F16 F10 F17 F4 F2 F18 F3 F11 F19 F14 F8 F7 F9',\n",
       " 'F6 F9 F12 F3 F1 F13 F8 F19 F18 F7 F15 F4 F17 F14 F11 F16 F20 F10 F2 F5',\n",
       " 'F4 F8 F10 F11 F12 F9 F3 F14 F6 F7 F2 F13 F1 F5 F16 F15',\n",
       " 'F16 F43 F14 F35 F17 F44 F3 F40 F21 F5 F45 F2 F28 F7 F6 F29 F13 F27 F19 F37 F15 F39 F4 F18 F22 F33 F38 F24 F8 F46 F9 F23 F31 F12 F26 F1 F30 F42 F11 F32 F25 F34 F36 F20 F10 F41',\n",
       " 'F1 F2 F4 F8 F5 F3 F7 F6',\n",
       " 'F5 F1 F6 F4 F7 F9 F3 F8 F2',\n",
       " 'F3 F5 F14 F20 F1 F12 F7 F33 F18 F10 F17 F27 F26 F19 F32 F2 F16 F11 F31 F21 F4 F22 F24 F9 F15 F29 F25 F8 F13 F28 F30 F6 F23',\n",
       " 'F14 F25 F7 F13 F16 F19 F3 F26 F24 F22 F1 F2 F18 F10 F6 F28 F5 F21 F9 F27 F11 F23 F30 F15 F12 F8 F17 F4 F20 F29',\n",
       " 'F22 F20 F37 F10 F16 F23 F24 F5 F19 F21 F11 F13 F25 F14 F29 F28 F3 F9 F31 F12 F4 F27 F1 F18 F33 F26 F17 F8 F7 F34 F32 F38 F15 F6 F36 F35 F30 F2',\n",
       " 'F3 F4 F7 F12 F10 F2 F11 F6 F13 F9 F5 F8 F14 F1',\n",
       " 'F10 F8 F9 F2 F3 F7 F11 F5 F12 F1 F4 F6',\n",
       " 'F27 F15 F2 F21 F7 F9 F5 F38 F24 F6 F37 F36 F39 F43 F1 F11 F34 F25 F20 F8 F19 F10 F32 F17 F41 F4 F40 F13 F29 F18 F46 F44 F23 F28 F3 F31 F12 F30 F14 F33 F45 F35 F22 F16 F26 F42',\n",
       " 'F11 F3 F6 F1 F7 F8 F4 F2 F10 F9 F5',\n",
       " 'F44 F8 F3 F27 F10 F37 F40 F46 F28 F33 F26 F22 F42 F17 F19 F6 F23 F35 F36 F1 F12 F7 F41 F16 F20 F14 F30 F11 F43 F13 F39 F5 F38 F34 F2 F32 F21 F18 F4 F9 F45 F31 F15 F24 F29 F25']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(l['feature_nums']) for l in train if l['narrative_questions'][1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['model_name', 'predicted_class', 'task_name', 'narration', 'values', 'sign', 'narrative_id', 'unique_id', 'classes_dict', 'narrative_questions', 'feature_nums', 'ft_num_to_name', 'old2new_ft_nums', 'old2new_classes'],\n",
       "    num_rows: 375\n",
       "})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify the questions\n",
    "Let's convert the questions, which were designed in a way to elicit a varying response from the annotators, into fewer umbrella questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "reg = re.compile(r'F\\d+')\n",
    "Counter([l['narrative_questions'][1] for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the prediction made for the test case.']).most_common()\n",
    "[[' '.join(reg.findall(n)) for n in l['narrative_questions']] for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the prediction made for the test case.']\n",
    "[' '.join(l['feature_nums']) for l in train if l['narrative_questions'][0] == 'Provide a statement summarizing the prediction made for the test case.']\n",
    "```\n",
    "A. For 99 cases the format is:\n",
    "* 'In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).'\n",
    "* \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\"\n",
    "* 'Describe the degree of impact of the following features: [0-4 fts (after first 7-9)]?' (3 times there are 0)\n",
    "\n",
    "B. For 78 cases the format is:\n",
    "* \"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\"\n",
    "* \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\"\n",
    "* 'Summarize the direction of influence of the features [the next 3-4 features (after first 2-4)] with moderate impact on the prediction made for this test case.'\n",
    "\n",
    "C. For 53 cases the format is:\n",
    "* 'Summarize the prediction for the given test example?'\n",
    "* \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\"\n",
    "* 'Compare and contrast the impact of the following attributes  [3-4 seemingly random features] on the models prediction of [C1/C2].'\n",
    "* 'Summarize the set of features has little to no impact on the prediction?'\n",
    "\n",
    "D. For 20 cases the format is:\n",
    "* 'Summarize the prediction for the given test example?'\n",
    "* 'For this test case, summarize the top features influencing the model's decision.'\n",
    "* 'For these top features, what are the respective directions of influence on the prediction?'\n",
    "* 'Provide a statement on the set of features has limited impact on the prediction of [C1/C2] by the model for the given test example?'\n",
    "\n",
    "E. For 39 cases the format is:\n",
    "* 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.'\n",
    "* 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.'\n",
    "* 'Compare the direction of impact of the features: [2-5 top features].'\n",
    "* 'Summarize the direction of influence of the features [the next 3-4 features] with moderate impact on the prediction made for this test case.'\n",
    "* 'Provide a statement on the features with the least impact on the prediction made for this test case.'\n",
    "\n",
    "F. For 44 cases the format is:\n",
    "* 'Provide a statement summarizing the prediction made for the test case.'\n",
    "* 'For the current test instance, describe the direction of influence of the following features: [2-5 top features]'\n",
    "* 'Compare and contrast the impact of the following features [the next 3-4 features] on the models prediction of [C1/C2].'\n",
    "* 'Describe the degree of impact of the following features: [the next 0-4 features]?' (usually 4 unless there are not enough features)\n",
    "\n",
    "G. For 39 cases the format is:\n",
    "* 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.'\n",
    "* 'Summarize the direction of influence of the features [2-5 top features] on the prediction made for this test case.'\n",
    "* 'Compare the direction of impact of the features: [the next 3-4 features].'\n",
    "* 'Describe the degree of impact of the following features:[the next 0-4 features]'\n",
    "\n",
    "H. For 3 cases the format is:\n",
    "* 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.'\n",
    "* 'Summarize the direction of influence of the variables [2-3 top features] on the prediction made for this test case.' -->\n",
    "* 'Compare the direction of impact of the variables: [the next 3-4 features].'\n",
    "* 'Describe the degree of impact of the following variables: [the next 3-4 features]?'\n",
    "\n",
    "| Q | A | New Q |\n",
    "| ---- | ---- | ---- |\n",
    "| Summarise the prediction | Note: In E (39) this question is asked across 2 sentences | Summarise the prediction |\n",
    "| Summarise the top features | A-D (250): Top features aren't named, just says 'top features' | a) Summarise the top features |\n",
    "|   | E-H  (125) specifies 2-5 top features | b) Summarise these top features ([fts]) |\n",
    "|   | Note: In D (20) this question is asked across 2 sentences |   |\n",
    "| Summarise moderate fts | A (99): 3-4 named fts (after first 7-9) | Summarise these moderate features ([fts]) |\n",
    "|   | B, C (131): 3-4 named fts (after first 2-4) |   |\n",
    "|   | E-H (125) named fts (the next 3-4) |   |\n",
    "| Summarise more/lower fts | C-E (112) describe fts with little to no impact (fts not named) | a) Summarise the negligible features |\n",
    "|   | F-H (86) 0-4 named fts | b) Summarise these negligible features ([fts]) |\n",
    "|   | Note: A,B (177) do not have a 4th Q |   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_qs(row):\n",
    "    narr_qs = row['narrative_questions']\n",
    "    if narr_qs[0] == 'In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).':\n",
    "        label = 'A'\n",
    "    elif narr_qs[0] == \"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\":\n",
    "        label = 'B'\n",
    "    elif narr_qs[0] == 'Summarize the prediction for the given test example?' and narr_qs[1] == \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\":\n",
    "        label = 'C'\n",
    "    elif narr_qs[0] == 'Summarize the prediction for the given test example?' and narr_qs[1] == \"For this test case, summarize the top features influencing the model's decision.\": \n",
    "        label = 'D'\n",
    "    elif narr_qs[0] == \"Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.\" and narr_qs[1] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.':\n",
    "        label = 'E'\n",
    "    elif narr_qs[0] == 'Provide a statement summarizing the prediction made for the test case.':\n",
    "        label = 'F'\n",
    "    elif narr_qs[0] == 'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.':\n",
    "        label = 'G'\n",
    "    elif narr_qs[0] == 'Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.' and narr_qs[1][:53] == 'Summarize the direction of influence of the variables':\n",
    "        label = 'H'\n",
    "    else:\n",
    "        raise ValueError('Unknown narrative question')\n",
    "    row['narr_q_label'] = label\n",
    "    return row\n",
    "\n",
    "def simplify_narr_question(row):\n",
    "    label = row['narr_q_label']\n",
    "    mentioned_fts = [reg.findall(n) for n in row['narrative_questions']]\n",
    "    q1 = \"Summarise the prediction.\"\n",
    "    \n",
    "    def commas_and_and(fts_list):\n",
    "        if len(fts_list) == 0:\n",
    "            return ' '\n",
    "        elif len(fts_list) == 1:\n",
    "            return fts_list[0]\n",
    "        elif len(fts_list) == 2:\n",
    "            return f'{fts_list[0]} and {fts_list[1]}'\n",
    "        else:\n",
    "            return f'{\", \".join(fts_list[:-1])}, and {fts_list[-1]}'\n",
    "    \n",
    "    if label in ['A', 'B', 'C', 'D']:\n",
    "        q2 = 'Summarise the top features.'\n",
    "    elif label == 'E':\n",
    "        q2 = f'Summarise these top features ({commas_and_and(mentioned_fts[2])}).'\n",
    "    else: # label in ['F', 'G', 'H']\n",
    "        q2 = f'Summarise these top features ({commas_and_and(mentioned_fts[1])}).'\n",
    "        \n",
    "    if label in ['A', 'B', 'C', 'F', 'G', 'H']:\n",
    "        q3 = f'Summarise these moderate features ({commas_and_and(mentioned_fts[2])}).'\n",
    "    elif label ==  'D':\n",
    "        q3 = '' # Ds have no q3 \n",
    "    else: # label ==  'E'\n",
    "        q3 = f'Summarise these moderate features ({commas_and_and(mentioned_fts[3])}).'\n",
    "    \n",
    "    if label in ['A', 'B']:\n",
    "        q4 = ''\n",
    "    elif label in ['C', 'D', 'E']:\n",
    "        q4 = f'Summarise the negligible features.'\n",
    "    else: # label in ['F', 'G', 'H']\n",
    "        q4 = f'Summarise these negligible features ({commas_and_and(mentioned_fts[3])}).'\n",
    "        \n",
    "    row['simple_narr_qs'] = [q1, q2, q3, q4]\n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Summarize the direction of influence of the variables'[:53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|| 3/3 [00:00<00:00, 691.33it/s]\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e52c5fd61e3bc2e9.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-184d025139b53859.arrow\n",
      "Loading cached processed dataset at /home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8efe0f68e9311dbd.arrow\n",
      "100%|| 375/375 [00:00<00:00, 8064.23ex/s]\n",
      "100%|| 47/47 [00:00<00:00, 7504.66ex/s]\n",
      "100%|| 47/47 [00:00<00:00, 7004.42ex/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"james-burton/textual-explanations\")\n",
    "new_ds = ds.map(label_qs)\n",
    "new_ds = new_ds.map(simplify_narr_question)\n",
    "# new_q_val = val.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], ['F4', 'F11'], ['F3', 'F15', 'F8', 'F12'], []],\n",
       " [[], [], ['F6', 'F10'], ['F4', 'F1', 'F9', 'F11'], []],\n",
       " [[], [], ['F5', 'F30'], ['F26', 'F17', 'F15', 'F28'], []],\n",
       " [[], [], ['F18', 'F31', 'F19', 'F36', 'F38'], ['F35', 'F20', 'F5'], []],\n",
       " [[], [], ['F12', 'F1'], ['F11', 'F4', 'F3', 'F5'], []],\n",
       " [[], [], ['F24', 'F23', 'F9', 'F18', 'F14'], ['F10', 'F11', 'F2'], []],\n",
       " [[], [], ['F11', 'F4', 'F6', 'F17', 'F3'], ['F5', 'F2', 'F16'], []],\n",
       " [[], [], ['F18', 'F3', 'F12'], ['F15', 'F14', 'F4'], []],\n",
       " [[], [], ['F36', 'F8', 'F26', 'F35', 'F3'], ['F12', 'F24', 'F9'], []],\n",
       " [[], [], ['F17', 'F9'], ['F19', 'F18', 'F43', 'F23'], []],\n",
       " [[], [], ['F4', 'F8'], ['F3', 'F14', 'F5', 'F7'], []],\n",
       " [[], [], ['F8', 'F6', 'F17'], ['F4', 'F10', 'F5'], []],\n",
       " [[], [], ['F4', 'F10', 'F1', 'F2', 'F7'], ['F9', 'F8', 'F6'], []],\n",
       " [[], [], ['F8', 'F21', 'F27', 'F24', 'F14'], ['F25', 'F28', 'F17'], []],\n",
       " [[], [], ['F33', 'F8', 'F17', 'F37', 'F4'], ['F29', 'F32', 'F2'], []],\n",
       " [[], [], ['F1', 'F4', 'F2'], ['F6', 'F5', 'F7'], []],\n",
       " [[], [], ['F12', 'F38'], ['F75', 'F61', 'F92', 'F23'], []],\n",
       " [[], [], ['F2', 'F5', 'F1', 'F3', 'F4'], ['F6', 'F7'], []],\n",
       " [[], [], ['F11', 'F4', 'F2', 'F1'], ['F9', 'F7', 'F6'], []],\n",
       " [[], [], ['F4', 'F10'], ['F5', 'F1', 'F8', 'F7'], []],\n",
       " [[], [], ['F7', 'F15'], ['F8', 'F16', 'F1', 'F2'], []],\n",
       " [[], [], ['F10', 'F11'], ['F9', 'F7', 'F12', 'F3'], []],\n",
       " [[], [], ['F11', 'F1'], ['F5', 'F2', 'F8', 'F12'], []],\n",
       " [[], [], ['F4', 'F15', 'F3'], ['F12', 'F17', 'F14'], []],\n",
       " [[], [], ['F6', 'F8'], ['F1', 'F5', 'F4', 'F2'], []],\n",
       " [[], [], ['F12', 'F5', 'F15', 'F6', 'F1'], ['F13', 'F16', 'F10'], []],\n",
       " [[], [], ['F6', 'F9'], ['F12', 'F3', 'F1', 'F13'], []],\n",
       " [[], [], ['F4', 'F8'], ['F10', 'F11', 'F12', 'F9'], []],\n",
       " [[], [], ['F16', 'F43'], ['F14', 'F35', 'F17', 'F44'], []],\n",
       " [[], [], ['F1', 'F2', 'F4'], ['F8', 'F5', 'F3'], []],\n",
       " [[], [], ['F5', 'F1'], ['F6', 'F4', 'F7', 'F9'], []],\n",
       " [[], [], ['F3', 'F5', 'F14'], ['F20', 'F1', 'F12'], []],\n",
       " [[], [], ['F14', 'F25'], ['F7', 'F13', 'F16', 'F19'], []],\n",
       " [[], [], ['F22', 'F20', 'F37', 'F10'], ['F16', 'F23', 'F24'], []],\n",
       " [[], [], ['F3', 'F4', 'F7', 'F12'], ['F10', 'F2', 'F11'], []],\n",
       " [[], [], ['F10', 'F8', 'F9'], ['F2', 'F3', 'F7'], []],\n",
       " [[], [], ['F27', 'F15', 'F2', 'F21'], ['F7', 'F9', 'F5'], []],\n",
       " [[], [], ['F11', 'F3', 'F6'], ['F1', 'F7', 'F8'], []],\n",
       " [[], [], ['F44', 'F8', 'F3', 'F27'], ['F10', 'F37', 'F40'], []]]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[reg.findall(n) for n in l['narrative_questions']] for l in new_ds['train'] if l['narr_q_label'] in ['E', 'F', 'G', 'H']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F16, and F15).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4 and F11).',\n",
       "  'Summarise these moderate features (F3, F15, F8, and F12).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features ( ).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F1, F9, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F5, and F10).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F7, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F26, F25, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F18, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F6 and F10).',\n",
       "  'Summarise these moderate features (F4, F1, F9, and F11).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F12, F2, and F21).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F28, F44, and F71).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F10, F2, and F6).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F8, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F6, F5, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F7 and F9).',\n",
       "  'Summarise these moderate features (F3, F4, F6, and F8).',\n",
       "  'Summarise these negligible features (F10, F1, F2, and F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F7 and F1).',\n",
       "  'Summarise these moderate features (F5, F3, F4, and F6).',\n",
       "  'Summarise these negligible features (F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F32, F17, and F24).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F18, F5, and F11).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F2, F10, and F15).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4 and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F5, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F5, F8, and F7).',\n",
       "  'Summarise these moderate features (F9, F16, and F18).',\n",
       "  'Summarise these negligible features (F4, F1, F13, and F20).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F31, F15, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F5, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F2, F1, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F9, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F5 and F30).',\n",
       "  'Summarise these moderate features (F26, F17, F15, and F28).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F8, F7, and F17).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F10, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F16, F10, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F18, F31, F19, F36, and F38).',\n",
       "  'Summarise these moderate features (F35, F20, and F5).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8, F10, F6, and F1).',\n",
       "  'Summarise these moderate features (F9, F3, and F2).',\n",
       "  'Summarise these negligible features (F5, F7, and F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F15, F23, and F16).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F12 and F1).',\n",
       "  'Summarise these moderate features (F11, F4, F3, and F5).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F4, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F14, F34, F23, and F29).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F8, and F6).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F24, F23, F9, F18, and F14).',\n",
       "  'Summarise these moderate features (F10, F11, and F2).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F1, F7, F3, and F8).',\n",
       "  'Summarise these moderate features (F6, F4, and F9).',\n",
       "  'Summarise these negligible features (F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F6, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F13, F16, and F14).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F10, F2, and F12).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F14, F10, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F14, F11, and F8).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F4, and F19).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F9, F2, F6, and F8).',\n",
       "  'Summarise these moderate features (F3, F5, and F4).',\n",
       "  'Summarise these negligible features (F7 and F1).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F17, F19, F11, and F14).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F6, and F5).',\n",
       "  'Summarise these moderate features (F8, F3, and F9).',\n",
       "  'Summarise these negligible features (F1, F7, and F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F13, F9, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11, F4, F6, F17, and F3).',\n",
       "  'Summarise these moderate features (F5, F2, and F16).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F7, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F4, and F5).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F7, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F16, F2, and F18).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F7, and F23).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F9, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F5, F9, F13, F2, and F12).',\n",
       "  'Summarise these moderate features (F3, F11, and F4).',\n",
       "  'Summarise these negligible features (F10, F8, and F1).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F4, F2, and F6).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F18, F3, and F12).',\n",
       "  'Summarise these moderate features (F15, F14, and F4).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8, F25, F9, F2, and F27).',\n",
       "  'Summarise these moderate features (F7, F24, and F3).',\n",
       "  'Summarise these negligible features (F31, F5, and F32).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F36, F8, F26, F35, and F3).',\n",
       "  'Summarise these moderate features (F12, F24, and F9).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F13, and F15).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F10, and F6).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F17 and F9).',\n",
       "  'Summarise these moderate features (F19, F18, F43, and F23).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4 and F8).',\n",
       "  'Summarise these moderate features (F3, F14, F5, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11, F4, F7, and F9).',\n",
       "  'Summarise these moderate features (F6, F8, and F1).',\n",
       "  'Summarise these negligible features (F3, F10, and F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8, F1, F7, and F5).',\n",
       "  'Summarise these moderate features (F10, F3, and F11).',\n",
       "  'Summarise these negligible features (F2, F6, and F9).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F7, F11, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F12, F11, and F19).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F2, F6, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F59, and F63).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F7 and F21).',\n",
       "  'Summarise these moderate features (F33, F8, F27, and F10).',\n",
       "  'Summarise these negligible features (F37, F1, F23, and F14).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8 and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8, F6, and F17).',\n",
       "  'Summarise these moderate features (F4, F10, and F5).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F10, F1, F2, and F7).',\n",
       "  'Summarise these moderate features (F9, F8, and F6).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F3, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F27, F25, and F32).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F5 and F20).',\n",
       "  'Summarise these moderate features (F31, F28, F8, and F17).',\n",
       "  'Summarise these negligible features (F16, F6, F2, and F11).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F25, F3, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F26, F15, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F9, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F13, F7, F18, and F21).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F13 and F11).',\n",
       "  'Summarise these moderate features (F12, F8, F2, and F7).',\n",
       "  'Summarise these negligible features (F1, F10, F3, and F14).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F21, F17, and F28).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F8, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F12, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8, F21, F27, F24, and F14).',\n",
       "  'Summarise these moderate features (F25, F28, and F17).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F1, F2, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F6, F8, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F7, F20, and F14).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F9, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F33, F8, F17, F37, and F4).',\n",
       "  'Summarise these moderate features (F29, F32, and F2).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F20, F48, and F23).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1, F4, and F2).',\n",
       "  'Summarise these moderate features (F6, F5, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F20, F10, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F12 and F38).',\n",
       "  'Summarise these moderate features (F75, F61, F92, and F23).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F6, F26, F32, F42, and F25).',\n",
       "  'Summarise these moderate features (F43, F29, and F7).',\n",
       "  'Summarise these negligible features (F39, F5, and F13).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F29 and F8).',\n",
       "  'Summarise these moderate features (F10, F23, F26, and F4).',\n",
       "  'Summarise these negligible features (F7, F25, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F24, F14, F30, and F18).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F7, F5, and F2).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F1, and F14).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F21, F11, and F13).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F12 and F1).',\n",
       "  'Summarise these moderate features (F17, F28, F5, and F7).',\n",
       "  'Summarise these negligible features (F10, F27, F21, and F18).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F3, F4, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F16, F14, and F17).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F8, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F17, F26, and F15).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F9, F8, F14, F7, and F4).',\n",
       "  'Summarise these moderate features (F12, F2, and F1).',\n",
       "  'Summarise these negligible features (F10, F3, and F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F7, F1, and F4).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F25, F12, and F15).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F24, F21, and F25).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F5, F1, F3, and F4).',\n",
       "  'Summarise these moderate features (F6 and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F9, and F4).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11, F4, F2, and F1).',\n",
       "  'Summarise these moderate features (F9, F7, and F6).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F8, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F7, F4, and F8).',\n",
       "  'Summarise these moderate features (F3, F5, and F6).',\n",
       "  'Summarise these negligible features (F1, F9, and F10).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F12, F5, F2, and F10).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F12, F4, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F15, F17, and F11).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F2, and F8).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F3 and F2).',\n",
       "  'Summarise these moderate features (F6, F1, F5, and F7).',\n",
       "  'Summarise these negligible features (F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F15, F5, and F4).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F8, F2, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F10, F1, and F4).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F18, F12, F30, and F10).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F9 and F1).',\n",
       "  'Summarise these moderate features (F22, F6, F12, and F11).',\n",
       "  'Summarise these negligible features (F17, F29, and F35).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F7, F9, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F4, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F3, F1, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1 and F4).',\n",
       "  'Summarise these moderate features (F9, F6, F5, and F2).',\n",
       "  'Summarise these negligible features (F8, F7, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1 and F6).',\n",
       "  'Summarise these moderate features (F12, F4, F5, and F11).',\n",
       "  'Summarise these negligible features (F10, F9, F3, and F8).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F7, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1, F2, F3, F5, and F7).',\n",
       "  'Summarise these moderate features (F6, F8, and F4).',\n",
       "  'Summarise these negligible features (F9, F10, and F11).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4 and F6).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F10 and F8).',\n",
       "  'Summarise these moderate features (F9, F13, F1, and F2).',\n",
       "  'Summarise these negligible features (F14, F6, F15, and F12).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F10, F5, and F9).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F27, F5, and F21).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F8, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F6, F4, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F1, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F1, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F6, and F8).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F15, F13, and F42).',\n",
       "  'Summarise these moderate features (F21, F20, and F17).',\n",
       "  'Summarise these negligible features (F10, F25, F11, and F27).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F5, F12, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F4, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F8, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4 and F10).',\n",
       "  'Summarise these moderate features (F5, F1, F8, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F9, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F8, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F2, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F9, F19, and F1).',\n",
       "  'Summarise these moderate features (F8, F15, and F13).',\n",
       "  'Summarise these negligible features (F18, F4, F6, and F12).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F4, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F9 and F3).',\n",
       "  'Summarise these moderate features (F1, F7, F10, and F5).',\n",
       "  'Summarise these negligible features (F2, F6, F4, and F8).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F15, F5, and F6).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F19, F1, and F18).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F1, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F3, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4 and F8).',\n",
       "  'Summarise these moderate features (F1, F5, F3, and F2).',\n",
       "  'Summarise these negligible features (F7 and F6).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F3, F6, F8, and F9).',\n",
       "  'Summarise these moderate features (F7, F2, and F5).',\n",
       "  'Summarise these negligible features (F4 and F1).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F13, F8, F2, and F11).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F7, and F10).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F3, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F7 and F15).',\n",
       "  'Summarise these moderate features (F8, F16, F1, and F2).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F38, F36, F23, and F28).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8 and F6).',\n",
       "  'Summarise these moderate features (F1, F7, F3, and F4).',\n",
       "  'Summarise these negligible features (F2 and F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F16 and F6).',\n",
       "  'Summarise these moderate features (F39, F35, F32, and F3).',\n",
       "  'Summarise these negligible features (F33, F24, F21, and F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F6 and F13).',\n",
       "  'Summarise these moderate features (F10, F14, F4, and F8).',\n",
       "  'Summarise these negligible features (F5, F15, F12, and F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F38, F59, F47, and F27).',\n",
       "  'Summarise these moderate features (F16, F52, and F75).',\n",
       "  'Summarise these negligible features (F13, F68, and F32).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F7, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F30, F22, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F10, F9, and F13).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F12, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F5 and F1).',\n",
       "  'Summarise these moderate features (F3, F7, F6, and F4).',\n",
       "  'Summarise these negligible features (F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F25, F22, F23, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F19, F22, and F4).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F3, and F1).',\n",
       "  'Summarise these moderate features (F5, F6, and F2).',\n",
       "  'Summarise these negligible features ( ).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F5, and F10).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F10, F5, and F11).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F1, and F5).',\n",
       "  'Summarise these moderate features (F6, F3, and F7).',\n",
       "  'Summarise these negligible features (F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8, F1, and F15).',\n",
       "  'Summarise these moderate features (F10, F11, and F17).',\n",
       "  'Summarise these negligible features (F5, F9, F6, and F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F10, F5, F3, F14, and F12).',\n",
       "  'Summarise these moderate features (F8, F6, and F1).',\n",
       "  'Summarise these negligible features (F4, F13, and F11).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F13, F16, and F19).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F6, F4, and F3).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F2, and F11).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F11, F9, and F1).',\n",
       "  'Summarise these moderate features (F6, F10, and F7).',\n",
       "  'Summarise these negligible features (F4, F8, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F13, F5, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F3, F2, and F10).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1, F7, F9, and F11).',\n",
       "  'Summarise these moderate features (F2, F10, and F3).',\n",
       "  'Summarise these negligible features (F4, F5, and F6).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F10 and F11).',\n",
       "  'Summarise these moderate features (F9, F7, F12, and F3).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F9, and F14).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11 and F1).',\n",
       "  'Summarise these moderate features (F5, F2, F8, and F12).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F13, F3, and F2).',\n",
       "  'Summarise these moderate features (F11, F8, and F9).',\n",
       "  'Summarise these negligible features (F4, F10, F17, and F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F17, F15, F11, and F20).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F18, F16, and F1).',\n",
       "  'Summarise these moderate features (F5, F8, and F2).',\n",
       "  'Summarise these negligible features (F7, F3, F15, and F12).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F13, F4, and F12).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F15, and F3).',\n",
       "  'Summarise these moderate features (F12, F17, and F14).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F6 and F8).',\n",
       "  'Summarise these moderate features (F1, F5, F4, and F2).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F13, F5, F3, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F4, and F6).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F11, F14, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F4, F8, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F6, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F6, F10, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F12, F5, F15, F6, and F1).',\n",
       "  'Summarise these moderate features (F13, F16, and F10).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F6 and F9).',\n",
       "  'Summarise these moderate features (F12, F3, F1, and F13).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F1, F2, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F8, F1, F15, and F14).',\n",
       "  'Summarise these moderate features (F4, F13, and F7).',\n",
       "  'Summarise these negligible features (F3, F6, and F11).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4 and F8).',\n",
       "  'Summarise these moderate features (F10, F11, F12, and F9).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F18, and F29).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F6, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F16 and F43).',\n",
       "  'Summarise these moderate features (F14, F35, F17, and F44).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F16, F2, F10, and F9).',\n",
       "  'Summarise these moderate features (F12, F3, and F11).',\n",
       "  'Summarise these negligible features (F7, F6, and F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4 and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F31 and F1).',\n",
       "  'Summarise these moderate features (F22, F27, F13, and F8).',\n",
       "  'Summarise these negligible features (F18, F7, and F36).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F7, F9, and F1).',\n",
       "  'Summarise these moderate features (F3, F11, and F8).',\n",
       "  'Summarise these negligible features (F12, F5, and F6).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F10, F6, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F5, F7, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F1, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F3, F4, F7, F8, and F6).',\n",
       "  'Summarise these moderate features (F5, F1, and F9).',\n",
       "  'Summarise these negligible features (F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features ( ).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F4, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F8, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F4, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1, F2, and F4).',\n",
       "  'Summarise these moderate features (F8, F5, and F3).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F8, F16, and F15).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F23, F32, and F29).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F3, F8, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F39, F13, F24, F38, and F22).',\n",
       "  'Summarise these moderate features (F26, F36, and F18).',\n",
       "  'Summarise these negligible features (F29, F42, and F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F37, and F28).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F9, F4, and F12).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F23, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F10 and F6).',\n",
       "  'Summarise these moderate features (F9, F5, F13, and F4).',\n",
       "  'Summarise these negligible features (F2, F12, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F5 and F1).',\n",
       "  'Summarise these moderate features (F6, F4, F7, and F9).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F2, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F14, F6, F9, F4, and F11).',\n",
       "  'Summarise these moderate features (F3, F1, and F12).',\n",
       "  'Summarise these negligible features (F7, F13, and F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F6, F11, F8, and F9).',\n",
       "  'Summarise these moderate features (F10, F5, and F3).',\n",
       "  'Summarise these negligible features (F4, F12, and F1).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F3, F9, F4, and F5).',\n",
       "  'Summarise these moderate features (F10, F6, and F8).',\n",
       "  'Summarise these negligible features (F1, F2, and F11).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F72, F42, and F45).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F1, F4, and F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11, F5, F10, F18, and F2).',\n",
       "  'Summarise these moderate features (F12, F7, and F15).',\n",
       "  'Summarise these negligible features (F13, F14, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F10, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F5, F1, and F7).',\n",
       "  'Summarise these moderate features (F2, F8, and F6).',\n",
       "  'Summarise these negligible features (F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F14, F22, F2, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2 and F6).',\n",
       "  'Summarise these moderate features (F3, F7, F10, and F4).',\n",
       "  'Summarise these negligible features (F1, F9, F8, and F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F14, F16, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F8, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F11, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F7 and F5).',\n",
       "  'Summarise these moderate features (F11, F1, F12, and F6).',\n",
       "  'Summarise these negligible features (F3, F4, and F10).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F9, and F12).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F3, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F7, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F10, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F7, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1 and F11).',\n",
       "  'Summarise these moderate features (F3, F4, F6, and F7).',\n",
       "  'Summarise these negligible features (F8, F2, and F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F8, F4, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F4, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7 and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F7, F5, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F11, F4, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F3, F5, and F14).',\n",
       "  'Summarise these moderate features (F20, F1, and F12).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F17, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F1, and F13).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11 and F7).',\n",
       "  'Summarise these moderate features (F1, F9, F12, and F8).',\n",
       "  'Summarise these negligible features (F3, F6, and F10).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F9 and F10).',\n",
       "  'Summarise these moderate features (F1, F7, F2, and F6).',\n",
       "  'Summarise these negligible features (F5, F11, F3, and F12).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F38 and F29).',\n",
       "  'Summarise these moderate features (F23, F3, F37, and F18).',\n",
       "  'Summarise these negligible features (F4, F14, and F39).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F9, F4, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F21, F20, and F8).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1, F4, F5, F7, and F8).',\n",
       "  'Summarise these moderate features (F9, F6, and F3).',\n",
       "  'Summarise these negligible features (F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F3, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F15, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F26, F36, and F34).',\n",
       "  'Summarise these moderate features (F18, F14, and F8).',\n",
       "  'Summarise these negligible features (F19, F16, F20, and F11).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F5, and F3).',\n",
       "  'Summarise these moderate features (F6, F9, and F11).',\n",
       "  'Summarise these negligible features (F8, F12, F1, and F10).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F15, F8, and F17).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F9, and F5).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F4, F3, and F2).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F20, F6, F8, and F12).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F9, F7, and F8).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F5, F7, and F8).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F33, F3, and F29).',\n",
       "  'Summarise these moderate features (F11, F6, and F12).',\n",
       "  'Summarise these negligible features (F38, F35, F20, and F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F3, and F4).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F16, F1, F5, and F9).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F3, F2, and F16).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1, F9, F4, F5, and F15).',\n",
       "  'Summarise these moderate features (F12, F7, and F11).',\n",
       "  'Summarise these negligible features (F13, F14, and F8).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F3 and F4).',\n",
       "  'Summarise these moderate features (F2, F5, F1, and F6).',\n",
       "  'Summarise these negligible features ( ).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F19, F17, F13, and F21).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F8, and F10).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F20, and F36).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F5 and F4).',\n",
       "  'Summarise these moderate features (F3, F6, F1, and F2).',\n",
       "  'Summarise these negligible features ( ).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F1, F8, F7, and F6).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F12, F7, F6, and F8).',\n",
       "  'Summarise these moderate features (F13, F11, and F2).',\n",
       "  'Summarise these negligible features (F10, F3, and F4).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2 and F5).',\n",
       "  'Summarise these moderate features (F7, F4, F8, and F1).',\n",
       "  'Summarise these negligible features (F3, F6, and F9).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F14, and F11).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F12, F36, and F16).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F5, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F3, and F5).',\n",
       "  'Summarise these moderate features (F1, F6, and F4).',\n",
       "  'Summarise these negligible features ( ).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F14, F2, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11 and F4).',\n",
       "  'Summarise these moderate features (F6, F10, F2, and F7).',\n",
       "  'Summarise these negligible features (F9, F3, and F13).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F14 and F25).',\n",
       "  'Summarise these moderate features (F7, F13, F16, and F19).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F16, F11, and F14).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F4, F5, F2, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F22, F20, F37, and F10).',\n",
       "  'Summarise these moderate features (F16, F23, and F24).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F14, F15, F5, and F16).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F29, F4, and F45).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F21, F20, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7 and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F2, F7, F1, and F16).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features ( ).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F3, F4, F7, and F12).',\n",
       "  'Summarise these moderate features (F10, F2, and F11).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F10, F8, and F9).',\n",
       "  'Summarise these moderate features (F2, F3, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F27, F15, F2, and F21).',\n",
       "  'Summarise these moderate features (F7, F9, and F5).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F1, F7, and F9).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F7, F4, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11, F3, and F6).',\n",
       "  'Summarise these moderate features (F1, F7, and F8).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F12, F22, and F20).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F16, and F11).',\n",
       "  'Summarise these moderate features (F12, F10, and F9).',\n",
       "  'Summarise these negligible features (F8, F14, F15, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F31, F42, and F43).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F5, F7, and F6).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F9, and F23).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1 and F7).',\n",
       "  'Summarise these moderate features (F5, F10, F9, and F6).',\n",
       "  'Summarise these negligible features (F12, F2, F3, and F11).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4 and F6).',\n",
       "  'Summarise these moderate features (F7, F11, F10, and F2).',\n",
       "  'Summarise these negligible features (F8, F9, and F1).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F7 and F10).',\n",
       "  'Summarise these moderate features (F9, F1, F4, and F11).',\n",
       "  'Summarise these negligible features (F12, F8, and F6).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F14 and F8).',\n",
       "  'Summarise these moderate features (F1, F12, F4, and F2).',\n",
       "  'Summarise these negligible features (F6, F11, F3, and F9).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1, F2, F3, and F4).',\n",
       "  'Summarise these moderate features (F6, F7, and F5).',\n",
       "  'Summarise these negligible features (F8).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F3, and F19).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F4, F6, and F3).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F11, F5, F6, and F12).',\n",
       "  'Summarise these moderate features (F10, F1, and F8).',\n",
       "  'Summarise these negligible features (F13, F4, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1 and F10).',\n",
       "  'Summarise these moderate features (F5, F2, F6, and F4).',\n",
       "  'Summarise these negligible features (F3, F7, and F8).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F7, and F85).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F7 and F8).',\n",
       "  'Summarise these moderate features (F3, F2, F9, and F4).',\n",
       "  'Summarise these negligible features (F5, F6, and F1).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F22, F8, F1, and F9).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F19, F7, and F3).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F18, and F19).',\n",
       "  'Summarise these moderate features (F11, F14, and F8).',\n",
       "  'Summarise these negligible features (F4, F7, F16, and F13).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F8, F7, and F10).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F4, F3, F9, F8, and F5).',\n",
       "  'Summarise these moderate features (F1, F2, and F7).',\n",
       "  'Summarise these negligible features (F6).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  '',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F2, F5, F8, F7, and F10).',\n",
       "  'Summarise these moderate features (F9, F4, and F11).',\n",
       "  'Summarise these negligible features (F1, F12, and F3).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F1 and F3).',\n",
       "  'Summarise these moderate features (F4, F7, F2, and F6).',\n",
       "  'Summarise these negligible features (F5).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F3, and F10).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F44, F8, F3, and F27).',\n",
       "  'Summarise these moderate features (F10, F37, and F40).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F10, F20, and F1).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F8, and F7).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F3, F7, and F1).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise these top features (F9, F1, and F5).',\n",
       "  'Summarise these moderate features (F8, F7, and F4).',\n",
       "  'Summarise these negligible features (F6, F3, and F2).'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F11, F8, F10, and F7).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F5, F4, and F20).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F7, F18, and F20).',\n",
       "  ''],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F20, F30, and F12).',\n",
       "  'Summarise the negligible features.'],\n",
       " ['Summarise the prediction.',\n",
       "  'Summarise the top features.',\n",
       "  'Summarise these moderate features (F6, F3, F2, and F4).',\n",
       "  'Summarise the negligible features.']]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds['train']['simple_narr_qs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F4 and F11.',\n",
       "  'Summarize the direction of influence of the features (F3, F15, F8 and F12) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: ?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F10 (value equal to  V4), F1, F9 (when it is equal to  V0) and F3 (when it is equal to  V2)) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F9, F5 and F10) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8, F7 and F4?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F26, F25 and F5?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F5, F18 and F1) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F6 (equal to  V4) and F10 (equal to  V3).',\n",
       "  'Summarize the direction of influence of the features (F4 (equal to  V2), F1, F9 (when it is equal to  V0) and F11) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F10 (equal to  V2), F12 (equal to  V1), F2 (with a value equal to  V0) and F21 (value equal to  V3)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F28, F44 and F71) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F3, F10, F2 and F6 (equal to  V1)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F11, F8 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F1, F6, F5 and F8) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F7 and F9) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F3 (value equal to  V3), F4 (when it is equal to  V1), F6 and F8 (when it is equal to  V2).',\n",
       "  'Describe the degree of impact of the following features: F10 (with a value equal to  V1), F1 (with a value equal to  V0), F2 (when it is equal to  V1) and F5 (with a value equal to  V4)?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F7 and F1.',\n",
       "  'Compare and contrast the impact of the following features  (F5, F3 (when it is equal to  V1), F4 and F6 (when it is equal to  V1)) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F2 (with a value equal to  V4)?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F11, F32, F17 and F24) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F18, F5 and F11?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F11, F2, F10 and F15) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4 and F7?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2, F5 and F8?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F5, F8 and F7.',\n",
       "  'Compare and contrast the impact of the following features  (F9, F16 (value equal to  V1) and F18 (value equal to  V1)) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F4 (when it is equal to  V0), F1, F13 and F20?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F31, F15 and F7) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F5 and F1?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F2, F1 and F8) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8, F9 and F5?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F5 and F30.',\n",
       "  'Summarize the direction of influence of the features (F26, F17, F15 and F28) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F8, F7 and F17) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F9, F10 and F5?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F16, F10 and F3) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F18, F31, F19, F36 and F38.',\n",
       "  'Summarize the direction of influence of the features (F35, F20 and F5) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F8, F10, F6 and F1) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F9, F3 and F2.',\n",
       "  'Describe the degree of impact of the following features: F5, F7 and F4?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F11, F15, F23 and F16?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F12 (equal to  V4) and F1 (equal to  V3).',\n",
       "  'Summarize the direction of influence of the features (F11 (equal to  V2), F4, F3 (when it is equal to  V0) and F5) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F4 and F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F14, F34, F23 and F29?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F8 and F6) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F24 (with a value equal to  V1), F23 (equal to  V3), F9 (with a value equal to  V0), F18 (equal to  V1) and F14.',\n",
       "  'Summarize the direction of influence of the features (F10 (value equal to  V0), F11 (value equal to  V2) and F2 (value equal to  V3)) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F2, F1, F7, F3 and F8.',\n",
       "  'Compare and contrast the impact of the following features  (F6, F4 and F9) on the models prediction of C3.',\n",
       "  'Describe the degree of impact of the following features: F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F10, F6 and F1 (with a value equal to  V2)?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F4, F13, F16 and F14) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F10, F2 and F12?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F14, F10 and F9?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F3, F14, F11 and F8) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F8, F4 (value equal to  V0) and F19) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F9, F2, F6 and F8) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F3, F5 and F4.',\n",
       "  'Describe the degree of impact of the following features: F7 and F1?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F17, F19, F11 and F14?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F2, F6 and F5) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F8, F3 and F9.',\n",
       "  'Describe the degree of impact of the following features: F1, F7 and F4?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F13 (equal to  V0), F9 and F8) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F11, F4, F6, F17 and F3.',\n",
       "  'Summarize the direction of influence of the features (F5, F2 and F16) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F7 and F4?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F2, F4 and F5) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F1, F7 and F4) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F16, F2 and F18) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F9, F7 and F23?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F10, F9 and F5?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F5, F9, F13, F2 and F12.',\n",
       "  'Compare and contrast the impact of the following features  (F3, F11 and F4) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F10, F8 and F1?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F1, F4, F2 and F6) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F18, F3 and F12.',\n",
       "  'Summarize the direction of influence of the features (F15, F14 and F4) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F8 (value equal to  V0), F25 (value equal to  V15), F9 (value equal to  V2), F2 and F27 (equal to  V0).',\n",
       "  'Compare and contrast the impact of the following features  (F7 (equal to  V3), F24 (when it is equal to  V2) and F3 (value equal to  V2)) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F31, F5 and F32 (value equal to  V1)?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F36, F8, F26, F35 and F3.',\n",
       "  'Summarize the direction of influence of the features (F12, F24 and F9) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F3, F13 and F15) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F10 and F6) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F17 and F9.',\n",
       "  'Summarize the direction of influence of the features (F19, F18, F43 and F23) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F4 and F8.',\n",
       "  'Summarize the direction of influence of the features (F3, F14, F5 and F7) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F11, F4, F7 and F9) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F6, F8 and F1.',\n",
       "  'Describe the degree of impact of the following features: F3, F10 and F2?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F8, F1, F7 and F5) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F10, F3 and F11.',\n",
       "  'Describe the degree of impact of the following features: F2, F6 and F9?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F7, F11 and F2?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F12, F11 and F19) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4, F2, F6 and F8?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F9, F59 and F63) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F7 and F21.',\n",
       "  'Compare and contrast the impact of the following features  (F33, F8, F27 and F10) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F37, F1, F23 and F14?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8 and F2 (when it is equal to  V1)?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F8, F6 and F17.',\n",
       "  'Summarize the direction of influence of the features (F4, F10 and F5) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F4, F10, F1, F2 and F7.',\n",
       "  'Summarize the direction of influence of the features (F9, F8 and F6) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4, F3 and F7?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F27, F25 (with a value equal to  V7) and F32 (with a value equal to  V0)) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F5 and F20.',\n",
       "  'Compare and contrast the impact of the following features  (F31, F28, F8 and F17) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F16, F6, F2 and F11?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F5, F25, F3 and F8?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F26, F15 and F9?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F9 and F5?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F13, F7, F18 and F21) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F13 (value equal to  V0) and F11 (with a value equal to  V0).',\n",
       "  'Compare and contrast the impact of the following features  (F12, F8, F2 and F7) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F1, F10, F3 and F14?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F21 (when it is equal to  V0), F17 (with a value equal to  V2) and F28?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F1, F8 and F3) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F11, F12 and F3?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F8, F21, F27, F24 and F14.',\n",
       "  'Summarize the direction of influence of the features (F25, F28 and F17) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F3, F1, F2 and F5?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F7, F6, F8 and F1) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F7, F20 and F14) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8, F9 and F1?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F33, F8, F17, F37 and F4.',\n",
       "  'Summarize the direction of influence of the features (F29, F32 and F2) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F20, F48 and F23?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F1, F4 and F2.',\n",
       "  'Summarize the direction of influence of the features (F6, F5 and F7) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F5, F20, F10 and F8?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F12 and F38.',\n",
       "  'Summarize the direction of influence of the features (F75, F61, F92 and F23) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F6 (when it is equal to  V1), F26 (value equal to  V1), F32 (equal to  V0), F42 (when it is equal to  V1) and F25 (when it is equal to  V3)) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F43 (with a value equal to  V1), F29 (with a value equal to  V3) and F7 (equal to  V2).',\n",
       "  'Describe the degree of impact of the following features: F39 (equal to  V2), F5 (when it is equal to  V0) and F13 (when it is equal to  V3)?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F29 and F8.',\n",
       "  'Compare and contrast the impact of the following features  (F10, F23, F26 and F4) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F7, F25 and F3?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F24 (value equal to  V2), F14 (value equal to  V1), F30 (with a value equal to  V2) and F18 (when it is equal to  V2)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F4, F7, F5 (when it is equal to  V2) and F2) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F4, F1 and F14) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F21, F11 and F13?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F12 and F1) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F17, F28, F5 and F7.',\n",
       "  'Describe the degree of impact of the following features: F10, F27, F21 and F18?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F5, F3, F4 and F9?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F3, F16, F14 and F17?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2, F8 and F3?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F17, F26 and F15) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F9, F8 (equal to  V2), F14 (when it is equal to  V12), F7 and F4) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F12 (equal to  V1), F2 (when it is equal to  V39) and F1.',\n",
       "  'Describe the degree of impact of the following features: F10 (when it is equal to  V10), F3 (when it is equal to  V4) and F5?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F8 (with a value equal to  V4), F7 (when it is equal to  V2), F1 and F4 (when it is equal to  V0)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F25 (with a value equal to  V1), F12 and F15 (with a value equal to  V14)?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F24, F21 and F25) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F2, F5, F1, F3 and F4.',\n",
       "  'Summarize the direction of influence of the features (F6 and F7) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F11 (value equal to  V3), F9 (with a value equal to  V3) and F4 (equal to  V2)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F11 (equal to  V8), F4 (with a value equal to  V0), F2 (equal to  V3) and F1.',\n",
       "  'Summarize the direction of influence of the features (F9, F7 and F6) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F5, F8 and F2) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F2, F7, F4 and F8) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F3, F5 and F6.',\n",
       "  'Describe the degree of impact of the following features: F1, F9 and F10?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F9?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F12, F5, F2 and F10) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F12, F4 and F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F3, F15, F17 and F11?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F7, F2 (value equal to  V0) and F8) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F3 and F2.',\n",
       "  'Compare and contrast the impact of the following features  (F6, F1, F5 (with a value equal to  V6) and F7 (with a value equal to  V3)) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F4 (value equal to  V0)?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F15, F5 and F4) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F5 (value equal to  V4), F8, F2 (when it is equal to  V0) and F9 (when it is equal to  V2)) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F2, F10, F1 and F4 (equal to  V1)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F18 (value equal to  V2), F12 (value equal to  V1), F30 (with a value equal to  V2) and F10 (when it is equal to  V2)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F9 and F1.',\n",
       "  'Compare and contrast the impact of the following features  (F22, F6, F12 (with a value equal to  V1) and F11) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F17, F29 and F35?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F8, F7, F9 and F1) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8, F4 and F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F3, F1 and F5?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F1 and F4) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F9, F6, F5 and F2.',\n",
       "  'Describe the degree of impact of the following features: F8, F7 and F3?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F1 (when it is equal to  V0) and F6 (value equal to  V2).',\n",
       "  'Compare and contrast the impact of the following features  (F12, F4 (equal to  V5), F5 and F11) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F10, F9, F3 (equal to  V0) and F8?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F7 (with a value equal to  V3)?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F7 and F9?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F1, F2 (equal to  V1), F3, F5 (when it is equal to  V0) and F7 (when it is equal to  V1)) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F6, F8 (equal to  V1) and F4 (value equal to  V0).',\n",
       "  'Describe the degree of impact of the following features: F9 (value equal to  V0), F10 (equal to  V1) and F11?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4 and F6?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F10 (value equal to  V0) and F8 (with a value equal to  V0).',\n",
       "  'Compare and contrast the impact of the following features  (F9, F13, F1 and F2) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F14, F6, F15 and F12?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F4, F10 (with a value equal to  V1), F5 (value equal to  V1) and F9 (when it is equal to  V0)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F27, F5 and F21?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F8 and F3?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F11, F6, F4 and F5?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F8, F1 and F3) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F1 and F5) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F7, F6 and F8) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F15, F13 and F42.',\n",
       "  'Compare and contrast the impact of the following features  (F21, F20 and F17) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F10, F25, F11 and F27?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F6, F5, F12 and F4) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F4 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F5, F8 and F9?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F4 (equal to  V4) and F10 (equal to  V3).',\n",
       "  'Summarize the direction of influence of the features (F5 (equal to  V2), F1, F8 (when it is equal to  V0) and F7) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F4, F9 and F7) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F9, F8 and F2) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F6, F2 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F9, F19 and F1.',\n",
       "  'Compare and contrast the impact of the following features  (F8, F15 and F13) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F18, F4, F6 and F12?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F1 (equal to  V0), F4 and F2) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F9 and F3.',\n",
       "  'Compare and contrast the impact of the following features  (F1, F7, F10 and F5) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F2, F6, F4 and F8?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F15, F5 and F6?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F19, F1 and F18?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2, F1 and F8?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F3 and F4?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F4 and F8.',\n",
       "  'Compare and contrast the impact of the following features  (F1, F5, F3 and F2) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F7 and F6?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F3, F6 (value equal to  V1), F8 and F9.',\n",
       "  'Compare and contrast the impact of the following features  (F7, F2 and F5) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F4 and F1?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F13, F8, F2 and F11?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F5, F7 and F10?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F5, F3 and F4 (equal to  V1)) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F7 and F15.',\n",
       "  'Summarize the direction of influence of the features (F8, F16, F1 and F2) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F38, F36, F23 and F28) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F8 and F6.',\n",
       "  'Compare and contrast the impact of the following features  (F1, F7, F3 and F4) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F2 and F5?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F16 and F6.',\n",
       "  'Compare and contrast the impact of the following features  (F39, F35, F32 and F3) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F33, F24, F21 and F4?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F6 (value equal to  V0) and F13 (with a value equal to  V0).',\n",
       "  'Compare and contrast the impact of the following features  (F10, F14, F4 and F8) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F5, F15, F12 and F2?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F38, F59, F47 and F27.',\n",
       "  'Compare and contrast the impact of the following features  (F16, F52 and F75) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F13, F68 and F32?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F3, F7 and F5?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F30, F22 (with a value equal to  V7) and F3 (with a value equal to  V0)) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F10, F9 and F13) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F9, F12 and F4) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F5 and F1.',\n",
       "  'Compare and contrast the impact of the following features  (F3, F7 (when it is equal to  V1), F6 and F4 (when it is equal to  V1)) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F2 (with a value equal to  V4)?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F25, F22, F23 and F7?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F19, F22 and F4) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F4, F3 and F1) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F5, F6 and F2.',\n",
       "  'Describe the degree of impact of the following features: ?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F8 (equal to  V0), F5 and F10) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F6 (value equal to  V4), F10, F5 (when it is equal to  V0) and F11 (when it is equal to  V2)) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F4, F1 and F5) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F6 (with a value equal to  V4), F3 (when it is equal to  V4) and F7.',\n",
       "  'Describe the degree of impact of the following features: F2 (when it is equal to  V0)?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F8, F1 and F15) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F10, F11 and F17.',\n",
       "  'Describe the degree of impact of the following features: F5, F9, F6 and F4?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F10, F5 (equal to  V2), F3 (when it is equal to  V12), F14 and F12) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F8 (equal to  V1), F6 (when it is equal to  V39) and F1.',\n",
       "  'Describe the degree of impact of the following features: F4 (when it is equal to  V10), F13 (when it is equal to  V4) and F11?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F13, F16 and F19) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F8, F6 (with a value equal to  V2), F4 and F3) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F7, F2 and F11?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F2, F11, F9 and F1) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F6, F10 and F7.',\n",
       "  'Describe the degree of impact of the following features: F4, F8 and F3?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F13, F5 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F9, F3, F2 and F10) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F1, F7, F9 and F11) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F2, F10 and F3.',\n",
       "  'Describe the degree of impact of the following features: F4, F5 and F6?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F10 and F11.',\n",
       "  'Summarize the direction of influence of the features (F9, F7, F12 and F3) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F5, F9 and F14?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F11 and F1.',\n",
       "  'Summarize the direction of influence of the features (F5, F2, F8 and F12) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F13, F3 and F2) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F11, F8 and F9.',\n",
       "  'Describe the degree of impact of the following features: F4, F10, F17 and F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F17, F15, F11 and F20) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F18, F16 and F1.',\n",
       "  'Compare and contrast the impact of the following features  (F5, F8 (value equal to  V1) and F2 (value equal to  V1)) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F7 (when it is equal to  V0), F3, F15 and F12?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F13, F4 and F12) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F4, F15 and F3.',\n",
       "  'Summarize the direction of influence of the features (F12, F17 and F14) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F6 and F8.',\n",
       "  'Summarize the direction of influence of the features (F1, F5, F4 and F2) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F13, F5, F3 and F1) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F2 (value equal to  V3), F4 (with a value equal to  V3) and F6 (equal to  V2)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F9, F11, F14 and F5?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F10, F4, F8 and F5) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F9, F6 and F3 (equal to  V6)?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F8, F6 (equal to  V0), F10 (value equal to  V31) and F3 (when it is equal to  V0)) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F12, F5, F15, F6 and F1.',\n",
       "  'Summarize the direction of influence of the features (F13, F16 and F10) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F7?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F6 and F9.',\n",
       "  'Summarize the direction of influence of the features (F12, F3, F1 and F13) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F7, F1, F2 and F8) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F8 (with a value equal to  V0), F1 (value equal to  V0), F15 and F14) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F4, F13 and F7.',\n",
       "  'Describe the degree of impact of the following features: F3, F6 and F11?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F4 (equal to  V2) and F8 (when it is equal to  V10).',\n",
       "  'Summarize the direction of influence of the features (F10 (with a value equal to  V0), F11 (when it is equal to  V0), F12 and F9 (value equal to  V0)) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F18 and F29 (with a value equal to  V2)?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F5, F6 and F7) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F16 and F43.',\n",
       "  'Summarize the direction of influence of the features (F14, F35, F17 and F44) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F16, F2, F10 and F9.',\n",
       "  'Compare and contrast the impact of the following features  (F12, F3 and F11) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F7, F6 and F4?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4 and F1?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F31 and F1.',\n",
       "  'Compare and contrast the impact of the following features  (F22, F27, F13 (with a value equal to  V1) and F8) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F18, F7 and F36?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F4, F7, F9 (with a value equal to  V0) and F1 (equal to  V1).',\n",
       "  'Compare and contrast the impact of the following features  (F3 (with a value equal to  V0), F11 (equal to  V2) and F8) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F12, F5 (equal to  V0) and F6 (with a value equal to  V0)?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8, F10, F6 and F2?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F8, F5 (with a value equal to  V2), F7 and F1) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F7, F1 and F2) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F3, F4, F7, F8 and F6.',\n",
       "  'Compare and contrast the impact of the following features  (F5, F1 and F9) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F2?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: ?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F6, F4 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F8 and F1) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F11, F4 and F2) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F1, F2 and F4.',\n",
       "  'Summarize the direction of influence of the features (F8, F5 and F3) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F9, F8, F16 and F15) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F11, F23, F32 and F29?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F3, F8 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F39 (when it is equal to  V1), F13 (value equal to  V1), F24 (equal to  V0), F38 (when it is equal to  V1) and F22 (when it is equal to  V3)) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F26 (with a value equal to  V1), F36 (with a value equal to  V3) and F18 (equal to  V2).',\n",
       "  'Describe the degree of impact of the following features: F29 (equal to  V2), F42 (when it is equal to  V0) and F4 (when it is equal to  V3)?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4, F37 and F28?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F9, F4 and F12?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F23 and F3?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F10 and F6) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F9, F5, F13 and F4.',\n",
       "  'Describe the degree of impact of the following features: F2, F12 and F3?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F5 (when it is equal to  V2) and F1 (value equal to  V1).',\n",
       "  'Summarize the direction of influence of the features (F6 (when it is equal to  V1), F4 (equal to  V1), F7 (value equal to  V2) and F9 (equal to  V2)) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F11, F2 and F5) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F14, F6, F9, F4 and F11.',\n",
       "  'Compare and contrast the impact of the following features  (F3, F1 and F12) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F7, F13 and F5?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F6, F11, F8 (with a value equal to  V0) and F9 (equal to  V1).',\n",
       "  'Compare and contrast the impact of the following features  (F10 (with a value equal to  V0), F5 (equal to  V2) and F3) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F4, F12 (equal to  V0) and F1 (with a value equal to  V0)?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F3, F9, F4 and F5) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F10, F6 and F8.',\n",
       "  'Describe the degree of impact of the following features: F1, F2 and F11?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F72, F42 and F45) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F9, F1, F4 and F2) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F11, F5, F10, F18 and F2) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F12, F7 and F15.',\n",
       "  'Describe the degree of impact of the following features: F13, F14 and F3?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F10 and F7?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F4, F5, F1 and F7.',\n",
       "  'Compare and contrast the impact of the following features  (F2, F8 and F6) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F3?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F14, F22, F2 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F2 and F6.',\n",
       "  'Compare and contrast the impact of the following features  (F3, F7, F10 and F4) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F1, F9, F8 and F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F14, F16 and F1 (equal to  V0)?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F1, F8 and F5) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F6, F11 and F7) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F7 (when it is equal to  V0) and F5) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F11, F1, F12 and F6.',\n",
       "  'Describe the degree of impact of the following features: F3 (value equal to  V2), F4 and F10?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F3, F9 and F12) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F10, F3 and F1) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2, F7 and F9?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F8, F10 and F1 (equal to  V1)) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2, F7 and F9?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F1 and F11) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F3, F4, F6 and F7.',\n",
       "  'Describe the degree of impact of the following features: F8, F2 and F5?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F2 (with a value equal to  V4), F8 (when it is equal to  V2), F4 and F1 (when it is equal to  V0)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2, F4 and F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F7 and F5?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2 (with a value equal to  V3)?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F1, F7, F5 and F3) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F5, F11, F4 and F1) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F3 (with a value equal to  V1), F5 (with a value equal to  V2) and F14.',\n",
       "  'Summarize the direction of influence of the features (F20 (value equal to  V2), F1 and F12 (equal to  V4)) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F11, F17 and F5?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F1 and F13) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F11 (when it is equal to  V0) and F7) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F1, F9, F12 and F8.',\n",
       "  'Describe the degree of impact of the following features: F3 (value equal to  V2), F6 and F10?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F9 and F10.',\n",
       "  'Compare and contrast the impact of the following features  (F1, F7, F2 and F6) on the models prediction of C3.',\n",
       "  'Describe the degree of impact of the following features: F5, F11, F3 and F12?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F38 and F29.',\n",
       "  'Compare and contrast the impact of the following features  (F23, F3, F37 (with a value equal to  V1) and F18) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F4, F14 and F39?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F9, F4 and F5) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F21, F20 and F8) with moderate impact on the prediction made for this test case.'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F1, F4, F5, F7 and F8.',\n",
       "  'Compare and contrast the impact of the following features  (F9, F6 and F3) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F2?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F3 and F9) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F9 (value equal to  V3), F15 (with a value equal to  V3) and F1 (equal to  V2)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F26, F36 and F34.',\n",
       "  'Compare and contrast the impact of the following features  (F18, F14 and F8) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F19, F16, F20 and F11?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F4, F5 and F3) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F6, F9 and F11.',\n",
       "  'Describe the degree of impact of the following features: F8, F12, F1 and F10?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F15, F8 and F17) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4, F9 and F5?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F7 (value equal to  V2), F4 (value equal to  V2), F3 (when it is equal to  V2) and F2 (value equal to  V2)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F20, F6, F8 and F12) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F9, F7 and F8) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F1 (value equal to  V2), F5 (value equal to  V2), F7 (when it is equal to  V2) and F8 (value equal to  V2)) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Summarize the direction of influence of the variables (F33, F3 and F29) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the variables: F11, F6 and F12.',\n",
       "  'Describe the degree of impact of the following variables: F38, F35, F20 and F2?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F6, F3 and F4 (equal to  V1)) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F16, F1, F5 and F9) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F1, F3, F2 and F16?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F1, F9, F4, F5 and F15.',\n",
       "  'Compare and contrast the impact of the following features  (F12, F7 and F11) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F13, F14 and F8?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F3 and F4.',\n",
       "  'Compare and contrast the impact of the following features  (F2, F5, F1 and F6) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: ?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F19, F17, F13 and F21) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F11, F8 and F10) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F11, F20 and F36?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F5 and F4) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F3, F6, F1 and F2.',\n",
       "  'Describe the degree of impact of the following features: ?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F1, F8, F7 and F6) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F12, F7, F6 and F8) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F13, F11 and F2.',\n",
       "  'Describe the degree of impact of the following features: F10, F3 and F4?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Summarize the direction of influence of the variables (F2 and F5) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the variables: F7, F4, F8 and F1.',\n",
       "  'Describe the degree of impact of the following variables: F3, F6 and F9?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F3, F14 and F11) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F4, F12, F36 and F16?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F2, F5 and F3) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F3?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F2, F3 and F5.',\n",
       "  'Compare and contrast the impact of the following features  (F1, F6 and F4) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: ?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F14, F2 and F1?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F11 and F4) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F6, F10, F2 and F7.',\n",
       "  'Describe the degree of impact of the following features: F9, F3 and F13?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F14 (with a value equal to  V0) and F25 (equal to  V2).',\n",
       "  'Summarize the direction of influence of the features (F7, F13 (equal to  V0), F16 and F19) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F16, F11 and F14) with moderate impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F4, F5, F2 and F3) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F22, F20, F37 and F10.',\n",
       "  'Summarize the direction of influence of the features (F16, F23 and F24) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F14, F15, F5 and F16?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F29 (value equal to  V0), F4 (when it is equal to  V1) and F45 (when it is equal to  V0)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F21, F20 and F1) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F7 and F9 (when it is equal to  V1)?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F2, F7, F1 and F16?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C2 by the model for the given test example?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: ?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F3, F4, F7 and F12.',\n",
       "  'Summarize the direction of influence of the features (F10, F2 and F11) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F10, F8 and F9.',\n",
       "  'Summarize the direction of influence of the features (F2, F3 (equal to  V0) and F7) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F27 (with a value equal to  V1), F15 (equal to  V3), F2 (value equal to  V0) and F21 (with a value equal to  V1).',\n",
       "  'Summarize the direction of influence of the features (F7 (with a value equal to  V0), F9 (value equal to  V0) and F5 (value equal to  V2)) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F10, F1, F7 (when it is equal to  V2) and F9) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8, F7, F4 and F3?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F11, F3 and F6.',\n",
       "  'Summarize the direction of influence of the features (F1, F7 and F8) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F12, F22 and F20) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F2, F16 and F11.',\n",
       "  'Compare and contrast the impact of the following features  (F12, F10 (value equal to  V1) and F9 (value equal to  V1)) on the models prediction of C3.',\n",
       "  'Describe the degree of impact of the following features: F8 (when it is equal to  V0), F14, F15 and F3?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F31 (value equal to  V1), F42 (when it is equal to  V0) and F43 (value equal to  V3)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F3, F5, F7 (when it is equal to  V2) and F6) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F3 (with a value equal to  V1), F9 and F23 (with a value equal to  V14)?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F1 and F7.',\n",
       "  'Compare and contrast the impact of the following features  (F5, F10, F9 and F6) on the models prediction of C3.',\n",
       "  'Describe the degree of impact of the following features: F12, F2, F3 and F11?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F4 and F6) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F7, F11, F10 and F2.',\n",
       "  'Describe the degree of impact of the following features: F8, F9 and F1?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F7 and F10) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F9, F1, F4 and F11.',\n",
       "  'Describe the degree of impact of the following features: F12, F8 and F6?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F14 and F8) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F1, F12, F4 and F2.',\n",
       "  'Describe the degree of impact of the following features: F6, F11, F3 and F9?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F1, F2, F3 and F4.',\n",
       "  'Compare and contrast the impact of the following features  (F6, F7 and F5) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F8?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F10, F3 and F19) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F10, F4, F6 and F3) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F11, F5, F6 and F12) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F10, F1 and F8.',\n",
       "  'Describe the degree of impact of the following features: F13, F4 and F3?'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Summarize the direction of influence of the variables (F1 and F10) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the variables: F5, F2, F6 and F4.',\n",
       "  'Describe the degree of impact of the following variables: F3, F7 and F8?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F3, F7 and F85?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F7 and F8) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F3, F2, F9 and F4.',\n",
       "  'Describe the degree of impact of the following features: F5, F6 and F1?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F22, F8, F1 and F9?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F19, F7 and F3?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F2, F18 and F19.',\n",
       "  'Compare and contrast the impact of the following features  (F11, F14 and F8) on the models prediction of C1.',\n",
       "  'Describe the degree of impact of the following features: F4, F7, F16 and F13?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F8, F7 and F10?'],\n",
       " ['Provide a statement summarizing the prediction made for the test case.',\n",
       "  'For the current test instance, describe the direction of influence of the following features: F4, F3, F9, F8 and F5.',\n",
       "  'Compare and contrast the impact of the following features  (F1, F2 and F7) on the models prediction of C2.',\n",
       "  'Describe the degree of impact of the following features: F6?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"For this test case, summarize the top features influencing the model's decision.\",\n",
       "  'For these top features, what are the respective directions of influence on the prediction?',\n",
       "  'Provide a statement on the set of features has limited impact on the prediction of C1 by the model for the given test example?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F2 (value equal to  V1), F5 (with a value equal to  V0), F8, F7 and F10) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F9 (equal to  V0), F4 (value equal to  V0) and F11 (with a value equal to  V1).',\n",
       "  'Describe the degree of impact of the following features: F1, F12 and F3 (value equal to  V2)?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F1 and F3) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F4, F7, F2 (equal to  V1) and F6 (equal to  V1).',\n",
       "  'Describe the degree of impact of the following features: F5 (value equal to  V4)?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F11, F3 and F10) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction made for the test under consideration along with the likelihood of the different possible class labels.',\n",
       "  'Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Compare the direction of impact of the features: F44 (with a value equal to  V1), F8 (equal to  V3), F3 (value equal to  V0) and F27 (with a value equal to  V1).',\n",
       "  'Summarize the direction of influence of the features (F10 (with a value equal to  V0), F37 (value equal to  V0) and F40 (value equal to  V2)) with moderate impact on the prediction made for this test case.',\n",
       "  'Provide a statement on the features with the least impact on the prediction made for this test case.'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F10, F20 and F1) with moderate impact on the prediction made for this test case.'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F6, F8 and F7?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F3, F7 (value equal to  V0) and F1) on the models prediction of C2.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Provide a statement summarizing the ranking of the features as shown in the feature impact plot.',\n",
       "  'Summarize the direction of influence of the features (F9, F1 and F5) on the prediction made for this test case.',\n",
       "  'Compare the direction of impact of the features: F8, F7 and F4.',\n",
       "  'Describe the degree of impact of the following features: F6, F3 and F2?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  \"Compare and contrast the impact of the following attributes  (F11 (when it is equal to  V13), F8 (equal to  V1), F10 (value equal to  V2) and F7 (equal to  V5)) on the model's prediction of C2.\",\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['In a single sentence, state the prediction output of the model for the selected test case along with the confidence level of the prediction (if applicable).',\n",
       "  \"In no less three sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Describe the degree of impact of the following features: F5 (when it is equal to  V0), F4 (with a value equal to  V2) and F20?'],\n",
       " [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F7, F18 and F20) with moderate impact on the prediction made for this test case.'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F20, F30 and F12) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?'],\n",
       " ['Summarize the prediction for the given test example?',\n",
       "  \"In two sentences, provide a brief overview of the features with a higher impact on the model's output prediction.\",\n",
       "  'Compare and contrast the impact of the following attributes  (F6 (equal to  V2), F3 (equal to  V1), F2 (with a value equal to  V0) and F4 (value equal to  V3)) on the models prediction of C1.',\n",
       "  'Summarize the set of features has little to no impact on the prediction?']]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds['train']['narrative_questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The prediction probability associated with class C2 and class C1, respectively, is 35.34% and 64.66%. Based on these probabilities, the model labels the given case as C1 since it is the most probable class. According to the attribution analysis, the most relevant features considered by the model here are F5, F1, and F8, while the least relevant features are F12, F2, and F4. Regarding the direction of influence of the features, F5, F1, F8, and F7 are the top positively supporting features, driving the decision higher in favour of C1. Further increasing the probability that C1 is the true label are the values of other positive features such as F16, F3, F15, and F14. To explain why the likelihood of C2 is 35.34%, we have to look at the negative contributions from F11, F6, F13, F2, F12, and F4. The abovementioned negative features contradict the model's decision with respect to the classification outcome.\",\n",
       " \"The classifier is very uncertain about the correct label for the case given.  Regarding the classifier's decision, there is close to an even split on the probability of either of the possible labels is the correct label but the classifier chooses the label as C2. The prediction verdict above is attributed to the contributions of mainly the following features: F4, F11, F3, and F15, however, the lowest ranked features are F7, F19, and F1. Analysing the direction of influence of the features shows that there are ten positive and ten negative features.  Positive features such as F3, F15, F8, and F20 increase the response of the classifier in favour of the assigned label. Conversely, negative features such as F4, F11, F12, and F2 decrease the likelihood of C2 being the correct label given that their values support the alternative label, C1. The uncertainty concerning the label assignment can be due to the fact that the top negative features F4 and F11 have very high attributions shifting the classifier's verdict away from the C2 class.\",\n",
       " 'The classification algorithm believes that C2 is the output label that was generated with 100% certainty and that C1 is unlikely to be the correct label in this case. According to the attribution investigations, the following input features are ranked from most relevant to least relevant: F2, F4, F6, F1, F3, and F5. As shown by the attribution plot, F2 is the only one shown to positively contribute to the above classification decision, while the others contribute negatively. The contributions of negative features such as F4, F6, and F1 result in the decision being driven in a different direction. From the prediction confidence level, we can conclude that the very strong influence of F2 overshadows the contributions of the negative features hence the very high confidence level.',\n",
       " \"Of the three possible labels, there is 100.0% confidence that C3 is the most probable label for the given case. The features that heavily influence the classification verdict presented here are F5, F10, and F6, and they have a very strong positive contribution, increasing the odds of the C3 prediction. Other features with a positive influence on the model are F3, F1, F12, F7, and F4. On the contrary, F9, F2, and F8 make the model's decision fluctuate negatively towards selecting an alternative label. All of the negative features mentioned above have a low to moderate impact on the classification verdict presented here compared to F6, F10, and F5. Finally, F11 with its very low positive impact is the least ranked feature marginally pushing the decision towards the assigned label.\",\n",
       " \"Per the model, class C2 has a prediction probability of 10.50 percent, whereas class C1 has a predicted probability of 89.50 percent. As a result of the model, it can be determined that C1 is the most likely label for the given scenario. All of the input features are shown to contribute to the above conclusion, with F1, F7, and F3 having the most influence on the classification decision. The least influential features with regard to this classification are F5, F2, F10, and F4, whereas, the impact of F8, F6, and F9 can be classified as modest. The large positive contributions of F7 and F1 are responsible for the model's high confidence which further supported by the positive contributions of F8, F5, and F2. In conclusion, the negative features F3, F6, F10, F9, and F4 favour labelling the case as C2 hence the associated predicted probability.\",\n",
       " \"The classifier says that C2 is the most likely label for the provided data with relatively high confidence. It is crucial to remember, however, that there is a 21.80% possibility that it is C1. F16 and F19 are the major driving variables for the aforementioned classification or prediction choice. The remaining variables  F1, F12, F17, and F6 have a modest to minor impact on the selection made above. Among the input variables, F1, F6, F4, F9, and F10 are the subset that have a negative influence or contribution whereas all of the remaining variables have a positive impact. In essence, the substantial positive contributions of F16 and F19, together with the contributions of additional positive variables such as F12, F17, F8, and F7, account for the classifier's confidence in this classification.\",\n",
       " 'C1 has an 83.0% chance of being the correct label for the case under consideration, making C2 the least likely class with a predicted likelihood of 17.0%. F24, F14, and F16 features have a significant impact on class selection here while on the other hand, the remaining features are shown to have marginal to no contribution to the classification verdict here. In actual fact, the values for F3, F9, F7, F4, F12, and F23 may have been ignored by the classifier because their respective influences are almost zero. Of the important features, only F26, F11, F22, F20, F6, and F19 are negative and this is mainly because their contribution to selection tends to reduce the chance that C1 is the correct label, preferring that the case is classified as C2. The remaining features such as F24, F14, F16, F21, F1, and F13 strongly contribute positively, increasing the chances of C1 which explains the level of certainty associated with C1.',\n",
       " 'C2 is the label picked by the algorithm with about 82.06% certainty, since the prediction likelihood of C1 is only 17.94%. F20, F5, F10, and F3 all contribute significantly to the above classification output and among them, the features that support the most positive contribution to the C2 prediction are F3, F20, and F5, while F10 drives the final prediction against assigning C2 in support of C1. F1 also contributes positively to the classification here, but F18 contributes negatively and like F10 favours C1. Finally, according to the analysis, F11, F13, F7, and F8 all have little effect on the final prediction made by the algorithm for this case.',\n",
       " 'The model is confident in its prediction, as it predicted class C1 with a likelihood of 90.48% and hence, for the given case, there is a smaller chance of it being any other class label. F6 and F10 are deemed the most important features whereas on the other hand all the other features have moderate to minimal amounts of influence. Both F6 and F10 have the same direction of impact, increasing the odds of the predicted label, C1. While F4 and F1 are both encouraging the model to make a prediction of C1, the others F9, F12, and F8 is pushing the model towards a different label. Many features have moderately low impact on the final prediction, but the features F3, F8, and F2 are those with the smallest influence.',\n",
       " \"Based on the probability distribution across the classes, the classifier is shown to have a moderately high confidence level in the C2 label assignment, with its likelihood equal to 65.0%, whereas that of C1 is only 35.0%. The prediction decision above is predominantly due to the influence of the variables F22, F12, F23, and F9. On the lower end are the least relevant variables, F11, F18, F16, F19, F2, and F4, with little to no influence on the classifier when assigning a label to the given instance. On the one hand, the top positive variables are F22, F12, and F23, increasing the probability that C2 is the correct label. Also, the top negative variables are F9, F26, F21, and F3, decreasing the classifier's response and consequently shifting the prediction verdict in the opposite direction towards C1. Other variables with a positive direction of influence are F5, F1, F8, F10, F17, F20, F24, F6, and F7.\",\n",
       " \"The model's output labelling judgement for the case under consideration is as follows: C2 cannot be the label for the given case; C1 is the most likely class label with a 100.0% confidence level. The key driving factors resulting in the aforementioned classification are the values of the input features: F38, F51, F13, F46, F28, F71, and F44. F70, F61, F85, F20, F59, F93, F14, F66, F24, F89, F30, F65, and F54 are the features that have a modest effect on the decision. Aside from the aforementioned input features, all others, such as F47, F10, F7, and F43, are revealed to be irrelevant to the conclusion reached here. Not all of the influential features support labelling the current instance as C1, and they are referred to as negative features. F44, F61, F30, F65, and F54 are the negative attributes that diminish the likelihood that C1 is the correct label in this case. F38, F51, F13, and F46 are important positive features that strongly increase the likelihood that C1 is the correct label.\",\n",
       " \"For the case under consideration, the model assigned C1 with very high confidence, since the likelihood of C2 being the right label is only 0.52% which is very small. F11, F7, F3, and F10 have a large positive impact on the model's output prediction. F3 and F10 have a moderately positive impact on the prediction of C1, while F2 has a similar impact but in the opposite direction. F5, F12, and F4 have a very low impact on classification. F6, F8, F1, and F9 have a larger but still insignificant effect. Examining the attributions indicates that there are only two features, F2 and F12, with values that contradict the prediction made here but, their impact on the model is smaller when compared to positive features such as F7, F3, and F11, which explains why the confidence level associated with this classification is high.\",\n",
       " 'Since the likelihood of C3 being the true label is shown by the prediction algorithm outputs to be equal to 93.02 percent, there is only a small chance that the true label for the given data instance is any of the other class labels, C2 and C1. The features F12, F1, F11, and F10 are the most important ones driving the label assignment verdict above, and on the other hand, the least relevant features are shown to be F9, F6, and F3. Considering the direction of influence of each input feature, as shown by the attribution analysis, it can be concluded that the positive features steering the prediction higher towards C3 are F12, F1, F10, F11, F2, F4, and F6. The marginal doubt in the predicted output decision is attributed to the negative contributions of F8, F7, F3, F9, and F5. Considering the attributions of the features and predicted probabilities across the classes, it can be concluded that the joint positive contribution outranks the negative contributions; hence, the algorithm is confident that C3 is likely the true label.',\n",
       " 'Between the three possible classes, there is an 88.0% probability that the correct label for this case is C1. This means that there is a 12.0% chance that the label could be one of the other possible labels, C2 or C3. Increasing the odds of the predicted label are the variables F7, F5, F2, and F10. The next set of variables, F6, F1, and F9, have values that moderately decrease the likelihood of C1 being the correct label. F11, F4, and F3 are the other negatively contributing features, and given that they are lowly ranked, they have a marginal impact when determining the correct label for this case. The other positive features further increasing the probability that C1 is the right label are F12 and F8. Overall, we can conclude that the decision to label the case as C1 is largely due to the strong positive influence of F5, F7, F10, and F2.',\n",
       " 'Based on the input variables, the model is moderately confident that the C2 is the appropriate label for the data under consideration. As a matter of fact, the prediction likelihood associated with class C1 is about 30.42%. The preceeding classification verdict can be largely blamed on the contributions of variables F4, F11, F1, and F6, whereas those with marginally lower contributions are F2, F3, and F7. The variables with moderate contributions are F5, F8, F9, and F10. Considering their respective contributions, F4, F1, F6, and F10 are the variables with positive influence that increase the chances of C2 being the correct label for the given data. The little doubt in the label choice here could be attributed to the negative variables, mainly F11, F5, F9, and F8, which decrease the chances of the model labelling the data given as C2 since these negative variables favour selecting the alternative label, C1 over C2. Given that majority of top variables contribute positively, it is not unexpected that C2 is the picked label with reasonably high confidence.',\n",
       " 'The classifier is 69.02% certain that the given case is under the class label C1, implying that the likelihood of C2 is only 30.98%. Analysis performed to understand the contribution of each input feature revealed that: F7, F9, and F3 are the most influential features when assigning a label to the given case. Features F4, F6, F8, and F10 have moderate contributions, whereas the F1, F2 and F5 have lower relevance to the final classification decision. F7 and F3 push the class assignment towards C1, whereas F9 does the opposite, decreasing the likelihood of C1. Similar to F9, F4, and F6 negatively impact the C1 classification, whereas F10, F1, and F8 positively push the decision towards the C1 class. Features F2, and F5 all have little impact on the final decision, with F5 having the least impact.',\n",
       " 'The classifier trained on this prediction problem assigns a label to a given case based on the information supplied. The class assigned by the classifier to the case under consideration is C1. The probability that C2 is the correct label is around 25.28%; therefore, it is less likely to be the true label. The above classification decision is mainly based on the influence of the features F7, F1, F5, F3, F4, F6, and F2. Of the above stated features, F3 and F1 are the ones shown to have a negative impact, decreasing the odds of C1 being the accurate label for the given case and encouraging the classifier to select C2 instead. Finally, it can be concluded that there is a moderately high level of confidence in the assigned label, which can be attributed to the strong positive contribution of F7 combined with other positive features such as F5 and F4.',\n",
       " 'The case given is labelled as C1 by the classifier with a confidence level equal to 82.07%. Therefore, the probability of C2 being the correct label is only 17.93%. The classification above is mainly due to the contributions of features such as F30, F12, F11, and F32. F17, F24, and F28 are the next three with moderate influence. However, not all the features are considered by the classifier when determining the correct label for the given case. F46, F2, F40, and F8 are notable irrelevant features. With regards to the direction of influence of the relevant features, F30, F12, F11, and F32 are the top features with strong positive contributions favouring the assignment of label C1. The top negative features that shift the classification in a different direction are F17, F24, F33, and F29. Considering the fact that a number of the relevant features have positive attributions, it is not surprising that the classifier is quite certain that the appropriate label is C1 instead of C2.',\n",
       " 'According to the algorithm, there is little to no chance that the correct label for the given data instance is any of the following classes: C4, C1, and C3. It is very confident that the proper label is C2.  This label assignment is largely due to the parts played by the features F19, F12, and F17. On the lower end are the input features F1, F9, F16, and F10, which are shown to be less relevant when it comes to this labelling assignment task.  Finally, among the top features identified during the attribution investogation, only F15 and F4 are features with a negative influence, decreasing the odds of C2 being the appropriate label here.',\n",
       " \"The model predicts that the label for this case is C2 with a high degree of certainty of about 99.19% and the probability of the other label is only 0.81%. From the analysis, the variables with the strongest attributions to this classification decision are F8, F11, and F14. The attributions of these variables increased the response of the model in favour of labelling the case as C2. Other variables that positively supported the label decision include F15, F6, and F16. Not all the variables support the model's prediction of C2 and this is because the values of F2, F10, F3, F7, and F1 are driving the prediction towards C1. The joint attribution from these variables is weaker than that from F8, F11, and F14, so the model is biased toward predicting C2. Finally, F13, F9, F5, and F17 are the least important positive features, given that they have minimal attributions in favour of C2.\",\n",
       " \"According to the output prediction probabilities across the two classes, the output decision for the given data is C2 with a very high confidence level. C1 has a prediction probability of about 0.00%. The variables contributing most to the abovementioned classification are F10, F2, and F5, whereas F4 and F7 are the least influential variables. The very high confidence level associated with the classification decision here could be attributed to the fact that a greater number of the input variables have attributions that increase the model's response towards label C2. F3, F9, and F4 are the variables with negative contributions that attempt to push the model to label this case as C1. To  put it in a nutshell, the joint contribution of the negative variables is very low unlike that of the positive variables, hence the model's certainty in the decision here.\",\n",
       " 'With a labelling confidence level of 99.50%, the classifier predicts the label C2 in this situation. Hence, it is correct to conclude that the classifier is less certain that C1 is the proper label for the case here. The analysis indicates that five features contradict the decision above, while four features support the classifier. The features contradicting the prediction are usually referred to as negative features while those supporting it are referred to as positive features. The negative features decreasing the odds of C2 being the correct label are F6, F9, F4, F2, and F8. Conversely, the positive features increasing the odds of C2 are F7, F3, F1, and F5.',\n",
       " 'The class assigned by the model is C2 with a close to 97.67% confidence level, implying that the likelihood of C1 is only 2.33%. Based on the analysis, the most important features considered during the classification are F25, F4, F1, and F28 but among these features, F4 and F1 are the only ones with negative attributions, decreasing the likelihood of C2 being the label for the given case. Furthermore, moderately influencing the decision are F12, F27, F23, and F18. F12, F27, and F23 have positive attributions, while F18 has a negative impact, shifting the prediction in a different direction. Finally, the features with insignificant impact on the model when it comes to this case include F17, F10, F9, and F11.',\n",
       " 'With a higher degree of confidence, the model labels this given case as C1 since there is a zero chance that it is C2. The classification here can be attributed to all the features having positive contributions, decreasing the odds of C2 being the correct label. The features can be ranked based on their degree of influence from the most relevant to the least relevant as follows: F5, F7, F3, F2, F6, F4, F1. This implies that F5 is the most influential feature, while F1 is the least influential among the input features.',\n",
       " 'According to the model, C1 has a prediction probability of 99.45 percent, C2 has a prediction probability of 0.47 percent, C4 has a prediction probability of 0.04 percent, and C3 has a prediction probability of 0.05 percent, therefore, the most likely class is C1. F8 and F5 positively influence the above-mentioned label decision in favour of C1, but F7 has the opposite effect, favouring a different label. F9 and F18 both have a similar negative impact on the C1 prediction, whereas F16 has a positive impact. In this case, F4, F1, F13, and F20 have little influence on the labelling result. All in all, the model is confident in its assignment of the C1 class as shown by the predicted probabilities across the classes.',\n",
       " \"Per the model employed here, the prediction probability of C2 is only 17.93%, and that of C1 is equal to 82.07%. Given the information provided to the model, the most valid conclusion regarding the true label is that C1 is without a doubt the most likely one. The attributions analysis indicates that F11, F46, F8, F36, and F31 are the major drivers resulting in the prediction probabilities across the classes under consideration. At the tail end are features such as F17, F9, F13, and F19 that have very little influence on the decision made with respect to the given case. Among the influential features, only F11, F46, F36, F7, F29, F35, F6, F26, and F44 have positive contributions in support of labelling the given case as C1. On the other hand, the negative features such as F8, F31, F15, F10, F38, F39, and F16, suggest C2 could likely be the true label in this case. Overall, the marginal doubt in the correctness of assigning C1 to the case under consideration is attributed to the negative features driving the model's decision in the direction of C2 away from C1. But the higher influence of positive features such as F11 and F46 ensures that C1 is assigned as the most probable label.\",\n",
       " \"The model is about 90.0% certain or sure that the correct label based on the input features of the given case is C1. The features with the most significant influence on the decision are F8, F2, F4, and F9. The influence of the features can be categorised as positive or negative traits depending on the direction of the effect on the model. Positive features increase the likelihood of the most likely class (i.e., C1), whereas negative features reduce the model's responsiveness to the assigned label, favouring the less likely class (i.e., C2). From the attribution analysis, F5, F7, and F1 are the negative features here. Overall, the negative features are shown to have moderate to low influence compared to the positive features, hence explaining why the model is very confident about the assigned label C1.\",\n",
       " \"With an 81.01% chance of being correct, C1 is the most likely label, consequently, the C2 class's prediction probability is only 18.99%. The algorithm or classifier got the above prediction mostly due to the influence of features like F7, F5, F4, and F2. F6, which is found to have very little impact with regard to the label choice here, is the least relevant feature for the algorithm. F5, F1, F4, and F2 have a positive direction of influence, pushing the algorithm higher towards the C1 label. Negative features like F7, F9, and F8 favour choosing or labelling the case as C2.\",\n",
       " 'The model makes classification decisions based on the information provided to it and for the case here, the prediction probabilities across the two class labels, C2 and C1, are 49.32% and 50.68%, respectively. Based on these prediction probabilities, the label assigned is C1, since it has the highest likelihood, however, the model is not very certain about the correctness of the assigned label since its probability is marginally higher than the average. The uncertainty in the classification here can be blamed on the fact that only F1, F6, F4, F12, and F5 have positive attributions, shifting the decision higher towards C1. On the other hand, features F3, F2, F10, F7, F9, F11, and F8 have negative contributions that decrease the prediction likelihood of C1 while increasing that of C2. To cut a long story short, the most positive features are F1 and F6, whereas the most negative ones are F3 and F2. Finally, F9, F5, and F11 are not as important as all the previously mentioned features hence received little attention from the model.',\n",
       " \"The most likely label for the given case is C1 since the predicted probability of C2 is only 34.27% and this means that the likelihood of C1 is 65.73%. The most relevant features that led to the C1 classification verdict are F5, F30, F26, F17, and F15. However, some of the features are deemed irrelevant to the above verdict and these include F3, F4, F13, and F27. Among the relevant features with some degree of impact, seven are shown to drive the model's class assignment towards the C2, while the remaining support the C1 prediction. Notable negative features swinging the prediction towards C2  are F5, F30, and F26, while the notable positive features are F17 and F15. The small uncertainty associated with the prediction decision for the given case could be attributed to the fact that all the three most important features are negative features whose values contradict assigning the label C1.\",\n",
       " \"Per the classifier for the given data, the most plausible label is C2. F2, F19, F24, and F8 are the main features pushing for the above-mentioned outcome. F3, F18, F14, F16, F13, and F22, on the other hand, have little contribution to the classifier employed here. F25, F17, F7, and F9 have a moderate contribution to the assignment of C2. The classifier's confidence in the label decision above can be attributed to larger positive attributions of F17, F25, F24, and F19 compared to the negative attributions of F7, F21, F2, F4, F8, and F5.\",\n",
       " \"The least probable class, according to the classification algorithm, is C2, with a prediction probability of 25.12%, therefore, we can conclude that the algorithm is quite confident that the correct label for this data is C1. Analysing the attributions revealed that F1, F6, F8, and F2 are the most relevant features, whereas F5, F7, and F4 are the least relevant features. Increasing the algorithm's response in favour of C1 are the positive features F1, F8, F2, F7, F5, and F9. On the contrary, all the other features, F6, F3, F12, F11, F10, and F4, drive the algorithm towards labelling the given data as C2, hence they are considered negative features. Furthermore, the negative influence on the algorithm is the reason why the confidence level in the C1 is reduced to 74.88%.\",\n",
       " \"According to the classification algorithm, neither C1 nor C3 nor C2 is the correct label for the given case. It is 100.0% certain that C4 is the right label. The higher degree of certainty in the above prediction can be attributed to the positive contributions of F18, F11, and F12. The other positive features include F20, F15, F6, and F14, however, unlike F18, F11, and F12, these features have a moderately low impact on the algorithm's decision. The remaining positive features, F7, F19, F13, and F9, are among the least influential input features considered by the algorithm. There are other features such as F16, F10, F3, and F4 whose contributions only serve to decrease the odds of C4 being the correct label for the given case. Regarding the high confidence of the algorithm with respect to this classification, one can conclude that the negative features have little influence on the algorithm's label decision here.\",\n",
       " \"The prediction likelihoods across the two classes are 15.35% for class C1 and 84.65% for C2, it can be concluded that C2 is the most probable class label for the given data instance. According to the attribution analysis conducted, the different input variables have varying degrees of influence on the model's decision here. The most influential set of variables is F18, F31, F19, F36, F35, F20, and F38, while the variables with the least influence include F37, F3, F25, F16, F33, and F6. The following or subsequent analysis performed to understand the direction of contribution of of the features  will focus on the most influential ones controlling the label selection here. Among the top influential features, F18, F31, F19, F36, and F38, only F18 and F31 have negative contributions, decreasing the probability that C2 is the correct label, and they strongly support labelling the case as C1 instead. Pushing the classification decision in favour of C2 are the positive variables such as F19, F36, and F38. The contributions of the remaining variables, including F35, F20, and F5, have moderate to low influence. All in all, the marginal uncertainty in the decision here is mainly due to the negative influences of F18, F31, F9, and F23, but the positive contributions of F19, F36, F5, F35, F20, and F38 drive the decision higher towards C2.\",\n",
       " \"According to the machine learning model, it is more likely that the case's label is C2, with a certainty of 100.0%, and this prediction decision is mainly based on the effects of the following features: F8, F10, F6, F9, and F1 on the model. Apart from F1 and F9, all the other variables mentioned above have a strong positive influence, improving the odds of the prediction class, C2. Together with F1 and F9, the values of variables F3 and F2 indicate that C1 could be the correct label instead. Unlike the top positive variables, F8, F10, and F6, each of these negative variables has a moderate contribution to the final decision. The features F5, F7, F11, and F4 are shown to have made minor contributions to the model's decision in this case. In summary, with only the positive contributions from F8, F10, F6, F11, and F5, the model is very certain of the classification output as indicated by the predicted probabilities across C2 and C1.\",\n",
       " 'The classification findings by the model for the case here are as follows: there is a 97.67% chance that C1 is the correct label hence only a marginally low chance of 2.33% that C1 is not the correct label but C2 is. From the above findings, it is valid to conclude that the right class for the given case is C1, and the model is very certain of this decision. The features with the most control and influence on the classification above are F27, F4, F17, F22, and F7 but the influence of the remaining features is either moderate or low or negligible. Some of the features with moderate impact include F14, F11, F15, and F23. Those with low influence are F18, F10, F25, F9, and F8. Finally, those with negligible impact are F19, F3, F1, F6, F5, F20, F29, F28, F2, and F13 since their values are shown to have no impact on the classification made by the model here. The top positive features increasing the prediction likelihood of class C1 are F27, F7, and F24. Conversely, the negative features decreasing the odds in favour of C2 are primarily F4, F15, and F17.',\n",
       " 'The model is very confident that C3 is the most probable class for the given case, with a probability of 90.48% which means that the other labels are very unlikely. F12 and F1 are the most important variables with respect to this classification verdict while all other variables are shown to have a medium or low impact. Fortunately, the top variables, F12 and F1, have the same direction of influence, increasing the likelihood of C3. Furthermore, while F4 and F11 push the model to predict C3, those pushing for the assignment of a different label are F3, F8, and F2. Finally, many features have a fairly small impact on the final prediction made by the model here, but F7, F8, and F6 have the least impact.',\n",
       " \"Despite the reasonably high confidence in the assigned label, the prediction probabilities across the two classes indicate that C2 might be the correct label. F7, F2, F9, and F8 are the factors whose major contributions resulted in the labelling choice mentioned above. According to the analysis, the top two factors, F7 and F2, have a negative influence, leading the classifier to classify the data as C2 rather than C1. F1 is the only other negative variable with a moderate effect when compared to the other two negative variables. Nevertheless, there are several factors, F9, F8, F3, F6, F4, and F5, that favourably support and encourage the classifier to assign C1. All in all, the degree of uncertainty in this classification instance might be explained by just looking at the negative factors' rather strong pull on the classifier towards C2.\",\n",
       " 'C1 has a probability estimate of only 6.80%, while that of C2 is 93.20%; consequently, the most likely class for the given case is C2. The important or relevant features considered by the classifier are F12, F17, F8, F16, F9, F24, F14, F34, F23, F29, F1, F38, F37, F18, F6, F22, F25, F7, F10, and F4. Not all input features are relevant when determining the appropriate label and these irrelevant features include F32, F13, and F28. Furthermore, F12 and F17 have a strong positive effect, increasing the odds in favour of C2. In contrast, the F8, F9, and F16 are the negative features, lowering the odds of C2. Comparing the attributions of F12, F24, and F17 features to those of the negative features mentioned above, it is not surprising that the classifier is convinced that C2 is the most likely label here.',\n",
       " \"The model is not 100% convinced that the correct label for the data under consideration is C2 since there is a 26.27% chance that labelling the data as C1 is correct.  All the input variables are shown to have some degree of influence on the classification decision, with the most influential variables being F9, F2, and F7, whereas F6 and F1 are the least influential. The impact of F5, F3, F4, and F8 can be considered moderate compared to the F9, F2, and F7. The uncertainty surrounding the above classification can be blamed on the fact that the majority of input variables have values suggesting that C1 could be the appropriate label. The negative features that decrease the prediction likelihood of C2 are F9, F7, F4, and F8. However, given that the prediction probability is about 73.73%, it can be said that the influence of positive features, F2, F5, F3, and F6, is enough to swing the model's verdict in favour of C2.\",\n",
       " \"The model predicted class C1 with an 81.98% prediction likelihood. F24 had the largest impact, followed by F23, F9, F18, F14, F10, F11, F2, F8, F21, F20, F27, F4, F12, F15, F19, F13, F16, F30, and finally, F29, which had the smallest non-zero impact. F24, the feature with the largest impact, contributed against the direction of the prediction, whereas F23, F9, F18, and F14 all contributed positively towards the prediction. Other features that had a negative influence on the prediction included F11 and F2, whereas F10 had a positive influence on the prediction. F22, F6, F1, and F5 are shown to have close to zero attribution in the model's prediction verdict in the given case.\",\n",
       " \"This case's label has a 70.83 percent chance of being C3 and per the predicted likelihoods across the alternative labels, C1 has a 29.71 percent chance of being the correct label, however, the model is certain that C2 is not the true label. The most important variables are F1, F7, F3, and F2, whereas the remaining influential variables are listed in order of the magnitude of their contributions: F8, F6, F4, F9, and F5. Three of the nine variables have values that push towards the prediction of label C1 while the other attributes are referred to as positive since their values inspire the prediction of class C3. F1, F7, and F3 are the three attributes that have a negative influence on the prediction judgement, pushing it away from C3 towards the label C1. Finally, it is essential to highlight that the cumulative effect of positive attributes is greater than that of negative attributes, F3, F7, and F1.\",\n",
       " \"First of all, the classification decision is solely based on the information or data supplied to the prediction model. According to the model, there is a 61.61% chance that C1 is the true label, and a 38.39% chance that C2 is the true label. Since the predicted probability of C1 is higher than that of C2, it is valid to conclude that C1 is most likely the true label. The main feature responsible for this classification is F14, with a very strong positive influence, driving the model's decision higher towards C1. The next set of relevant features are F7, F17, F18, F15, F24, F32, F30, and F10. Among all the features mentioned above, F7, F18, F15, F32, and F30 have negative contributions that are responsible for the decrease in the probability that C1 is the true label. This implies that the contributions of F17, F24, and F10 combined with that of F14 explain why the model is moderately certain that C1 is the true label.\",\n",
       " 'Because the prediction probability of C2 is barely 0.70 percent, the classifier outputs the label C1 with near 100 percent confidence based on the values of the input attributes. The effects of F8, F4, and F2 on the aforementioned classification decision are significant. The values of these features are given greater emphasis by the classifier than the others. F2 is has a negative impact among these top features, pushing the prediction judgement towards the least likely class, C2 whereas on the other hand, F8 and F4 are referred to as positive features since they improve the likelihood of the C1 label rather than the C2 label. Finally, unlike the others, the values of F1, F9, F6, and F15 have only a little influence on the label selection made here.',\n",
       " \"The classification algorithm arrived at the prediction output based on the variables or information supplied about the case under consideration. The prediction probabilities across the three-class labels, C2, C3, and C1, respectively, are 28.17%, 50.21%, and 21.62%, making C3 the label assigned by the algorithm, judged based on the prediction probabilities. The attributions analysis suggests that F4, F3, F9, and F8 are the positive features that increase the algorithm's prediction response in favour of C3. On the other hand, F7, F1, F6, F10, F2, F12, F11, and F5 have negative contributions in support of labelling the case as either C2 or C1. Overall, judging by the degree of contributions of the positive features, it is not surprising that the algorithm is moderately certain that neither C2 nor C1 is the most probable label for the case under consideration here.\",\n",
       " \"Judging based on the information provided on the case under consideration, the model outputs that the prediction probability of C2 is only 0.48%, indicating that with about 99.52% certainty, the true label here is C1 and in simple terms, the model is very confident that the true label for the case under consideration is C1. The higher degree of certainty in the above classification can be attributed solely to the positive contributions of influential features F4, F12, and F16. Analysis indicates that all the remaining features such as F1, F8, F17, F7, and F14 have moderate to low contributions towards the prediction conclusions above, whereas F3, F11, F15, and F13 are the least relevant features here. The very marginal decrease in the C1's prediction likelihood could be attributed to the influence of negative features F8, F7, F5, F13, and F11 since their contributions support labelling the case as C2 instead. Moderate positive features further driving the model to label this case as C1 are F1, F17, F10, and F14.\",\n",
       " 'Judging based on the values of the variables passed to the model with respect to the case under consideration, the output labelling decision is as follows: there is about an 83.98% chance that C2 is the correct label, whereas the likelihood of C1 is only 16.02%, hence the label choice with a higher confidence level is C2. The top-variables influencing this decision are F2, F4, F3, and F14, while the least important variables are F9, F12, and F13. According to the variable contributions analysis performed, only the input variables F8, F16, F19, and F15 exhibit negative attributions, pushing the prediction decision towards the alternative label, C1. The other variables positively support the C2 prediction, shifting the verdict strongly away from the C1 class. In conclusion, positive variables such as F2, F4, F3, F14, F7, and F17 have a higher joint contribution compared to the negative features, which can explain why the model is certain that C2 is the most probable label.',\n",
       " 'The model predicts the class label C4 for the given test instance with a likelihood of about 69.23%. However, there is about a 30.77% chance that the true class label is C2, while the others, C3 and C1, have a 0.0% likelihood. The top features contributing to this prediction decision are F1, F15, F9, and F2, whereas the least important are F12, F11, and F6. Among the top features, while F1 and F15 have values that shift the prediction decision towards the C4 class label, the values of F9 and F2 suggest that the true label could likely be C2. For the features with moderate influence on the decision, F4, F14, F18, and F5 have negative contributions, further decreasing the confidence level in the C4 assignment. On the other hand, the moderate positive influences of F17, F8, F20, F19, and F16 drive the decision further towards the C4 label. Considering the attributions of the input features, it is surprising that the confidence level is just 69.23% since the top feature, F1, has the highest contribution among all the input features. Finally, the values of F10, F11, and F6, though shown to be less important when deciding the correct label for the given case, have positive contributions to the prediction with respect to the given case.',\n",
       " 'The given case is likely C2 with a confidence level of 87.50% judged based on the values of the input features supplied to the classifier and according to the attributions analysis, F9 and F2 have a high degree of impact. F6, F8, F3, F4, and F5 have a moderate degree of impact while on the contrary F7 and F1 have little impact. Examining further, the values of F9, F2, F6, and F8 all have a positive influence on the classifier supporting the label assignment decision for the given test case. F3 and F5 are also positively supporting features, whereas F4 has a negative influence on the final classification. Finally, F7 and F1 both have very little contributions, though F1 has significantly less than even F7.',\n",
       " \"The label for this example is estimated to be C2 among the four possible classes, with a 73.08 percent chance of being true. C1 is the next most likely label, with a probability of roughly 26.92 percent. The above prediction assessment is mostly dependent on the values of the variables F3, F9, F8, F5, and F12. F3 had the greatest influence, followed by F8, F9, F12, and F5. The positive variables F3, F9, F10, and F17 outnumber the negative variables F8, F12, F5, and F19. Twelve of the twenty variables have values that tilt the prediction towards one of the three other probable classifications. As a result, it is not unexpected that the model is not completely certain of the C2 assigned. Given that the chance of C2's being accurate is 73.08 percent, the model appears to be relatively confident in its final judgement for the data instance under review.\",\n",
       " \"The model has classified the instance as C2 due to the effects of the following features: F5, F8, F6, and F2. Based on the values of these variables, the likelihood of the C2 label is 65.51 percent. F2 and F6 are the top positively contributing variables, whereas F5 and F8 are the most adversely contributing variables. Unlike F2 and F6, which have greater influences on the model's prediction choice in this situation, F3 and F9 have fairly modest positive influences. Finally, F1, F7, and F4 show negative predictive effects, however, as compared to F5, their attributions are modest.\",\n",
       " 'Considering the predicted likelihoods across the classes,  C2 is confidently chosen as the true label since its likelihood is 93.27%, implying that the likelihood of C1 is only about 6.73%. F6 and F15 are the two features with a very strong positive influence, favouring the prediction of class C2. The following features have a moderate effect and are listed in descending order of influence: F5 and F10 have a negative effect, while F4 and F13 have a positive effect on the prediction of C2. Similar to F5 and F10, the features F9 and F8 also negatively affected the prediction decision. Finally, the values of F2, F16, F1, and F7 are the least important to the model decision for this case.',\n",
       " 'The classification output is C1, however, the classifier is somewhat unsure about this prediction decision because the corresponding predicted probability is only 55.19%. F11 is by far the most influential feature whereas F4, F6, and F17 have been recognised as having the biggest effect on prediction output here after F11. The combination of F11, F4, F6, F17, and F3 features has resulted in the classification choice being altered from C1 to C2. While F5, F2, and F16 all have a minor influence on the classification, F5 is the only one that has a positive impact on the C1 classification. In this case, many features had lower influence on the prediction, with F15, F8, F13, F19, and F10 having a marginal effect.',\n",
       " 'Judging based on the values of the input variables, the classification algorithm labels the case as C2 since its prediction likelihood is equal to 88.69%. The prediction decision is primarily based on the contributions of F2, F1, and F9, however,   F7, F4, and F10 are shown to be the least important variables. Regarding the direction of influence of the variables, F2, F9, F6, F7, and F4 are the positive variables that increase the odds of C2 being the correct label. Driving the prediction toward the alternative label, C1, are the variables F1, F3, F8, F5, and F10. Owing to the fact that the most influential variables, F2 and F9, have strong positive attributions, outweighing the contributions of the negative variables, it is not surprising that the algorithm is certain about the decision made.',\n",
       " 'The classification algorithm predicts class C1 with a confidence level of 61.55% and this implies that the probability of the alternative label is only 38.45%. In this case, the top features driving the prediction decision are F7, F9, F1, and F2, followed by F4, F5, F8, F3, and finally F6. Based on the inspections performed to understand the direction of influence of the input features, it can be concluded that F7 has the strongest positive contribution, while F1 has the strongest negative contribution and conversely, all the remaining features have moderate contributions. The other positive features are F9, F4, F5, and F3, whereas the remaining negatives are F2, F8, and F6. All things considered, the influence of the negative features indicates that the likelihood of the C2 label is 38.45% while the positive contributions push the prediction higher towards C1 resulting in the 61.55% prediction confidence.',\n",
       " \"The classification model's decision about the true label for the case is based on the information provided to it. Among the three labels, C2, C3, and C1, the model shows without a doubt that neither C3 nor C1 is the true label, given that the probability of C2 being the true label is 100.0%. F12, F6, and F2 are the main contributing factors or variables in the final verdict here since their respective influence outranks the remaining variables. In fact, analysis indicates that F3, F11, and F5 are the least influential variables since they receive little emphasis from the model when making the labelling decision here. In between F12, F6, and F2, and F3, F11, F8, and F5, are the variables such as F9, F10, F1, and F7 with moderate influence on the classification decision here. Among the variables passed to the model, only F9, F7, and F3 are shown to have negative contributions, which suggests that perhaps the true label could be either of the remaining labels. However, given the 100.0% predicted likelihood of C2, it is reasonable to deduce that the positive variables, such as F12, F6, F2, F10, F4, and F1, significantly influence the model's judgement towards C2.\",\n",
       " \"According to the model, C1 is the class with the higher probability, which is equal to 52.57 percent, of being the label for this selected instance or case. Conversely, there is a 47.43 percent chance that C2 is the correct label showing that the model is less certain about the classification verdict in this case. This uncertainty can be linked to the fact that the majority of variables have values that favour assigning C2. The only variables increasing the model's response to prediction C1 are the positive variables namely: F6, F16, F7, F1, F8, F11, and F5. The top negative variables decreasing the likelihood of C1 are F14 and F19 supported by other negative variables, F2, F18, and F9, that further shift the verdict towards C2.\",\n",
       " 'According to the predicted likelihoods across the classes, C1 has a 17.0% chance of being the true label for the given data or case, implying that C2 is the most likely label. F12, F19, and F20 are the most important factors that led to the classification judgments above. The remaining factors have a minor or non-existent impact on the classifier. The classifier most likely ignored the values of F18, F3, F1, F8, F14, and F5 when giving a label to this case since their relative degrees of impact are extremely near to zero. F9, F15, F24, F11, F21, and F4 are considered negative factors among the significant factors because their contributions to the choice tend to reduce the chance that C2 is the correct label. These negatives features lend themselves to the case being classified as C1 but the remaining features contribute positively, raising the likelihood of the C2 classification.',\n",
       " 'According to the ML model, C1 is the most likely class label, and we can conclude that the model is quite confident about the decision given that the probability of having C2 as the correct label is only 7.0%. For the case under study, analysis indicates that F4, F8, F3, and F6 are essentially the negative set of features that push the forecast higher towards C2 instead of C1, while F7, F11, F2, and F1 increase the odds of the prediction being equal to C1. In general, the most relevant feature is F7, while F5 and F9 are the least relevant features, with marginal influence on the above classification verdict. In summary, given the very strong positive influence of F7 together with the moderate influence of the other positives, F11, F1, and F2, it is not strange that the model chose to label the case as C1 instead of C2.',\n",
       " 'Because the confidence level associated with the other class, C1, is just 2.29%, the model predicts that the given example is likely C2 and to be specific, the model is quite certain that the right label for the given case is C2. All the features are shown to have some degree of influence on the decision above, with F14 and F6 being the least relevant features, while F5 and F9 are the top features. From the analysis performed to understand how each feature contributes to the above prediction assertion, only  the features F13, F12, F1, F8, F7, and F6, have negative influences, shifting the prediction verdict towards C1.  The remaining features all contribute positively, strongly shifting the prediction towards the assigned label which could explain the prediction confidence level associated with label C2. The most positive features are F9, F2, and F5 with stronger push in favour of the output label and they are supported by other positive features such as F4, F10, F3, and F11 have a moderate degree of influence.',\n",
       " 'The classifier made the prediction here based on the information provided about the case under consideration, and according to the classifier, the prediction probabilities or likelihoods across the labels C1 and C2 are 100.0% and 0.0%, respectively. All the input features are shown to have different degrees of influence on the final decision here by the classifier. The most influential features are F5 and F3, with F2 and F6 ranked as the least contributing factors. The values of F4 and F1 suggest that perhaps the true label could be C2 since they are the negative features. However, considering the confidence in C1, it is valid to conclude that the joint influence or contribution to the classification of the negative features with respect to the given case is outmatched by the joint positive attribution of F5, F3, F2, and F6.',\n",
       " 'For the selected case, the model assigns the label C1. The prediction probability distribution across the classes C2 and C1 is 2.40% and 97.60%, respectively. The most important features considered for this prediction are F18, F3, F12, and F15, while on the other hand, the least relevant features with little contributions to the decision based on the analysis are F1, F8, F19, and F9. The top positive features Increasing the likelihood of the prediction being made are F18, F3, and F15. Pushing the prediction towards the alternative class C2, the top negative features are F12, F14, and F4. F17, F11, F13, F7, and F2 are some of the features that have a moderate impact on the classification decision in this case.',\n",
       " \"The given instance was labelled as C1 by the model based on the values of its features. The model is about 79.64% certain about this prediction decision, hence, there is a slight chance that the label could be C2. Among the different features, the ones with the most impact on the model are F8, F25, F9, F2, and F27. The most negative feature is F8, and it is significantly pushing the narrative toward the prediction of C2. From this, it is foreseeable that there is a chance that the true label could be C2 which is about 20.36%. The influence of F8 and F9 is somewhat counterbalanced by the values of the features F25, F2, and F27. Other attributes that shift the decision in favour of C2 are F7 and F24. F3 shifts the decision further in the direction of C1 and in addition, F31 supports the model's prediction while the values of F5 and F32 of the given test case contradict the model's decision, decreasing the likelihood of C1. Among the features not relevant to this prediction decision for this case are F10, F20, F28, and F26.\",\n",
       " \"According to the classification algorithm, the best label for the given case is C2, because there is little to no chance that C1 is the correct label. Not all of the features are found to contribute to the label given here. The following significant features are ordered in order of their effect on the algorithm's output: F36, F8, F26, F35, F3, F12, F24, F9, F21, F6, F20, F5, F4, F25, F19, F27, F7, F23, F37, F31. F30, F33, and F13, on the other hand, are unimportant features since they have almost no influence. Among the most influential features F36, F8, F26, F35, and F3, F26 is considered the most negative, dragging the verdict in a different direction, while the others have positive contributions, increasing the possibility that C2 is correct in this case. F24 is recognised as a positive feature with modest effect, whereas F12 and F9 are identified as negative features. Given that the majority of the top five attributes have positive contributions, boosting the likelihood that C2 is the correct label, it is not unexpected that the algorithm is quite confident in the assigned label's accuracy.\",\n",
       " 'The classifier labbelled the given case as C2 with a confidence level of 98.89%, implying that the chance of C1 being the correct label is only about 1.11%. The classification output decision is solely based on the information supplied to the classifier about the case under review. We can rank the contributions of the features as follows: F12, F6, F8, F3, F13, F15, F5, F1, F10, F2, F9, F14, F7, F11, and F4. Among the top features, F12 is the only negative feature, increasing the probability of predicting the alternative label, C1. Other top features that are shifting the prediction towards C2 are F6, F8, and F3. Similar to F12, the features F5, F11, and F2 have negative contributions, supporting the generation of C1. By comparing the strong joint positive attribution to the joint negative attribution, it is evident why the classifier is very certain that C2 is the right label for this instance.',\n",
       " \"The prediction probability associated with class C1 is 10.50%, while that of class C2 is 89.50%, therefore, it can be concluded that C2 is the most probable label for the given case according to the model. All the input features are shown to contribute to the above decision, and the ones with the strongest influence on the classification decision are F8, F7, and F1, but F10, F4, F6, and F3 are shown to be the least relevant features . Finally, the degree of influence of F9, F5, and F2 can be described as moderate. The model's high confidence can be attributed to the strong positive contributions of F7 and F8 which are supported by the contributions of the remaining positive features F9, F10, and F4. Conversely, shifting the prediction in favour of C1, the negative features F1, F5, F6, F2, and F3.\",\n",
       " 'The model labels the case as C2 with fairly high confidence equal to 89.73%, whereas the likelihood of C1 is only 10.27%. Analysis shows that only 20 of the 46 input variables contribute to the prediction assertion above. The prediction judgement C2 is mainly based on the variables F17, F9, F18, and F19. F43, F23, F32, F33, F29, and F20 also contribute to the decision, however, their degree of influence is only moderate. According to the direction of influence analysis, F17, F19, F29, and F33 positively support the decision of the model to assign the label C2. However, F9, F23, F20, F18, F43, and F32 reduce the likelihood or chance that C2 is the true label for this particular test instance. The main variables with less influence on the above classification decision are F14, F31, F7, and F38.',\n",
       " 'The label predicted for this case is C1 with very high confidence of approximately 97.71% which insinuates that there is a marginal possibility that C2 could be the label. The above classification decision is largely due to the values of F4, F8, F3, and F14. On the other hand, F6 and F1 are less relevant when the model is deciding the correct label for the case here. Digging deeper revealed that each feature either positively or negatively contribute to the prediction made here. Six features contradicted the classification decision, while the remaining ones positively supported the C1 prediction. The negative features driving the prediction towards C2 are F3, F5, F13, F2, F9, and F1 and countering their influence are  the top positive features are F4, F8, F7, and F14.',\n",
       " 'The likelihood of C2 being the correct label for the selected case or instance is 67.54% according to the classifier. This means, there is a 32.46% chance that C1 could be the label and the classification assertion above is influenced mainly by the variables F11, F4, F7, and F9. On the contrary, F10, F2, and F5 are deemed less important when deciding the correct label for this given case.   Decreasing the likelihood of the predicted label , C2, are the variables  F9, F8, F2, and F5, therefore, these negative variables support the alternative class C1. However, the collective or joint attribution of the top positive variables, F4, F11, and F7 is strong enough to tilt the classification in favour of C2.',\n",
       " 'The confidence level score with respect to each class label suggests that this case should be labelled as C2. Specifically, there is about an 80.0% chance that C2 is the correct label. However, this implies that there is also about a 20.0% chance that it should be C1. The above prediction decision is based predominantly on the influence of the following features: F8, F1, F7, F5, F3, F11, and F2. According to the analysis, the features F8, F1, and F7 have a very strong positive influence, swinging the prediction decision towards C2. In contrast, the value of F5 also suggests the decision should be the alternative class, C1. Similar to F5, the values of F10, F3, and F11 indicate the label could be C1. However, the influence of these features is very small compared to F8, F1, F7, and F5. Finally, the attributes with a moderately low influence on the final prediction decision for this case include F2, F6, F4, and F9. The values of F2 and F9 have a negative attribution, while F6 and F4 have positive attributions.',\n",
       " 'The classification algorithm is pretty confident that the correct label for the data under consideration is C1, wowever, it is noteworthy to consider that C2 has about a 15.13% chance of being the correct label.  The predicted probability of each label is assigned based on the influence of features such as F6, F3, F10, and F8. However, the analysis shows that the values of F11, F2, F12, and F5 are less relevant when classifying the data.   Only the features F10, F9, F11, F2, F12, and F5 have negative attributions, decreasing the predicted probability of the assigned label and one can say these features are shifting the prediction decision towards the label C2.',\n",
       " 'The case, despite having features with considerable negative impact, also has numerous and measurable positive features, so the assignment of the label C2 by the model is very likely since the predicted probability is 91.95% which is very higher than that of C1. The F26, F6, and F16 were the most important features driving the model to arrive at the labelling assignment of C2. F11 and F12 have nearly identical positive attributions, while F19 and F4 has negative impacts, swinging the prediction towards a different label. However, the joint positive impact of F11, F26, F16, and F12 stands out over the impact of F6, F18, F4, and F19, favouring the prediction of the C2 model. All things considered, there are more features with a positive impact than those with negative impact; the mean attribution of the positive attributes is much larger which somewhat explains why the confidence level is very high. Above all, it is important to note that the prediction is made with less emphasis on the values of F15, F5, F10, and F9 hence they are practically irrelevant when it comes to labelling this case.',\n",
       " 'The predicted label is C2 given the predictability of C3 is 28.96% and that of  C1 is 23.41%. Considering the probabilities of the classes, the model can be described as being moderately confident. The prediction of C2 can be attributed to the varying degree of contributions of the input features. Attribution analysis indicates that F9, F7,  and F3 are considered the most influential. Those with moderate influence are F10, F5, F11, F4, F2, and F6, whereas on the contrary, the least influential ones are F8, F1, and F12. The analysis also revealed that not all the features contribute positively to the prediction decision and amongst the input features, the ones with negative attributions decreasing the likelihood of the C2 prediction are  F7, F3, F11, F4, and F2 whereas conversely, the top positive features are F9, F10, and F5.',\n",
       " \"The model outputs a predicted probability of 2.55% for the C1 label and 97.45% for the C2 label. Judging from above, the most probable class is C2. Hence, C2 is the assigned label by the model, with a very high confidence level. The top features contributing to the prediction assessment above are F51, F26, F4, F55, and F9. However, the values of about twenty features are deemed relevant while the remaining are regarded as irrelevant when classifying the given case. These irrelevant features include F67, F45, F11, and F71. Among the relevant features, F4, F6, F32, F28, F10, and F57 are shown to be the only positive features that increase the model's response in favour of the assigned label C2. In contrast, the majority of the relevant features, mainly F51, F26, F55, and F9, have negative contributions, decreasing the odds of the label C2, hence supporting the assignment of C1 to the given case.\",\n",
       " \"The algorithm identifies the provided data or case as C1 with a greater level of certainty since the prediction probability of class C2 is just 0.07 percent as a result, C2 is less likely than C1. The influence of input features such as F7, F21, F33, F8, and F27 is mostly responsible for the classification verdict above with only F27  having a negative influence among them, slightly pulling the decision in favour of C2. F7, F21, F33, and F8, on the other hand, make considerable positive contributions in favour of assigning C1 to the data. F10, F37, F34, F23, F25, F17, F1, and F14 are some more features that have a modest effect on the algorithm's decision. But, not all features are demonstrated to influence the classification decision either negatively or positively to the aforementioned classification outcome and in reality, a number of these are demonstrated to be irrelevant for determining the suitable label for this case and these include F13, F18, F35, and F19. All in all, the most important features for this classification instance are F7 and F21, whereas F38 and F32 are the least important.  \",\n",
       " 'For the given dataset instance, the label assigned by the classifier is C1 since it has a predicted probability of about 89.16%. On the other hand, there is a 9.0% chance that C2 could be the appropriate label, whereas C3 only has a 1.84% chance of being the true label. The classifier arrived at this classification verdict chiefly due to the influence and contributions of variables such as F5, F4, F10, and F6. However, there is less emphasis on the values of F1, F8, and F2, since their impact on the classifier with respect to the given case is smaller compared to the other variables, hence they are the least ranked features. From the attribution analysis, there are four variables with negative contributions, pushing the verdict in the direction of C2. These negative variables are F5, F6, F7, and F3, and their influence on the classifier could explain why there is a little bit of doubt about the correctness of the C1 class assigned and the notable positive variables are F4, F9, F1, and F10.',\n",
       " 'The case is labelled as C2 by the model but looking at the predicted probabilities across the different classes, there is a 33.63% chance that the label could be C1. To explain the above prediction conclusion, the analysis revealed that the majority of the features have negative influences or attributions, pushing the prediction away from C2 in favour of C1. The negative features include F8, F6, F17, F4, and F10 and the values of these features are ranked higher than any of the positive features. Shifting the prediction in the direction of C2 are the positive features F5, F19, F15, and F16. The analysis also revealed that the values of F11, F12, and F3 are less relevant to the prediction for the case under consideration.',\n",
       " 'The most likely label chosen by the model in this case is C1. The decision above is based on the prediction probabilities for the two possible labels, C1 and C2, which are 94.25% and 5.75%, respectively. The following variables can be ranked from most important to least important based on their contribution to the model when it comes to this instance: F4, F10, F1, F2, F7, F9, F8, F6, F3, and F5. F10 and F4 turned out to be the most important positive variables, supporting the model towards assigning the class C1. The least positive variables are F6 and F8, which have less effect on the model. In fact, most of the input features have negative contributions towards the assignment of class C1, leading to a decision change in favour of the other label, C2. The most negative variables are F7, F1, and F2, and the least negative are F3 and F5.',\n",
       " 'As per the classification algorithm employed, the most probable label for the data under consideration is C2 since the chances of C1 is very slim and negligible.  The main driver behind the labelling decision above is F1. The features with moderate influence are F5, F6, F2, F8, F9, and F4, while those with very small or marginal impact are F3 and F7.  The direction of influence of the input features could be used to explain why the algorithm is very confident here. Most of the features have a positive impact, increasing or improving the chances of C2 being the correct label and the feature with a significantly higher contribution, F1, is a positive feature which when coupled with other positives F6, F2, F4, and F9 encourages the prediction or assignment of the C2 label. Furthermore, aside from F5 and F8, the other two negative features, F3 and F7, are shown to have a significantly lower impact on the algorithm and the very marginal doubt in the decision can be attributed to the influence of the negative features.',\n",
       " \"The ML algorithm classifies the provided data or case as C2 with a likelihood of 80.70%, hinting that the likelihood of C1 being the correct label is only 19.30%. This classification decision above is mainly based on the influence or contributions of the input features. The most relevant features driving the classification algorithm to arrive at the above decision are F11, F16, F22, F6, F32, F27, and F25. On the other side, not all of the input features are considered relevant when deciding the appropriate label for the given data instance, and these irrelevant features include F24, F18, F31, F3, and F19. Among the top influential features, F32, F27, and F25 are regarded as negative features since their contributions push the algorithm's decision towards the less likely class, C1, although F11, F16, F22, F29, and F6 have positive contributions, increasing the probability that C2 is the right label here.\",\n",
       " 'The predicted probability of class C2 is 12.81% and that of class C1 is 87.19%. Therefore, the label chosen by the model is C1, which is the most probable class. The top two features with significant influence on the prediction verdict above are F5 and F20. These features have positive attributions, shifting the decision higher in support of label C1. Other positive features are F28, F8, F3, and F37. Decreasing the likelihood of the assigned label are the negative features such as F31, F17, F16, and F6. Finally, the values of features such as F39, F4, F22, F30, F14, and F1 are considered irrelevant to the prediction decision above.',\n",
       " \"The C1 has a predicted probability of just 3.10% while that of the C2 is 96.90%, therefore, the most likely class selected by the classifier for the given data is C2. The relevant features contributing to this classification are mainly F23, F4, F31, F9, F35, F14, F5, F25, F3, F8, F18, F36, F34, F1, F22, F10, F33, F29, F16, and F11. As per the attribution analysis, F23 and F4 have a very strong joint positive contribution, increasing the classifier's response higher in favour of C2 than C1. In contrast, F31, F35, and F9 are the top negative features, degrading the classifier's response in favour of C1. Comparing the attributions of F23, F14, and F4 to those of the negative features mentioned above, it is not surprising that the classifier is quite confident that C2 is the most probable label here.\",\n",
       " 'There is only a 17.0% chance that C1  is the correct label which implies that the most probable label for the given data or case is C2 given its predicted likelihood of 83.0%.  The main influential features resulting in the classification conclusions above are F25, F5, and F3 whereas the remaining features have either a moderate or negligible influence on the classifier. When it comes to assigning a label to this case, the classifier likely ignored the values of F1, F13, F12, F24, F14, and F19 since their respective degrees of influence are very close to zero.  Among the influential features, only F26, F18, F2, F16, F23, and F10 are considered negative features mainly due to the fact that their contributions towards the decision here only serve to decrease the likelihood that C2 is the correct label and it can be said that these features favour labelling the case as C1. The remaining features such as  F25, F5, F3, F7, F4, F20, and F15, offer positive contributions, increasing the likelihood of the C2 class.',\n",
       " \"The classification algorithm's decision on the true label for the given case is solely dependent on the information presented to it. Per the algorithm, the accurate label for the case under consideration is most likely C1, and the 12.47% possibility of C2 reflects only a minor uncertainty in the classification algorithm's certainty. The marginal doubt mentioned above can be blamed on the negative contributions of F11, F6, F7, F1, and F5, supporting the assignment of C2 instead of C1. Conversely, the positive contributions of F2, F10, F3, F4, F8, and F9 are shifting the algorithm's decision higher in favour of label C1, hence the high certainty of its correctness. Overall, F11 and F6 are the most influential negative features, whereas F2 and F10 are the most positive features. Also, F12 is shown to have a negligible influence on the classification decision with respect to the case here.\",\n",
       " 'The model indicates that the label for this case is likely C2, with an 83.33% chance that it is correct, implying that it is unlikely that C1 is the appropriate class. This predictive assertion is chiefly influenced by the values of the input variables F13, F24, and F1. While the F1 and F24 values positively control the model towards the prediction of C2, the F13 value biases the decision towards C1. However, the combined effect of F1 and F24 outweighs the contribution of F13. In addition, the variables F7, F18, and F21 also positively support the output predictions of the model. F17 has similar direction of contribution that of F13, further decreasing the odds of the C2 label. Unlike all the variables above, F25, F26, F4, F9, F15, and F8 are shown to have very little effect on model predictions with respect to the given case and we can say that their values receive very low consideration from the model.',\n",
       " \"The algorithm's forecast for the data instance under consideration is C2, and the decision's confidence level is about 91.36 percent. We can observe from the plot that the variables F13 and F11 are moving the prediction judgement towards the other label, C1. The F12, F8, F2, and F7, on the other hand, have values that have a favourable influence, pushing the data classification choice towards label C2. While F1 and F3 contradict the prediction, F10 and F14 have values that confirm the algorithm's prediction output verdict.\",\n",
       " 'The model classifies this case as C1 and it is noteworthy that there is, however, a 38.26% chance that the true label could be class C2. The uncertainty associated with the classification decision above is higher than expected, which could be attributed to the values of the different input features. The most influential feature is F9, which has a positive effect on the class C1 prediction by the model here. All other features are much less influential, with contributions from F20, F2, F22, and F12 shifting the prediction towards C2. Supporting the model in assigning the label choice, F1 is the next most influential feature. The impacts of the F21 and F17 are moderate, ranking seventh and eighth, respectively. Unfortunately, values of features such as F33, F23, F32, and F6 do not matter when determining the correct label in this instance.',\n",
       " 'The classification or prediction algorithm indicates that the most probable label for the given data is C1 since there is only a 25.47% chance that C2 could be the correct label. The major factors resulting in the above decision are F10, F7, and F5, while the set of features with moderate influence are F9, F2, F1, and F8. The least vital features are shown to be F3, F11, F4, and F6. In conclusion, it is very surprising to see the uncertainty surrounding the classification here given that only F9 and F1 have a negative impact, driving the algorithm to label the data as C2. To be specific, the contributions of F9 and F1 result in a decrease in the likelihood of C1 being the right label, as indicated by the prediction probabilities across the two possible classes but the influence of these negatives are moderated by the major positive features which are F10, F7, and F5.',\n",
       " 'The classification verdict is as follows:  the most probable label for this case is C1, and the classifier is certain that neither C2 nor C3 is the correct label. The main drivers for the above classification are F4, F1, and F7, all of which have a strong positive influence, pushing the classifier to choose C1. Other positive features pushing the classification further higher towards C1 include F9, F6, F11, and F2. Not all the input features support the assigned label and the negative features F12, F5, and F3 indicate that the most probable class for this case could different from the assigned label. However, considering the confidence level in the above classification, it is valid to conclude that the classifier paid little attention to the negative features, hence selecting class C1.',\n",
       " \"The best choice of label for the given case is C2 according to the classification algorithm, since there is little to no chance that C1 is the right class. Not all the features are shown to contribute either positively or negatively towards the label assigned here. The influential features can be ranked according to the associated degree of impact on the algorithm's output as follows: F8, F21, F27, F24, F14, F25, F28, F17, F26, F15, F22, F12, F20, F4, F19, F7, F16, F35, F6, F30. On the other hand, the irrelevant features include F36, F9, and F38 since they have close to zero impact. Among the top influential ones, F8, F21, F27, F24, and F14, the input feature F27 is regarded as the most negative, dragging the verdict in a different direction, while the others have positive contributions, improving the likelihood that the choice of C2 is appropriate in this case. The features with moderate influence are F28, F25, F17 where  F28 is identified as a positive feature, while F25 and F17 considered negative features. Since a large number of top features have positive contributions that increase the probability that C2 is the right label, it is not surprising that the algorithm is very confident about the correctness of the assigned label.\",\n",
       " 'For the given case, the prediction decision is as follows: The probability of C2 being the correct label is only 18.57%, the probability of C1 is 81.43% making it the most probable label for the case here. The certainty of the prediction can be attributed to the influence of variables such as F8, F12, F4, F6, and F7. The least relevant variables considered to arrive at the classification verdict are F2, F5, F10, and F11. F9, F3, and F1 have moderate contributions to the classification here. The attribution analysis performed indicates that F6, F7, F3, F1, F5, and F11 are the negative variables, decreasing the likelihood of C1 in favour of labelling the given case as C2. The variables F8, F12, and F4 have the highest positive influence, which increases the odds of label C1 being the correct label.',\n",
       " 'The output decision of the classifier with respect to the given case is: C1 is the most probable label, followed by C2 and C3. To be specific, the predicted likelihood across the classes are as follows: 86.54% for C1, 13.46% for C2, and finally a 0.0% probability with respect to C3.  The moderately high classification confidence could largely be due to the impact of certain input features supplied to the classifier. F9, F12, F7, F6, and  F8 are the top-ranked variables whereas the least ranked are F1, F10, F2, F5, F3, F11, and F4. The marginal uncertainty in the classification verdict is due to the negative attributions of F12, F8, F2, F3, and F4 which prefer labelling the case differently. In conclusion, we can see that F9, F7, F6, F10, and F1 are among the positive variables pushing the classification in favour of C1.',\n",
       " \"C2 is the predicted label assigned to this case or instance. This is based on the fact that there is only a 0.68% chance that C1 is the correct label. The most relevant variables that increase the prediction's probability are F8, F2, F20, and F7. Conversely, F13 is the only important feature driving the classification decision in the direction of C1. Other negative features include F14, F12, F1, and F4. Other positive features increasing the chances of the C2 prediction are F19, F5, and F17. Unlike F8, F2, F20, and F7, these positive variables have moderate contributions to the model's decision. The least ranked among all the relevant features are F21, F3, F10, and F6, with lower attributions to the C2 prediction, however, F11 and F18 are shown to have no impact when determining the correct label for the case under consideration.\",\n",
       " 'The following classification decisions are largely based on the factors or attributes of this particular case. The class label, in this case, is projected to be C1 out of the potential classes, which is 97.50% likely. The next possible label is C2, which has an approximate probability of 2.50%.  The confidence level with respect to this classification is very high, and the features with the most contributions are F3, F6, and F2. However, F9, F8, and F1 are shown to be the least relevant features. The attribution analysis shows that the only positive features whose contributions favour labelling the case as C1 are F6, F2, F7, and F5. However, the negative attributions of F3, F4, F8, F9, and F1 also indicate that perhaps C2 could be the true label. Judging based on the confidence level coupled with the attributions, it can be concluded that the values of the positive features F6, F2, F7, and F5 are good enough to steer the classification in the direction of C1, but the strong negative attribution of F3 casts about 2.50% of doubt on the decision.',\n",
       " \"The prediction probabilities for classes C2 and C1, respectively, are 15.35% and 84.65%. Based on the aforementioned, C1 is the most likely class label for the presented data instance, and according to the attribution analysis, the various input variables had varying degrees of impact on the model's classification judgement. F33, F8, F17, F37, F29, F32, and F4 are the most influential factors, whereas F25, F18, F26, F15, F13, and F3 have the least impact. The subsequent analysis will concentrate on the most relevant factors influencing the label selection in this case. Looking at the attributions of the input features, only F33 and F8 exhibit negative contributions among the top influential features, F33, F8, F17, F37, and F4, lowering the chance that C1 is the right label, and they strongly favour labelling the instance as C2 instead. Positive variables such as F17, F37, and F4 influence the classification choice in favour of C1. The remaining variables, including F29, F32, and F2, have a moderate to low impact. In essence, the marginal uncertainty in this decision is mostly owing to the negative impacts of F33, F8, F31, and F11, while the positive contributions of F17, F37, F2, F29, F32, and F4 push the decision much closer to C1.\",\n",
       " \"The model assigns the class C1 with near perfect certainty or confidence level since the predicted likelihood of C2 is only 1.0%. F63, F90, F49, F64, and F93 have the greatest cumulative beneficial influence on the model's choice to create C1. F67 also had a significant influence, but it shifted the choice away from C1. Furthermore, F45 and F20 had a modest influence on C1 decision making, which was still bigger than features F30 and F50, which had a moderate impact and contributed to C2 class prediction. Furthermore, F20, F48, and F23 have minimal positive impact on the final result, further increasing the chances of C1 being the  appropriate label for the given case. However, a number of input features, notably F38, F65, F72, and F87, appear to be less essential to predictions here. All in all, the very high confidence level could easily be explained away by considering the fact that the joint influence of the positive variables such as F63, F90, F49, F64, and F93 far outshines the joint contribution of the negative variables such as F67, F30, F50, and F3.\",\n",
       " 'Between the two classes, the model labelled this case as C1 with a likelihood of about 97.0% since there is only a marginal chance that it belongs to label C2. The most relevant features influencing this decision are F6, F1, F7, and F12. In this case, F6, F1, and F12 have a considerable positive influence on the prediction of C1. In contrast, the values of F7 and F13 throw a bit of doubt on the C1 prediction. However, compared to F6, F1, and F12, this shift is very small. Finally, there are some attributes with limited impact on the prediction of C1 and these are F5, F3, F11, F2, F9, and F10 since their values are less important to the model in terms of determining the label for this case.',\n",
       " 'Probably C1 is the right label for this case since the probability of the alternative label, C3 and C2, are only 1.03% and 0.0%. The order of importance of the features for the above classification verdict is F1, F4, F2, F6, F5, F7, F3, and F8. Analysis conducted shows that only the features F4, F5, and F7 have negative contributions, hence reducing the probability of assigning label C1 to the given case. Positive features that increase the likelihood that C1 is the valid label are F1, F2, F6, F3, and F8. The co-attribution of the positive variables is stronger than that of the negative ones, so it is not surprising that we see the level of confidence associated with the prediction of class C1.',\n",
       " 'The model labels the given data as C2 since it has a higher predicted probability equal to 51.42% compared to that of C1 which is equal to 48.58%. The input variables with higher contributions to the above classification decision are F21, F4, F9, F30, and F25, while those with little influence are F16, F7, F27, F22, and F19.  Positively supporting the choice of the label, in this case, are mainly F21, F4, F25, and F30. However, the main negative variables are F9, F6, and F1. Judging based on the degree of influence as well as the direction of influence of the variables, it is not surprising that the model is only 51.42% confident in the assigned label which is marginally above average.',\n",
       " 'The following is the classification for the provided data:  C1 is the most likely class label and C2 cannot possibly be the correct label given the likelihood is 0.0%. F12, F38, and F75 are the key variables that contributed to the classification choice. However, the classifier does not consider all features while making this conclusion, and these irrelevant features include F58, F24, F57, and F63. Revealed to have positive contributions to the prediction made here among the top features are  F75, F19, F64, and F23, but all of the others, F12, F38, F61, F72, F7, F26, and F92, argue against labelling the present scenario as C2 and despite the fact that the bulk of relevant features are pointing in the opposite direction, the classifier is extremely certain that the proper label for the current scenario is C1, not C2.',\n",
       " \"The prediction probability of C1 is 17.93% and that of C2 is 82.07%. Therefore, the most probable class for the given case is C2. The above classification assertion statements are based on the information supplied to the classifier about the case given. The top features with significant attributions leading to the decision made above are F6, F26, F32, F42, F43, and F25. Conversely, F38, F24, F14, F28, and F33 are among the features deemed irrelevant to the classification decision here since their contributions are almost negligible and much closer to zero. The attribution analysis suggests that not all the relevant features positively contribute to the classifier's arriving at the verdict here. Those with positive attributions that push the classifier towards generating C2 as the label are F6, F26, F32, F42, F4, F7, F16, and F21. Decreasing the likelihood of the correctness of C2 are the negative features such as F43, F29, F25, F13, F39, F5, F41, and F12, which could be blamed for the little uncertainty in the classification output, as indicated by the prediction probability of C1.\",\n",
       " \"The classification algorithm classifies the given case as C1 with a confidence level equal to 99.99%, suggesting that there is little chance that the C2 label could be the true label. The classification confidence level can be attributed to the influence and contributions of the features F29, F8, F10, F26, and F23. Positively supporting the model's decision are values of F29, F8, F10, and F26. On the contrary, the values of F23, F4, F3, and F7 are shifting the model towards producing the C2 label, which results in a marginal decrease in the certainty associated with the C1 label. The other positively supported features further improving the odds in favour of C1 include F25, F12, F16, and F5. Overall, it is not farfetched to accept that C1 is the correct label for the case under consideration since the strong positive influences of F29, F8, and F10 far outweigh the influence of any of the other input features. In other words, as mentioned above, there is only a small chance that the true label is not C1 considering the attributions of the top influential input features.\",\n",
       " \"The data is marked as C2 by the classifier based on the input features, with a moderate degree of confidence since the prediction probability of the other label, C1, is only 44.0%. The most influential features driving the classification above are F27, F12, F24, F14, F30, F18, F26, F2, F20, F22, F13, F21, F17, F23, F10, F25, F5, F6, and F8. Strongly reducing the chance of C2 being the true label for the given case are the negative features F12 and F27. Actually, these negative features, along with other features such as F30, F18, and F20, are responsible for the uncertainty in the classification decision here. On the contrary, the input features F24, F14, F26, F2, F22, and F13 positively contribute to the classifier's decision to choose C2 as the label here. Finally, it is important to note that not all the features are shown to be relevant when making the labelling decision regarding the case under consideration, and these irrelevant features include F15, F4, F1, and F29.\",\n",
       " \"The model determined that this case belongs to C1 of the three possible labels, with an 83.0% likelihood. It is important to note, however, that there is about a 14.0% chance that it could be C2 and a 3.0% chance that it is rather C3. The most relevant feature driving this prediction is F12, with a very strong positive attribution, increasing the odds of the label C1. The following attributes have values pushing for a different prediction: F11, F4, F7, and F6, however, their attributions are very low when compared to that from F12. Other features positively contributing to the model's decision for this test case are F5, F2, F9, F1, F3, F10, and F8, with F3, F10, and F8 being the least relevant features considered by the model for the given case.\",\n",
       " 'The classifier assigned the label C1, given that there is merely a 2.18% chance that C2 is the correct label. Influencing this classification decision are mainly the values of the variables F5, F12, F11, and F4 which are also commonly referred to as positive variables since they increase the response in favour of the predicted label. Other variables supporting the prediction of C1 are F1, F14, F6, and F8. However, unlike F5, F12, F11, and F4, these variables have a moderate impact on the classifier. The  variables that decrease the likelihood that C1 is the correct label are F3, F2, F13, and F7 since they have values that swing the classification verdict in the direction of C2.',\n",
       " \"Because the chance that C2 is the right label is around 42.17 percent, the example under review is labelled as C1 with a moderate degree of confidence. F4, F1, F7, F15, F6, and F14 have the most influence on the above forecast, whereas F25, F21, F11, F13, F29, F10, and F26 have small contributions. F20, F22, F5, F8, F17, F12, and F24 all have a relatively modest impact. However, the classifier does not take into account all of the attributes while making a judgement in a specific case and the attributes F9, F2, F16, and F23 are all irrelevant features. F4, F1, F7, F6, F21, F29, and F12 are the positive features pushing the prediction in support of the forecasted label. We can see from the attributions map that the bulk of the influential features exhibit negative attributions that reduce the likelihood that C1 is the correct label, justifying the uncertainty associated with the classifier's prediction choice.\",\n",
       " \"All features are shown to have a positive impact on the classification to class C1 or to have no impact at all. F12, F1, F17, and F28 are the four features with the most impact.  Some of the remaining features, in order of feature importance, are F5, F7, F10, F27, F21, F18, F2, F23, F24, F29, F11, and F6. F12 and F1 both have the highest positive impact on the final classification, pushing the classification towards class C1. All of F17, F28, F5, and F7 influence the model's classification to C1. In terms of the features which have a positive impact on the classification, features F10, F27, F21, and F18 are all ranked to have a medium degree of influence on the final classification. F10 and F27 both have a similar importance attribution, which is higher than that of F21 and F18. All the other features not listed above are irrelevant to the decision above and among them are F22, F25, and F30.\",\n",
       " 'Label C2 has a lower probability than label C1, so C1 is the most likely option in this case. C1 has a probability of approximately 96.25 percent, which can be attributed to variables such as F7, F2, F8, and F6. According to the attributions assessment, the least relevant variables are F3, F4, and F9. Inspection of the direction of influence of the features showed that F10 and F1 present negative contributions that push the model somewhat away from producing C1 because they support the label C2. Considering that the combined impact of the negative variables is quite minimal in comparison to the combined impact of the positive variables such as F7, F2, F8, F5, and F6, it is not surprising that the model is very certain that C2 is not the accurate label for the given case.',\n",
       " 'According to the prediction made here, the most likely label for the given case is C2, with a prediction probability of 97.02%, indicating that the prediction probability of C1 is only 2.98%. The classification above is mainly due to the influence of F9, F13, and F5. The next set of features with moderate contributions includes F1, F12, and F6. However, those with little consideration from the classifier are F7, F4, F10, and F15. In consideration of the fact that all the top four features have a strong positive contribution, it is foreseeable why the classifier is relatively confident that the correct label for this case is C2. Additionally, the negative attributes with moderate to low impact are F12, F3, and F16.',\n",
       " 'The classification conclusion is as follows: C1 is the most likely label for this case and the classifier is certain that neither C3 nor C2 are the right labels since their likelihoods are equal to zero. The driving factors for the above classification are F6, F11, and F12, all of which have a substantial positive impact, causing the classifier to select C1. F1, F4, F2, and F9 are also positive features. The assigned label is not supported by all of the input features since the negative features F10, F8, and F3 support the decision that the most likely class for this instance could be any one of the other labels, C2 and C3. Nevertheless, given the confidence level in the aforementioned classification, it is reasonable to assume that the classifier paid little attention to the negative features, resulting in the selection of class C1.  ',\n",
       " 'The classifier states that there is a 50.0% chance that the true label of this test observation is C2. This indicates that the classifier is less certain in its prediction decision regarding the case under consideration. The label assigned is mainly due to the values of the features F9, F6, F4, F1, F2, and F7. The top features, F9 and F6, have very strong positive contributions pushing the prediction higher towards the most probable label. Among the remaining features stated above, F4, F1, F2, and F7, only F7 demonstrates some level of contradiction, forcing the labelling decision in a different direction. Finally, the features with marginal impact on the prediction made here are F5, F8, and F3. While F5 and F3 positively influence the decision made, F8 suggests that the label assigned by the classifier might not be the true label.',\n",
       " 'According to the attribution analysis, the each input variables contributes differently to the decision. For the case under consideration, there are variables that have negative influence on the decision here, but it also has numerous quantifiable variables that are positive. Per the model, C2 is 91.95% certain to be the correct label and C1 has a predicted probability of only 8.05%. The most essential input variables are F1, F7,  F8, and F2, which allow the model to effectively compute the likelihoods across the classes, C2 and C1. F26 and F17 have nearly comparable positive effects, but F15 and F3 have a negative influence, altering the output decision in favour of a different label. The cumulative positive contribution of F26, F1, F2, F4, F19, and F17 was greater than that of F7, F8, F3, and F15, hence the positive variables succeed at improving the predictability odds in favour of the C2 class. Furthermore per the variable attributions, the contributions of F22, F5, F20, and F9 has very little to do with the classification decision since their attributions are negligible and closer to zero than all the above-mentioned variables.',\n",
       " \"Deciding the most probable label for the given case on the basis of the values of the input variables, the classification algorithm's output decision is that:  the probability of C2 being the correct label is 79.78%, the probability of C1 is 20.22%. Therefore, the most likely label is identified as C2 and the attribution analysis shows that all the variables contributed to some extent to the final decision by the algorithm with respect to the given case. The most influential variables are F9, F8, F14, and F7, but F13, F6, and F11 are the least influential ones. The analysis also indicates that F9, F7, F13, and F11 are responsible for the marginal doubt in the classification decision here hence they are commonly referred to as negative variables since their contributions only tend to shift the verdict in a different direction than the assigned label. Finally, the variables such as F8, F14, F4, F12, F2, and F1 are the positive variables that increase the algorithm's response in favour of outputting the C2 label.\",\n",
       " 'The reliability of the classification verdict for this case is 71.57%, implying there is a 28.43% chance that the correct label could be C1. F6 has a significant negative impact on classification output since its contribution contradicts the labelling of the case as C2, hence favours labelling the case as C1. The values F5, F8, F7, F1, F4, F2, and F3 have a positive effect on the results, but still contributes less than the effect of F6. The analysis shows that F6 has an overwhelming negative impact or influence on the predictive decisions of the model here. F8, F7, F1, and F4 have a positive effect on model predictions. Due to the power of the F6 function, all other functions have little effect on the results. In summary, the uncertainty of the predictions can be explained by the control on the model by feature F6, which drags the classification decision favourably towards C1.',\n",
       " \"This model predicted class label C1 with about 93.32% certainty, while there was about a 6.68% chance of the correct class being identified as a different label. Seven features, F30, F5, F33, F10, F11, F9, and F6, have higher impacts on the model prediction decision above. But the feature F30 has the largest positive impact on the result and on the contrary, F33, F11, F9, and F6 show the potential to shift the narrative to a different label since their contributions reduce the likelihood of the predicted label for this case. In addition, features F25, F12, and F15 have moderate impacts on the model's prediction but each of them is increasing the responses, and finally, the features shown have negligible influence include F17, and F3.\",\n",
       " \"Considering the prediction likelihoods, this case is labelled as C2 by the model, that is, the model states that there is about an 83.33% chance that the case is under C2 and about a 16.67% chance that it is not. The most relevant features influencing the decision made here are: F20, F7, F17, and F5. Among the feature set mentioned above, F20 and F7 offer a very strong positive contribution to the prediction of C2. Conversely, F5 suggests the alternative label C1 could be the true label for this case, but this attribution is weak when compared to F7 and F20. Other features that are moderately pushing for this classification decision include F8, F24, F25, and F16. However, the values of F21, F2, F11, and F26 advocate for the assignment of a different label. Finally, the features F6, F4, F14, and F22 have very little impact on the model's prediction for this case.\",\n",
       " \"For the given instance, the model generated the label C1 with a very high predicted probability equal to 99.66% which implies that the model is very confident that C2 is not the correct label. Ranking the contributions of the features to the prediction above, from the most relevant to the least relevant, is as follows: F2, F5, F1, F3, F4, F6, and F7. Among the seven features, only F4 and F6 have negative contributions, pushing the prediction towards the C2 label. However, given that these features have very low contributions, their impact on the model's decision is close to negligible when compared to the contributions of the positive features F2, F5, and F1.\",\n",
       " 'The final prediction given by the model was C1 with almost 100% certainty, showing the model is confident about its decision. F10 had significantly more influence on the prediction than any other feature with F3 and F5 having the next highest attribution values. All the top features, F10, F3, and F5, encouraged the model to output class C1. F2, F12, and F9 are the features that had the least positive impact on the final classification. The features F4, F6, F8, and F11 have moderate impacts, pushing the model slightly away from a C1 classification.',\n",
       " \"Based on the information provided to the classifier, the true label for the given case is likely C1, with a confidence level of 76.26%. Each input variable has a different degree of influence on the classifier's final labelling decision with respect to the case under consideration. Whilst F10, F8, and F7 have lower contributions to the classifier's decision, F16, F15, and F5 are identified as the major contributors resulting in the assignment and classification probabilities across the two classes. There is a 23.74% chance that perhaps C2 is the true label and the features responsible for this are the negative features, F5, F11, F1, F2, F14, F10, and F8. Driving the classifier's decision in favour of C1 are the positive features such as F16, F15, F3, F12, F9, F4, and F6.\",\n",
       " \"According to the model, C3 is the least probable class, while the most probable class for the given case is identified as C2. The top two variables with the greatest control over the model in terms of this case's label assignment are F11 and F4 but on the contrary, the rest of the variables have moderate-to-lower influence. The contribution of F4 is negative, reducing the chances of selecting the label C2. F11, F2, and F1 drive the model to classify the given case as C2. Furthermore, both F7 and F6 have values that increase the predicted probability of C2, but F9 and F3 decrease the model's response in favour of any of the remaining classes. When choosing a label in this instance, the model pays little attention to the respective values of F8, F12, F5, and F10 hence they are the least ranked features.\",\n",
       " \"Judging by the prediction probabilities, the most probable or likely class assigned by the classifier is C1, with the associated confidence level of 90.97%. The features with the most influence on the prediction above include F9, F13, and F14, while the least important features are F10, F3, and F6. Beside some of the features are shown to negatively contribute to the prediction made here and these negative features, F5, F13, F2, F4, and F10, reduce the classifier's response to generating label C1, consequently pushing the verdict towards C2. The joint impact of the negatives is smaller compared to that of positive features such as F9, F14, F8, and F1, hence the greater drive on the classifier to assign C1 as the correct label.\",\n",
       " 'According to the model employed, the label for the case is more likely to be C1. This assessment decision is mainly based on the inpacts of features such as F2, F7, F4, F3, and F8. Among these top features, F2, F7, and F4 have positive contributions to the prediction above, while F8 and F3 are identified as negative features which decreases the likelihood associated with class C1 for this case. Furthermore, the values of F10, F9, F5, and F6 also indicate that the other label, C2, may be the correct label but luckily, the influence of the above-mentioned negative features can be classified as only moderate when compared to F2, F7, and F4. In conclusion, with such a strong positive influence from F2, F7, F4, and F1, it is safe to say that the model is very accurate in its classification judgments, with 100.0% certainty.',\n",
       " \"From the prediction likelihood of each class label, the most probable label for the given case based on the values of its features is C2. The likelihood of C1 is negligible, hence we can conclude that the classifier is very confident that C2 is the correct label.  Analysing the attributions of the input features showed that the most relevant feature with a strong influence on the classifier's decision here is F4. However, the classifier likely disregards the values of the irrelevant features, F6 and F9, when arriving at the classification above.  The confidence level of the classifier employed to make the classification decision above is higher, mainly because the majority of the influential features have positive contributions. Positive features such as F4, F1, and F8 increase the classifier's response higher in favour of C2. F3 and F5 are the main negative features, but compared to F4, their influence on the above classification is very small.\",\n",
       " \"The correct label for the given data instance, according to the machine learning algorithm, is C2 and this is mainly because the probability that C1 is the right label is only about 3.08%.  From the analysis, the ranking of the input features based on their respective degree of influence is F3, F11, F12, F5, F2, F10, F8, F9, F6, F7, F4, and F1. This implies the most relevant features are F3, and F11 whereas F4 and F1 are the least relevant ones.  Given that F6, F7, and F4 are the features that have a negative impact on the algorithm's selection in this case, it's no wonder that it's quite confident in the chosen class. The arguement towards labelling the case as C2 is also supported by the fact that the joint negative contributions of F6, F7, and F4 is very small when compared to that of the top positive features F3, F11, F12, F5, and F2.\",\n",
       " 'Based on the values of the input variables, the prediction model labels the case given as C2 with very high certainty. Specifically, there is only about a 5.59% possibility that C1 is the correct label according to the model. The most influential factors leading to the above prediction decision are the values of F10, F2,  and F14 whereas F9, F3, and F6 are deemed less relevant by the model. In between the two ends (most influential and least influential) are the features such as F15, F8, and F11 with moderate contributions. According to the attribution investigation performed, F10, F8, F11, F4, F5, and F6 have positive contributions, increasing the model\\'s response to favour labelling the case as \"C2\". Conversely, features such as F2, F14, F12, and F15 provide negative contributions, resulting in a small shift toward selecting C1 as the correct class. In conclusion, given that the prediction likelihood of C1 is only 5.59%, it is obvious that the positive features outweigh the negative ones in terms of the considerations they receive from the model, hence the model\\'s decision to assign the C2 label.',\n",
       " 'The data under consideration is labelled as C1 since it is the most probable label, with a prediction likelihood equal to 99.97% therefore classifier employed here is very confident that C2 is not the right label. The top features with the greatest influence on the classifier in terms of the above classification are F13, F2, F19, and F20. Conversely, the values of F1 and F12 have inconsiderable or insignificant influence on the decision made by the classifier. The input features with moderate to low influence but higher than F1 and F12 on the classifier include F10, F14, F3, and F15. The analysis also shows that the majority of the input features have positive attributions, explaining the level of confidence of the classifier as demonstrated by the prediction probabilities across the classes. The positive features increasing the odds of being labelled C1 include F13, F2, F19, F10, F14, F3, and F17. The marginal doubt in the prediction made here could be attributed to the influence of negative features such as F20, F15, F11, and F9. The negative features support classifying the given data as C2, but since their collective influence is smaller compared to that of the positives, the classifier is shifted more towards labelling the data as C1.',\n",
       " 'C1 was the predicted category for the given case and the classifier is shown to be very certain about the above prediction verdict, given that the probability of C1 being the label is about 99.72%. The following five features all contributed positively towards the prediction of the C1 class with increasing levels of impact: F4, F5, F10, F6, and F9. F7 and F2 both had similar levels of impact on the prediction of C1, with F7 having a marginally stronger impact. F7 contributed towards the prediction of C1, while F2 contributed against it, in favour of an alternative label. F3 and F1 are the least relevant features, with very little impact, both with negative attributions, driving the prediction decision or verdict away from C1. From the analysis, only the features, F3, F1, and F2, are shown to have negative attributions, shifting the prediction away from C1. However, the collective attribution of F3, F1, and F2 is very low when compared to that of the positive features, so the classifier is motivated strongly by the positive features, leading to the prediction decision above for the case under consideration.',\n",
       " \"The ML model or algorithm employed here predicted the class C2 with 100.0% confidence level, clearly implying that the case belongs under the class C2 and not C1 since its associated likelihood is 0.0%. Analysis of the contributions of the features indicated that only features F4 and F7 have negative influence, shifting the classification decision away from C2. However, these features are shown to be the least significant ones when it comes to assigning a label to the case under consideration. Therefore, it is a little surprising to see that the model's confidence level is very high with respect to the prediction made here. Among the remaining positive features, F3, and F2, have the strongest impact or influence, increasing the odds of C2 being the label for the case under consideration and the least positive features are F1, F5, and F6.\",\n",
       " 'Judging from the values of the input variables, the label predicted for the case under consideration is C2 with a high confidence level of 98.89%, implying that the probability of C1 being the actual label is just 1.11%. The attribution analysis suggests that F11, F10, and F3 are the most impactful features controlling the label selection. In contrast, F8, F13, and F1 are the least important variables whose values contribute marginally to the label selection. While the variables F11, F13, F6, and F9 contribute towards labelling the given case as C1, the remaining variables such as F10, F3, and F15 strongly support the C2 selection. The variables supporting the assignment of C2 are the positive variables whereas negative variables are those shifting the decision in favour of C1 and are against the C2 labelling decision.',\n",
       " 'There is little to no doubt that C3, among the three classes, is the proper label for this example since its associated predicted probability is 100.0%. F5, F12, and F4 are the variables with the most influence on the labelling output produced here. Furthermore, these variables have a stronger positive influence on the C3 prediction. Similarly, F8, F9, F6, F7, and F10 are some of the variables favouring the selection of C3 as the correct label. F2, F3, and F1, on the other hand, have a negative and opposing impact on the model, increasing the odds in favour of the other labels. When compared to F4, F5, and F12, all of these negative variables have a moderately low impact on the prediction given here. Finally, the lowest ranked essential input variable is recognised as F11, with a very low positive attribution.',\n",
       " 'Here, the model assigned C1 the highest probability, equal to 99.48%, implying that the predictability of C2 is only 0.52%. Per the attribution analysis, only F1 and F9 have negative contributions that decrease the likelihood of the C1 label in favour of the C2 label. F12, F10, F8, and F2 have the highest positive contributions that improve the odds in favour of the C1. The contributions of the other positive features, such as F4, F6, and F7, have moderate contributions, whilst F3, F11, and F5 are the lowest ranked positive features. All in all, the model is very certain that C2 is not the true label, and this highlighted by the fact that the joint negative contribution of F9 and F1 is only marginal when compared with the very strong influence of positive features such as F12, F8, and F2.',\n",
       " 'The assigned label or class by the prediction algorithm is C2, which happens to be the most probable class predicted with a probability of around 56.0%, consequently, there is a 44.0% chance that perhaps C1 could be the true label instead. The classification assertion above is attributed to the contributions of mainly F23, F1, F18, F12, F30, F10, F11, F16, F29, F24, F8, F15, F7, F28, F9, F17, F14, F6, F26, and F25. However, not all of the features are considered relevant when determining the correct label for the given case. F5, F4, F27, and F2 are examples of irrelevant features. Among the influential features, F23 and F1 are regarded as the most negative, dragging the verdict in a different direction, while the top features, F18 and F12, have positive contributions, increasing the likelihood that C1 is the right label here. Actually, the reason for the 44.0% prediction likelihood of C1 can be attributed to the strong negative influence of F23 and F1. The other negative features include F30, F10, and F29, while the other positive features are F11, F16, F24, and F8.',\n",
       " \"For the given case, the model predicts C1 as the label. The probability that the label could be the alternative class, C2, is only about 1.94% which implies that the model is very confident in this classification decision or output. F5 and F1 are the top features pushing for the C1 prediction for this case. Other features with a positive impact on this prediction include F22, F6, F12, F29, and F11. On the other hand, the values of F17, F35, F15, and F14 make up the set of features with negative attributions on the prediction decision above. However, compared to F9, F22, F6, and F1, the features above have a very marginal influence on the model. This might explain why the model is highly confident that the true label is likely C1. Finally, there were some features with insignificant impact on the model's prediction decision for the case under consideration and these include F21, F36, F42, and F13.\",\n",
       " 'The predicted likelihood of C1 based on the information supplied to the model is 51.62%, whereas there is a 48.38% likelihood that C2 is the correct label. The uncertainty of the model in terms of this case or instance can be attributed mainly to the direction of influence of the variables F5, F2, and F8. Decreasing the chances of C1 being the correct label are the variables F5, F8, F7, and F4. While F5, F8, and F7 have strong negative attributions, F4 is the least negative variable. Increasing the likelihood of C1 prediction are mainly the variables F2, F1, and F9. The features F3, F6, and F10 also have a weak positive influence on the classification decision arrived at by the model for this case under consideration.',\n",
       " 'In this case, the classifier indicates that there is a 99.50% chance that the C1 class is the true label, so it is correct to conclude that the classifier is not sure that C2 is the correct label for the case here. According to the study, five input variables contradict the label choice, while four variables support the classification made above. The variables that contradict the prediction are known as negative features while positive features are those that support the classification verdict. F1, F2, F7, F8, and F5 are the negative variables that reduce the likelihood of C1 being the correct label. F3, F6, F9, and F4 are the positive variables that increase the likelihood of C1.',\n",
       " 'Considering the values of features such as F9, F8, and F11, the model is very certain (about 99.65% certain) that C1 is the right label for the given case. While F9, F8, and F11 are the most important features, the model paid little attention to F1, F5, and F7 when deciding on the appropriate label here.Overall, driving down the odds of C1 are the negative features F11, F6, F3, and F5, which are shown to support the other label. However, the very high confidence in the above-mentioned decision is chiefly attributed to the positive contributions of F8, F9, F10, F4, and F2.',\n",
       " 'With a certainty of 100.0%, the model labels this case as C2 and from the predicted likelihoods across the classes, it can be inferred that the model verdict is that there is a zero chance that the case is under C1. The most significant feature is F1, while the least important attributes are F8, F7, and F3. The moderate features are F4, F9, F6, F5, and F2, ranked in order of their respective attributions on the label predicted. With regards to the direction of influence of each feature, some of the input features have positive attributions in favour of the assigned label and increasing the response of the model in favour of the C2 label, while the remaining ones contradict. F1, F6, F5, and F8 are the positive features, while F4, F9, F2, F7, and F3 are the negative ones, shifting the prediction verdict in the direction of C1.',\n",
       " \"The case under consideration can be labelled as either C2 or C1 or C3, and based on values for features such as F1, F6, F12, F4, and F5, the model labelled this test case as C2 with a confidence level equal to 62.29%. However, there is a 28.41% chance that the label could be C1 and a 9.3% chance that it could be C3. All the features used to make the prediction decision have different influences on the model with respect to this test case. That is, while some features positively support the prediction, others have values suggesting any of the alternative labels could be the true label. According to the analysis, F1, F12, F6, and F4 are the top features with the highest impact on the prediction made. The features F1, F12, F4, and F6 are the top attributes positively supporting the prediction of C2. In contrast, F5 and F11 are the features with the most negative attributions, pushing for the prediction of an alternative class. Further decreasing the likelihood of C2 are the features F10, F9, F3, and F8, which all negatively contribute to the model's final decision with respect to the given case. Finally, features F2 and F7 are shown to be less relevant, with positive contributions to the above classification.\",\n",
       " 'Tasked with labelling a given case as either class C1  or class C2 , the model assigns C1 as the most probable true label, with a confidence level of approximately 99.90%. This confidence level suggests that the probability of C2 being the correct label is only 0.10%. Attribution analysis conducted indicates that all the variables have a different degree of influence or contribution to the model arriving at the above mentioned classification verdict. The features responsible for the very high certainty of the model with respect to the case under consideration are F2, F6, F3, and F1. Actually, the only input variables with a negative contribution also happen to be the least relevant variables, F4 and F7.',\n",
       " \"Even though there is moderately high confidence in the assigned label, the prediction probabilities across the two classes indicate that C1 could be the correct label for this data instance.  The variables with primary contributions resulting in the labelling decision above are F3, F2, F5, and F4. As per the attribution analysis, the top two variables, F3 and F2, have a negative impact, influencing the classifier to label the given data as C1 instead of C2. The only other negative variable is F6, with moderate influence compared to the other two negative variables. On the other hand, there are many variables, specifically F5, F4, F8, F1, F7, and F9, that positively support and influence the classifier to assign C2. To a greater degree, the level of uncertainty with respect to this classification instance could be explained away by just looking at the negative variables' fairly strong pull on the classifier towards C1.\",\n",
       " 'According to the classification model employed here, there is a marginal chance that the true label for this test example is C1. Undoubtedly, the model estimated that the likelihood of the true label being equal to C2 is 99.92%. The above prediction decision is based on the influence of features such as F3, F1, F2, F5, and F7. All these features have significant positive support for the prediction decision here, with the top features being F1 and F2. Furthermore, the features with a moderate influence on the prediction of C2 are F6, F8, F9, and F4. While F4 positively supports labelling the case under consideration as C2, the features F6, F8, and F9 indicate otherwise. Finally, the features with marginal impact are F10, F12, and F11.',\n",
       " 'Considering the values of the features, the prediction from the model for the case under consideration is C2 and this labelling decision is not 100% certain given that there is a 27.27% probability that it could be C1. For the case under consideration, the assigned label is mainly due to the values of the features F3, F9, F7, and F2 while the least important is F1. The direction of the contributions of the relevant features is summarised in the following sentences: F3 and F9 have a very strong joint positive contribution in favour of class C2 coupled with moderately positive input features F7, F2, and F4, however unlike them, F1 has a very low positive impact on the model for the case here. All of F6, F10, F8, and F5 have a negative impact on the prediction made here, however, their pull is not enough to shift the prediction in the direction of the other class label, C1.',\n",
       " \"For this case, the classification model's confidence is only about 69.40%, implying that the likelihood of label C2 is about 30.60%. According to the classification attribution analysis, F1 and F2 are the most relevant features, whereas F4 and F6 are the least influential. When the attributions of the features were carefully analysed, only F8, F5, and F7 are identified as negative features since their contributions drive down the prediction likelihood of the assigned label, C1. Conversely, F1, F2, F3, F4, and F6 have a positive influence on the model in support of labelling the given case as C1 instead of C2.\",\n",
       " 'The model prediction for the test case is C2 and the confidence level of this prediction decision is 91.36%, while the predicted probability of C1 is only 8.64%. According to the attribution analysis, we can see that the features F10 and F8 have negative attributions, pushing the prediction decision towards the alternative label, C1. Conversely, the F9, F13, F1, and F2 have values with a positive impact, shifting the classification decision towards label C2. Furthermore, while the attributes F14 and F15 contradict the prediction made, F6 and F12 have values that support the prediction from the model for the test case under consideration. Finally, F7, F3, F5, and F4 are the least ranked features, and among them, only F4 has a negative influence that contributes marginally to the shift away from labelling the case as C2.',\n",
       " 'In summary, the model predicted an 87.14% likelihood of the class label C2 for the test example under consideration, therefore, there is a chance of about 12.86% that the correct class label could be a different label. The features with the highest impact on the model are F7, F3, F4, and F10, whose values are attributing most to the labeling decision here and among these features, only F10 shows the potential to shift the narrative toward a different label. On impact comparison, features F7, F3, F4 and F10 have higher impact on the model prediction than F5 and F9. Features F7, F3, F4, F5, and F9 show a positive impact shifting towards the prediction of C2. F10 is the most negative of all the set of features passed to the model, F1, F8, and F6 have moderate negative influence, whereas the feature F11 has very little negative impact on the prediction.',\n",
       " \"Mainly based on the values of the features F23, F13, F24, and F30, the model classifies the given case as C1 with a prediction confidence level of 90.15%. This means that there is only a 9.85% chance that the correct label could be C2. The features that positively contribute to the prediction include F23, F30, F43, and F18, since their influences increase the model's response in favour of assigning the label C1. On the flip side, features dragging the final decision higher towards C2 include F13, F24, F27, and F21, since their values contradict the assigned label here. Finally, the prediction was made with less emphasis on the values of features such as F4, F26, F7, and F25, given that they are shown to have very close to zero influence.\",\n",
       " '90.58% it the predicted chance that C2 is the correct label for the given case, indicating that the predicted probability of C1 is only 9.42%. Per the feature-attributions, the top-ranked features are F12, F7, and F6, whereas the smallest important or least ranked features are F3, F11, F10, and F9. The influence of intermediate input features like F4, F5, and F2 is considered moderate. The features with positive contributions to the classification above are F6, F5, F3, and F11, while on the other hand, all the remaining features are shown to negatively contribute to the decision above. The main negative features that decrease the probability that C2 is the true label, considering the likelihood of label C1 for this case, are F12, F7, and F4.',\n",
       " \"The most likely label for the given scenario, according to this prediction, is C1, which has a prediction probability of 97.02 percent, whereas C2 has a prediction probability of just 2.98 percent. The impact of F14, F7, and F1 is mostly responsible for the aforementioned classification. F13, F12, and F17 are the following groups of features with moderate contributions. F16, F9, F2, and F8, on the other hand, receive minimal attention from the classifier. Given that all four top features have a substantial positive contribution, it's easy to see why the classifier is quite certain that C1 is the correct label in this case. F12, F11, and F6 are also negative features, having a moderate to low influence.\",\n",
       " 'According to the prediction algorithm employed here, the most probable label for the given data instance is C2. The confidence level associated with the prediction decision above is 64.62%, meaning there is about a 35.38% likelihood that C1 is the right choice.  The input features can be ranked according to their respective degrees of influence in decreasing order as follows: F4, F3, F1, F8, F2, F9, F5, F7, and F6. Therefore, when classifying the given case, the algorithm places little emphasis or consideration on the values of F3 and F4,  however, the values of F7 and F6 are the most important here.  F6, F9, F5, and F1 are regarded as negative features since their contributions decrease the likelihood of C2 being the correct label. However, positive features such as F7, F8, and F2 drive the algorithm higher towards assigning C2 to the case under consideration here.',\n",
       " 'The true label has a 50.0% chance of being one of the two classes and based on the predicted likelihoods mentioned above, it can be concluded that the model is very unsure about the correctness of the classification. The above prediction decisions are mainly influenced by the features F2, F3, F4, F1, F5, and F7, while the least important are F8, F6, and F9. Overall, since the predicted likelihood is evenly split between the two classes, it can be concluded that the model is very uncertain as to which label is the right one. The variables with contributions that support the assignment of C2 include F2, F5, F6, and F9, but on the other hand, the ones with contributions towards the assignment of C1 are F3, F7, F4, F1, and F8. With respect to the assignment of the C2 label, F3, F7, F4, F1, and F8 are the negative variables, while F2, F5, F6, and F9 are the positive variables.',\n",
       " 'The model is assigned the label C1 for the given example. F10, F2, and F4 are the most important features that influence the above-mentioned estimate decision, however unlike them, F6, F1, and F11 are less important. The majority of features have values that swing the judgement towards the other label, C2. The only input features that increase the likelihood that C1 is the correct label are F10, F5, and F1, therefore it is very surprising that the model has 100.0% confidence in its estimate for the given example.',\n",
       " 'Since the probability that C2 is the correct label is only 2.18%, the classifier assigns the label C1 in this labelling instance. The main factors influencing this classification decision are the values of the variables F4, F11, F9, and F7. From inspecting the direction of influence of the above-mentioned variables, they can be referred to as the positively contributing variables because they increase the response of the classifier, increasing the odds in favour of the assigned label, C1. Other positive variables that support the prediction of C1 are F2, F10, F6, and F8, however, unlike the top positive ones, these variables have only moderate control on the classifier. Just four of all the input variables are shown to reduce the probability that C1 is the correct label and these variables are F3, F1, F12, and F5 since their respective values cause the classification judgement to shift in the direction of C2. In summary, given that the confidence level in the C1 prediction is 97.82%, it is obvious that the negative contributions of F3, F1, F12, and F5 result in only a marginal decrease in the certainty or confidence level.',\n",
       " 'The selected case is labelled as C2 with close to an 85.0% confidence level, hinting that there is a smaller chance that it could be C1. The most important variables when determining the label for this case are F15, F13, F42, and F21. The variables with moderate influence include F10, F25, F11, and F27. However, the last three ranked variables according to their respective impacts on the model for the case under consideration are F38, F41, and F35. Significantly increasing the odds of the predicted label are the variables F15 and F42. Conversely, the F13 has the strongest impact, driving the classification verdict towards C1. Other features with similar direction of influence as F13 are F17, F11, F30, F12, and F16.',\n",
       " 'The probable label for the given case is C1 since its associated predicted probability is 91.85% compared to the 8.15% of C2. The input variables mostly responsible for the above prediction verdict are F11, F10, and F6, however, the values of F8, F14, and F3 are deemed less relevant by the model in this case. The attributions of the input variables can be either positive or negative, depending on the direction of influence on the model. Among the variables, the ones with negative attributions that decrease the probability that C1 is the correct label are F5, F4, F1, F8, F14, and F3. On the contrary, F11, F10, F6, F9, F7, F13, and F12 are some of the remaining variables that increase the likelihood of C1 being the correct label. Based on the attributions of the variables, we can conclude that the collective impact of the negative variables is not strong enough to shift the prediction verdict away from C1, resulting in only a marginal uncertainty in the assigned label.',\n",
       " \"The classification verdict of the model for the case under consideration has a 50.10% chance of being C1. But based on the estimated likelihoods indicated above, it is possible to deduce that the model is extremely doubtful about the classification's validity. The following variables have the most attributions to the aforementioned prediction decisions: F1, F6, F2, and F9. F8 and F5 are the least important, whereas the values of the variables F4, F7, and F3 had only a moderate impact. Regarding the direction of influence of the variables, F1, F7, F8, and F5 are the ones driving the classification higher towards the C1 label and away from C2. However, factoring the likelihood of the C2 label, the negative variables, F6, F9, F2, F4, and F3, successfully cast doubt on the validity of the assigned label. In simple terms, the negative contributions from F6, F9, and F2 can easily explain the uncertainty associated with the class label assignment for the case under consideration here.\",\n",
       " 'The algorithm classified the given data as C2 with close to 99.32% certainty since the prediction likelihood of C1 is only 0.68%.  The abovementioned prediction verdict is largely due to the influence of F10, F2, and F1 while the other influential features include F7, F3, and F4. However, F5, F8, F9, and F6 are shown to have smaller contributions to the decision made here.  Not all the features have positive contributions, and F1, F3, and F4 are known as negative features since for the given case, they reduce the likelihood of the assigned label and hence they favour or support labelling the case as C1 instead.',\n",
       " \"The model is quite certain that C1 is the most likely class for the current scenario. C1 has a 90.48% chance of being correct, implying that any of the other labels is highly unlikely. F10 and F4 are the most relevant variables influencing the abovementioned classification decision but all other factors or variables are proven to have a moderate or minor influence. Fortunately, the top variables, F4 and F10, have an impact on the model that is positive, boosting the chance of C1. Furthermore, whereas F1 and F5 force the model to forecast C1, the variables F8, F11, F9, and F6 are forcing the model to assign a different label. Finally, several variables have a very minor influence on the model's final forecast here, but F12, F9, and F6 are shown to have the least contributions.\",\n",
       " 'The label assigned by the model is C2 with a higher predicted confidence level of 99.99%, meaning the probability of C1 being the correct label is virtually equal to zero. The classification decision above is mainly due to the influence of the features F5, F3, F8, and F4, however, the remaining features have very marginal contributions to the decision. Among the features, only F1 and F6 are shown to have a negative impact, reducing the likelihood of the assigned label. However, this negative influence is very weak compared to that of the top positive features, F5, F3, F8, and F4.',\n",
       " \"With respect to the given case, the classification algorithm employed here generates C1 as the most probable class since the probability of C2 is 41.63% while that of C1 is 58.37%. F1, F7, and F4 are the most influential features resulting in the classification decision mentioned above, whereas the least relevant features are F2 and F5. As indicated by the prediction probabilities across the classes, the confidence in the labelling decision here is not perfect, which can be attributed to the influence of the negative features F1, F7, F4, and F8. On the other hand, the moderate positive influence of F3, F6, F9, F2, and F5 explains the algorithm's decision to label the case as C1 with such an average level of confidence.\",\n",
       " 'The most likely label for the provided data instance, according to the predictive algorithm used here, is C1. The confidence level associated with the above prediction decision is 64.62 percent, which means C2 has a 35.38 percent chance of being correct. The following input features can be prioritised in decreasing order according to their relative degrees of influence: F3, F7, F2, F6, F4, F1, F8, F9, and F5. As a result, the algorithm places little emphasis or attention on the values of F7 and F3 when classifying the given case whilst the values of F9, F8, and F5 are the most relevant. Regarding the direction of influence or impact of the input features, F5, F1, F8, and F2 are considered negative features because their contributions reduce the likelihood of C1 being the correct label. Positive features such as F4, F6, and F9, however, push the algorithm closer to assigning C1 to the situation in question.',\n",
       " 'C1 is the label predicted by the classifier for the case or example under consideration the confidence in the above prediction is about 96.35%. It is important to take into consideration, however, that there is also a very small chance equal to 3.65% that the correct label could be C2. The ranking of the features according to their respective contributions to the decision above is as follows: The top features with significant influences are F9, F19, and F1. The remaining features with moderate contributions are: F8, F15, F13, F18, F4, F6, F12, F20, F7, F10, F5, F2, and F16. Finally, the values of F14, F17, F11, and F3 are shown to have a very low impact on the prediction of C1 for the case under consideration. The assessment below only considers the features shown to have the most relevant impact in terms of the direction of the prediction here. Among the most contributing features, only F8 and F15 have a negative influence, while the remaining ones, F9, F19, F1, and F13, are shown to have positive contributions to the prediction for the case. Looking at the cumulative influences of each set of positive and negative features, it is not strange that the label assigned is C1 with a confidence level of 96.35%.',\n",
       " \"The model predicted the C1 class with very high confidence of 93.27%, hence we can conclude that there is only a 6.73% chance that the true label is C2. Two features have a very strong positive influence on the prediction of the C1 class and they are F7 and F3. The following features have a medium impact and are listed in decreasing order of influence: F5 and F12 have a negative influence, while F11 and F1 have a positive influence on the prediction of C1. F1, F8, and F14 have a positive influence on the prediction of the C1 class, while F4, F9, F13, and F2 influence the prediction negatively. Those with the least contribution regarding the model's decision for this case are shown to be  F10, F16, F14, and F6. Among these least contributing features F10 and F6 are shown to have negative contributions whereas F14 and F16 contribute positively in favour of the assigned label.\",\n",
       " 'This case or instance is labelled as C1 with a very high confidence level, however, the classifier estimates that C2 could be the correct label with a prediction likelihood of about 5.75%. The values F9, F3, and F1 played a major role in the aforementioned labelling choice and because F4 and F8 have minimal attributions, they are the lowest rated features. F3 and F9 have values, which increases the probability that C1 is the correct label. Other variables that drive the clasifier towards assigning the predicted class are F2 and F6. Here, F3, F6, F9, and F2, are referred to as positive input variables since their contributions are towards the generated C1 label. In contrast, the remaining six variables are shown to have a negative influence on the classifier, indicating that the correct label could be C2 instead of the C1 selected by the classifier and the strongest negative variables are F1, F7, and F10.',\n",
       " 'The prediction likelihood of class C1 is 73.85%, making it the most probable label for the given case. When making the above prediction, the input features are shown to have some degree of influence on the decision made by the classifier. While features such as F16, F25, and F19 have very low contributions to the classification, the features F22 and F26 are shown to be the main contributors to the decision. Finally, the features with moderate contributions are 21, F11, 42, F18, F12, and F10. As indicated by the prediction likelihoods across the classes, the classifier is shown to have a little doubt in the correctness or validity of C1, and the main features resulting in this little uncertainty are the negative features F22, F13, F10, F12, F5, F6, and F24. However, the values of F26, F11, F14, F18, F4, and F15 suggest that C1 is very likely the true label.',\n",
       " \"According to the model, the probability of C2 is 12.35% and that of C1 is 87.65% meaning C1 is the most probable label for the given case. The variables with the majority influence on the abovementioned decision are F25, F3, F12, F8, F20, and F21 whereas variables F16, F23, F4, F9, F6, and F26 are shown to have little to no influence on the model's decision with respect to the given case. The contributions and influence of variables such as F19, F1, F24, and F17 can be described as moderate.  Among the variables controlling the prediction decision here, F25, F20, F1, F17, F15, F7, F22, and F14 are the negative variables decreasing the model's response to the output of the label C1. Conversely, the highly influential variables F3, F12, F8, and F21 are the main drivers that contribute positively, increasing the probability of C1 being the correct class label. Overall, given that the variable with the highest influence on the model is F25, a negative variable, it is not unexpected that there is a little doubt in the classification decision here, as shown by the prediction probabilities across the classes.\",\n",
       " 'With a moderately high level of confidence, C1 is assigned to the given case by the classifier and this is due to the fact that the other classes, C3 and C2, have likelihoods of 3.0% and 14.0%, respectively. Across the input features, only F11, F3, F9, and F12 are shown to contribute negatively, shifting the classification away from C1 and towards C3 and C2. On the contrary, the features such as F5, F6, F4, and F2 are among the positive set of features that drive the verdict in support of assigning C1 to the given case. From the attributions of the different features, F5 is the most relevant contributor to the classification made here, while F8, F10, and F7 are ranked as the least influential features and considering the direction of influence of each input feature, it is understandable why the classifier is certain about the decision made.',\n",
       " \"Considering the values of the input variables, the classification model is very confident that the most probable label is not C2 but C1. The top input variables receiving much consideration from the model to arrive at the classification verdict are F38, F28, F31, F15, and F22. Among these most influential variables, F38 and F28 are regarded as negatives since their contributions serve to swing the classification decision in the opposite direction. On the contrary, F31, F15, and F22 have a positive influence, increasing the model's response to favour labelling the given case as C1. Other positive variables include F17, F14, and F13, whereas the other negative ones include F26, F9, and F6. Input variables such as F7, F29, F21, and F36 are shown to have zero attributions, that is, their values are not paid enough attention to influence the model's decision with respect to the given case.\",\n",
       " \"The odds are in favour of label C1 given that the probability of it being the correct label for the case under consideration is 81.32%. However, the likelihood of label C2 is 18.68%. The classification decision above is mainly due to the values of F8, F12, F9, and F5. The feature with the least attribution to the model's output label here is F6. The features F8, F9, and F12 have very strong positive contributions to the prediction, increasing the odds of the label C1. Other features with positive attribution in support of C1 are F7, F4, and F11. Unlike the features stated above, the remaining features, F5, F10, F2, F1, F3, and F6, have values that shift the final prediction verdict in the direction of C2 and account for its 18.68% likelihood.\",\n",
       " 'The model predicted C2 with a high probability equal to 88.70%, whereas C1 has only a 11.30% likelihood of being the true label. Considering the predicted likelihood of C1, there is only little confidence in its correctness as the true label for the case here. The value of F4 has a large negative influence on the C2 classification decision, while F8 is the top positive feature. F1, F5, F3, and F2 all have positive impacts on the C2 prediction, with F1 and F8 having the highest influence, F3 and F2 having low influence, and F5 being somewhere in the middle. Broadly speaking, the negative influences of F4, F6, and F7 only succeed in driving the decision slightly away from C2 towards the other label as shown by the predicted probabilities across the classes.',\n",
       " \"The algorithm's predicted output label for the given case is C2 with a very strong confidence level equal to 100.0%; hence C1 can't be the true label. Among the features, the most relevant ones are F3, F6, and F8 with very significant impact, pushing the prediction decision away from C1 towards C2. The next set of attributes, F9, F2, and F5, offer a moderate shift towards C2 coupled with marginal positive contribution from F4 and F1. From the above statements, all the features are shown to support the label assignment decision in the case under consideration. Consequently, it is no wonder that the algorithm has 100.0% confidence in the output decision or verdict above.\",\n",
       " \"In this case, the prediction algorithm is not 100.0% certain that the correct label for the given case is C2, since there is a 43.49% chance that the right label could be C1 instead. The algorithm's decision to label the case as C2 mainly stems from the influence of features such as F1, F12, F15, F3, and F14. On the other hand, little consideration is paid to the values of the least ranked features, F9, F6, and F7. Within the top-ranked features, F14 and F3 have a negative impact, increasing the prediction probability of label C1. Further decreasing the likelihood of the C2 class are the negative features are F2, F11, F16, and F7. However, all the remaining features strongly or moderately push for the classification output to be C2 and the notable positive features are F1, F12, and F15. Considering all the features' attributions, the uncertainty or doubt in the classification could be attributed to the algorithm's paying too much attention to the values of the negative features.\",\n",
       " \"Mainly based on the information on the case given, the classifier's output decision is as follows: C1 is the most probable label, followed by C3 and C2, with C2 being the least. To be specific, the prediction probabilities across the classes are as follows: C2 has 4.34%, C3 has 21.64%, and C1 has 74.0% chance of being the true label. The moderately high classification confidence is largely due to the impact of F3, F1, and F9. However, the values of F4 and F2 received very little consideration when the classifier was picking the most probable label for the given case. With respect to the direction of influence of the features, F3, F1, F10, F6, and F2 have varying degrees of positive contributions, driving the classifier to label the case as C1. On the contrary, F9, F12, F8, and F11 are among the negative features, shifting the classification decision in a direction away from C1.\",\n",
       " \"The model predicted C1 for the case under consideration which a predicted likelihood of 67.95% whereas, that of C2 is 32.05%. The top influencing features ordered from highest to lowest, are F9, F8, F6 and F1, and among them only F6 is shown to have positive attribution in support of the model's decision. F5, F10, and F3 have a smaller positive influence on the prediction, while F4 has an even smaller negative impact. F7 is the least relevant feature, and hence its negative attribution has very little influence on the model for this case.\",\n",
       " \"The case under consideration is labelled as C1 by the model employed for this classification problem. However, according to the model, there is a 45.34% chance that C2 could be the label, presenting some level of uncertainty in the classification verdict made here. F7, F15, F8, F16, F2, and F1 are the top features identified as very important to the model's decision, whereas those with negligible contributions include F33, F10, F25, F13, and F4. Across the input features, those with a negative influence that motivates the classification output to be C2 are mainly F15, F5, F16, and F21. The other negative features contributing to the predicted likelihood of C2 are F9, F17, F26, and F20. Contradicting all the negative features and motivating the prediction output to be C1 are the positive features F7, F8, F1, F2, F28, F19, and F23. In conclusion, it is very surprising to see that the confidence level of the C1 prediction is only 54.66% given the very strong positive contribution of F7, but one can say that the negative features successfully cast doubt on the decision with regards to the case under consideration.\",\n",
       " \"With a certainty level of 82.07 percent, the label choice for the given case is C2 and in a nutshell, the likelihood of C1 having the correct label is only 17.93%. The contributions of features like F30, F33, F38, and F36 are largely responsible for the classification above. The following three, with modest impact, are F23, F28, and F5. However, while choosing the proper label for a given case, the classifier does not consider all of the features. F39, F35, F20, and F14 are notable but insignificant features. F30, F33, F38, and F36 are the top features, with considerable positive contributions supporting the assignment of label C2. F23, F28, F10, and F40 are the top negative features that cause the classification to swing in a different direction. To bring things into perspective, due to the fact that the bulk of important attributes have positive attributions, it's not surprising that the classifier is confident that C2 rather than C1 is the correct label.\",\n",
       " 'C2 was predicted with a high degree of certainty by the model since the likelihood of the alternative class is only 11.30%. The value of F8 has a significant negative impact on the classification choice, whereas F6 has a moderately positive contribution. F4, F3,  F7, and F1 all have a favourable or positive impact on the C2 prediction, with F1 having the most positive impact, F3 and F4 having the least, and F7 being in between. F2 and F5 have a minor negative influence on the class assignment here, which together with F8 contributing to the decrease in the liklihood of C2.',\n",
       " \"With a higher level of certainty, the algorithm labels the given data or case as C2 because the predicted probability of class C2 is 99.93% while that of class C1 is only 0.07%. C1 is therefore less likely than C2 and the classification assertion or decision here is chiefly attributed to the impact of input features such as F16, F6, F39, F35, and F32. Among these relevant features, only F32 has a negative contribution, mildly dragging the verdict in favour of C1, whereas conversely, F16, F6, F39, and F35 have strong positive contributions in support of assigning C2 to the given data. Other features with moderate influence on the algorithm's verdict here include F3, F33, F10, F21, F22, F19, F24, and F4. However, some of the input features  are shown to have negligible contribution to the abovementioned classification output and in fact, these include F1, F27, F30, and F9. In summary, the most vital features with respect to this classification instance are F16, F39, and F6 with positive contributions strongly increasing the algorithm's response towards label C2 hence the 99.93% predicted probability.\",\n",
       " \"There is uncertainty about the correct label for the given example since both labels, C2 and C1 are shown to have a 50.0% chance of being correct. The prediction decision above is mainly attributed to the influence of the input features F1, F8, and F6, while F4, F2, and F5 are deemed less important to the decision above. Looking at the direction of influence of each input feature, only F8, F8, F4, and F5 are shown to have a positive contribution, increasing the model's response towards assigning C2. All the remaining six features have a negative contribution towards the decision here, supporting the assignment of the other class.\",\n",
       " 'The classification model assigned the label C2 to the given example and given that the confidence level is 100.0%, we can be certain that the chances of C1 being the true label are negligible. The most relevant features controlling the prediction decision above are F4, F5, and F3. F9, F6, and F1 are among the least relevant features. Most of the properties have values that sway the decision towards the other C1 class. The only features that increase the odds that C2 is the correct label are F4, F10, and F6. It is strange that the model has 100.0% confidence in its prediction for the selected sample, given that only a small number of the input features contribute positively to reaching the C2 estimate.',\n",
       " \"The model prediction for the test case is C1 and the confidence level of this is almost 100%. From examining the contributions of variables or attributes, the values of F6 and F13 push the prediction verdict in favor of the other label. On the contrary, F10, F14, F4, and F8 have values with a positive influence that biases the classification decision towards label C1. While attributes F5 and F12 contradict the prediction made, F15 and F2 have values that support the model's prediction for the given case.\",\n",
       " 'The label predicted by the classifier is C1 at a 71.80% confidence level. On the other hand, there is a 28.20% chance that C2 could be the label. The prediction can be mainly attributed to contributions from F38, F59, F47, and F27. Considerable positive contributions to the prediction here are from F38, F27, F52, and F59 since their values support the prediction of C1. Shifting the prediction towards C2 are the negative features F47, F16, F75, F13, and F32. There were some features with minuscule influence on prediction decision made for the case under consideration; these include F17, F54, and F6. In simple terms, the classifer deems the values of these features less important when assigning the label here.',\n",
       " \"The model, making a classification decision based on the input variables, predicts the class C2 label for this case with a predicted likelihood equal to 54.21%. It also shows a 45.79% probability that C1 is the correct label. The classification decision made above is primarily influenced by the variables F2, F4, F1, F8, and F10. The three most influential variables, F2, F4, and F8, have a negative impact since their values are shifting the labelling decision in the direction of C1 instead of C2. Positive variables are F10, F1, F11, F7, and F6, supporting the model's class assignment decision for this situation and one can conclude that it is the influence of the positives that motivates the decision towards C2.\",\n",
       " 'Based on the values of the input features, the classifier believes that the most probable label for the given data is C2, due to the fact that there is only a 19.30% chance that it could be C1 instead. The most influential features resulting in the decision or judgement above are F9, F24, F14, F6, F3, F30, and F22, though features such as F12, F31, F19, and F5 are indicated to have negligible contributions to the classification. Actually, the high certainty of the chosen label can be attributed to the very strong positive influence of F9 and the moderate positive influence of F24, F14, F11, and F6. Conversely, the negative features F30, F22, F3, and F18 reduce the likelihood of C2 since their values support labelling the case as C1.',\n",
       " \"According to the classification algorithm with a very high confidence level, the correct label for the given data instance is C2.  This prediction decision is heavily influenced by features such as F1, F6, F2, F10, F13, and F9. Among these top features, the only features with a negative contribution towards the assigned label are F9 and F13. With respect to the given instance, their negative contributions decrease the algorithm's response in favour of the least probable class.  F5, F3, F11, F12, and F8 positively support the assignment of label C2. Conversely, F7 and F3 have a similar direction of influence as F13 and F9.\",\n",
       " 'For the given data instance, the most probable class according to the classifier is C2 since the probability of C1 being the correct label is only about 10.0%.  The most influential features resulting in the prediction decision above are F8, F1, and F7 which are shown to negatively contribute to the decision above since they strongly push the classifier towards assigning a different label.  F5, F9, and F4 are shown to be the only features to positively contribute to the classification made here. Aside from the positive features, all the others negatively reduce the odds of the given data instance having C2 as its label.',\n",
       " 'Judging based on the information about the given case, the model outputs C1 with a prediction probability of 74.72%, however, it is vital to keep in mind that there is also a 25.28% probability that C2 could be the true label. The attribution analysis shows that all the input variables have varying degrees of influence on the model as it arrives at the abovementioned decision and the influence of the features can be ranked from the most relevant to the least relevant as follows: F5, F1, F3, F7, F6, F4, and F2. Across the input features, only F1 and F7 have negative attributions, reducing the likelihood of the predicted label which explain the 25.28% predicted likelihood of the C2 label. Therefore, F5, F3, F6, F4, and F2 are the positive input features pushing the decision higher towards C1 and away from C2.',\n",
       " \"The data is labelled C2 by the model as it has a somewhat greater prediction chance than C1. F6, F5, F10, F13, and F28 are the input variables that have the most impact on the above classification choice, whereas F14, F19, F30, F9, and F12 have the least influence. F6, F5, F28, and F13 are basically supporting the choice of the label in this scenario while on the contrary, F10, F18, and F1 are the primary negative factors. It's not unexpected that the model isn't 100 percent sure of the assigned label considering the degree of influence as well as the direction of influence of the variables.\",\n",
       " 'Although the case under consideration has variables with a significant negative impact, it also has many measurable variables that are positive, so there is a good chance that C1 is correct since it has a 91.95% certainty. F15, F2, and F6 are the most important input variables, thanks to which the model successfully assigns the selected label, C1. F22 and F19 have almost identical positive impacts, while F4 has negative effects, shifting the output decision in favour of a different label. However, the cjoint positive contributions of F22, F15, F6, and F19 was higher than that of F2, F9, F18, and F4, increasing the likelihood of the C1 class. Unfortunately, the values of the variables F17, F26, F5, and  F1 are likely ignored since their attributions are much closer to zero.',\n",
       " 'The classification output observations that follow are based on the information supplied about this specific case. The class label in this case is forecasted to be C3 out of the four possible labels, with a probability of around 83.08 percent. With a probability of 16.87 percent, C2 is the next most likely label. The third possible label, C1, has a 0.05 percent chance of being correct. The algorithm, on the other hand, confirms that C4 is unlikely to be the correct label. According to the attribution analysis, F4, F3, F1, F5, F6, F2 is the ranking of the input features based on how powerful their effect on the algorithm is. Furthermore, among the input variables, F4 and F5 exhibit negative attributions, causing the decision to be shifted away from label C3. Finally, F3, F1, F6, and F2 are the positive variables that sway the judgement in favour of C3.',\n",
       " 'The model predicted class C2 with a very high confidence level of 93.27% and looking at the predicted probabilities across the label, there is only a 6.73% chance that C1 is the true label. There are two features that have a very strong positive effect on the prediction of class C2 and these are F12 and F4. The following features have moderate impact and are listed in descending order of impact: F16 and F9 have a negative impact, while F3 and F8 have a positive impact on the prediction of C2. In addition, both F5 and F10 had a negative effect on the model, further decreasing the odds of C2 being the true label for the given case. Finally, in terms of model decisions for this case, the features with the least contributions are F14, F1, F11, and F6.',\n",
       " 'Between the three possible classes, there is a 100% certainty that the correct label for this case is C3. The features with a very high impact on the prediction made here are F7, F6, and F2, which are also shown to have a very strong positive contribution to the C3 prediction. Other features that shift the prediction in favour of C3 are F10, F11, F3, F12, and F8. On the other hand, F5, F4, and F9 negatively swing the model towards predicting a different label. Compared to F7, F6, and F2, all the negative features have a low to moderate influence on the prediction made here. Finally, F1 has the lowest positive contribution that also further increases the likelihood of the output label, C3.',\n",
       " 'For the given case or instance, the model assigns the label C2, with the prediction confidence equal to 56.56%. The variables F4, F1, F5, and F6 all contribute a lot to the classification decision above. While F4 and F5 are impacting positively, F1 and F6 are decreasing the likelihood of the assigned label. For the remaining features, both F3 and F7 shift the classification towards C2, whereas F2 has a marginal influence on the model, shifting the final verdict away in favour of the alternative label.',\n",
       " 'The prediction made for this case by the model is that C1 is most likely the true label, with a confidence level of 72.03% higher than the 27.97% of the C2 label. According to the input features attribution analysis conducted, the features with the most influence on the decision are F1, F8, F15, and F10, all of which increase the probability that C1 is indeed the true label. The top negatively contributing features, increasing the probability that perhaps the true label could be C2, on the other hand, are F11, F17, F5, and F4. Conversely, F9, F6, F2, and F14 also have positive contributions, further pushing the decision towards labelling the case as C1. Overall, the fairly high confidence in the classification decision here can be attributed to the fact that positive features have a much higher influence on the decision than their negative counterparts.',\n",
       " 'Tasked with labelling cases, the classification model labels the case under consideration as C1 since the probability of C2 is only 20.22%. The predicted probability of the less probable class, C2, reflects the fact that the model is a bit doubtful about the output label. Responsible for this doubt are the negative features F10, F14, F9, and F7 since they support labelling the given case as C2 over C1. On the contrary, F5, F3, F12, F8, F6, F4, F13, and F1 are among the positively contributing features, responsible for the moderately high confidence in the classification output decision.',\n",
       " \"The classification algorithm determines that neither C3 nor C4 nor C2 is a suitable label for the present context. C1 is quite guaranteed to be the correct label. The aforementioned conclusion has a higher degree of confidence due to the positive contributions of F18, F20, and F11. Aside from the above mentioned positive variables, F14, F15, F8, and F10 are also positive. However, their influences are moderate compared to F18, F20, and F11 . The remaining positive variables, F6, F7, F9, and F3, are among the algorithm's least influential input variables. Other attributes, such as F13, F16, F19, and F1, merely serve to reduce the likelihood of C1 being the proper label in the current context. Given the algorithm's high confidence in this classification, one may conclude that the negative variables had minimal impact on the algorithm's label selection here.\",\n",
       " 'The model gave the output label as C1 with a very high probability of 99.69%, leaving only 0.31% chance that C2 could be the right one. According to the contributions or attributions analysis done to understand the properties of various traits, F10 is by far the most influential trait. F8 had a positive impact on model predictions, as did F3. This is in contrast to F6 and F4, which have a negative impact on the model, pushing the classification verdict towards C2. Several input features are shown to have a limited impact on the output label produced by the model and they are: F11, F2, F5, F7, and F1. Overall, only the features F9, F6, F4, F11, F2, and F7 showed negative attributions, reducing the likelihood of the C1 label being assigned by the model but their joint impact was not enough to predispose the model toward a different classification decision.',\n",
       " 'Between the two classes, the given case is assigned the label C2 given that it has the highest predicted probability of about 93.0% since the probability of having C1 as the label is only 7.0%. Analysing the prediction made for the case under consideration, F6, F9, F4, and F10 are the features mainly pushing the prediction higher away from C2, while F5, F8, F3, and F1 improve the odds of the prediction being equal to C2. All things considered, the most relevant feature is F5, by contrast F2 and F11 are the ranked as the least relevant for the label assignment above.',\n",
       " \"The classifier says that C1 has a 67.54 percent chance of being the correct label for the given example or case; consequently the label C2 has a 33.46 percent chance of being the chosen class. The variables F2, F11, F9, and F1 have the most impact on the prediction judgement here. On the other hand, F8, F3, and F5 are seen as less relevant variables when determining the proper class. The variables F1, F10, F3, and F5 lower the probability of the assigned label C1 since they are negative variables favouring the C2 prediction decision. However, the other features' collective or joint attribution is strong enough to favour C1. In summary, F11, F2, and F9 are the most positive variables.\",\n",
       " 'The classification algorithm labels the presented data as C2 with the degree of confidence equal to 81.43 percent, although there is an 18.57 percent possibility that C1 is the correct label. The positive effects and contributions of input variables F8, F12, and F9 are mostly used to assign C2 to a specific scenario. Furthermore, the bulk of the remaining input variables contribute positively, making label C2 even more predictable. The only variables with negative contributions are F11, F3, F10, and F1, which move the choice to C1 rather than C2. Comparing the negative attributions to the positive attributions illustrates why the algorithm is certain that C2 is the correct label here.',\n",
       " 'The probability that the label is C1 is 51.62% and the probability that C2 is the correct label is 48.38%. For this case or example, the uncertainty of the model is mainly due to the direction of influence of the variables F1, F7, and F9. Reducing the chance that C1 is the correct label are variables F1, F9, F3, and F6. While F1, F9, and F3 have a strong negative impact, F6 has the least negative contribution. Per the attribution analysis, increasing the prediction probability of C1 are the variables F7, F10, and F2 which are supported by F5, F8, and F4 all with moderate positive influences on the classification decision made by the model.',\n",
       " \"The classifier assigns the label C2 since the probability associated with C2 is greater than that of C1. For the case under consideration, F1, F7, F11, and F9 are the sets of features significantly influencing the decision made by the classifier. However, features such as F5, F6, and F8 have limited to no impact on the classifier's output decision. F7, F1, and F9 are the features that are positively shifting the verdict toward predicting C2, not C1. In contrast, F11, F10, F6, and F8 have negative attributions, implying that they decrease the likelihood of C2 in favour of C1.\",\n",
       " \"The probability that C2 is the label for the given case is zero and judging by the predicted probability associated with the remaining classes, the classifier is fairly certain that the correct label is C3 given its likelihood of 75.0%. The features are ranked in order of their respective impacts, from most important to least relevant: F10, F11, F9, F7, F12, F3, F6, F4, F8, F2, F1, and F5. Examining the contributions of the input features revealed that the ratio of negative features is smaller than the number of positive features. The negative features, F6, F3, F7, F9, and F4, decrease the classifier's response towards the generated class but the F10 value has the strongest positive contribution, increasing the response of the classifier to support the C3 assignment. Lastly, the least ranked features, F8, F2, F1, and F5, have a weak positive effect on the above prediction outcome, further increasing the odds in favour of label C3.\",\n",
       " \"The most likely label for the given example based on the values of the variables is C1, according to the prediction probability of each class label. It can be concluded that the classifier is quite certain that C1 is the correct label because the probability of C2 is small. According to the attributions of the input variables, the most relevant features with a strong impact on the classifier's decision here are F9, F4, and F5, while on the contrary, the least relevant variables are  F3 and F2. F9, F8, and F5 are positive variables that boost the classifier's response in favour of C1. The primary negative variables are F4 and F6, however they have a little impact on the above classification when compared to F9. Because the majority of the influential features have a positive impact, the confidence level of the classifier used to make the classification decision is high.\",\n",
       " 'The given case is labelled as C2 since it has a prediction probability of 98.33% which implies that C1 is the least probable label. The higher confidence in the assigned label is mainly due to the contributions of input features F12, F15, and F1. In contrast, F8, F10, and F7 are the least ranked features. Based on feature attribution analysis, the top features F12, F15, and F1 have a strong positive influence, increasing the response of the classifier to assigning the label C2. Furthermore, pushing the decision further towards C2 are the other positive features such as F11, F4, F13, and F5. Supporting the prediction of the least probable class are the features F2, F6, F3, F14, and F7. When you compare the joint influence of the negative feature to that of the positive feature, it is evident why the classifier is very certain that C2 is the most probable label.',\n",
       " \"The correct label, according to the classifier,  is neither C3 nor C2, but C1, with a prediction likelihood of about 75.0%. By analysing the attributions of the input features, they can be ranked according to the level of impact, from the most important feature to the least relevant, as follows: F11, F1, F5, F2, F8, F12, F7, F10, F6, F9, F3, and F4. Among the twelve features considered by the classifier for the prediction verdict, seven have a positive influence on the classifier. F5, F2, F7, F12, and F10 are the five negative features that swing the assessment decision towards other classes. The value of F11 has a strong positive contribution to increasing classifier's response, favouring the assigning of C1. The last four features, F6, F9, F3, and F4, have a weak positive effect on the classifier's prediction for this case.\",\n",
       " \"It is important to note that the classifier's labelling decision is based solely on the information supplied. The classification verdict is as follows: C2 is the most probable label with respect to the case under consideration, since the prediction likelihood of the other label, C1, is only 12.50%. The most important variables contributing to the abovementioned classification are F13, F2, and F3, whereas remaining variables such as F11, F8, F9, F4, and F10 have a modest effect on the classifier's labelling decision for the given case. All the top features positively support the selection of C2 as the correct label and the negative variables increasing the chances of C1 are F5, F15, and F16. Given that these are the variables reducing the classifier's response towards generating label C2, it is not surprising that the classifier is very confident that C2 is likely the true label. In addition, the joint negative attribution of F5, F15, and F16 is very small when compared with the positive attributions of F13, F3, F11, and F2.\",\n",
       " 'According to the classification algorithm or model, C1 is the most likely class, with a very high confidence level, and C2 has a very low likelihood of being the right label. All of the inputs are proven to contribute to the categorization described above and the following is a ordering of the features from least essential to most significant based on their degree of influence: F2, F3, F4, F8, F1, F6, F7, and F5. It is clear from the attributions of the input attributes that the algorithm is quite certain that C2 is not the proper label for the given case since each attribute contributes positively, resulting in a significant push towards C1.',\n",
       " 'The model indicates that C1 and C4 have zero prediction probabilities, while that of C2 is 3.85%, meaning the most probable label for the given case is C3  and the confidence level is approximately equal to 96.15% certainty. The major features driving the above classification are F19, F8, and F17, while the least relevant features are F10, F9, F7, F5, and F3. The intermediate features have varying degrees of influence, from moderate to low, and these include F15, F11, and F20. Among the top influential features, only F15 has a negative contribution, driving the prediction slightly towards one of the other possible classes. Furthermore, the top two positive features, F8 and F19, have a stronger influence than all the negative features combined. It is, therefore, not surprising that the model is confident about the classification verdict here.',\n",
       " 'The predicted output label from the model is C2 with almost 100% certainty, indicating it is very certain it is correct and this is mainly because the likelihoods across the other labels C3, C4, and C1 are 0.47%, 0.05%, and 0.04%, respectively. Among the top features F1, F16, and F18, the features F18 and F16 positively influence the classification decision above in the direction of C2, whereas F1 influences in the opposite direction in favour of an alternative label. With a similar direction of influence as F1, the features F5, F3, F20, and F2 negatively impact the prediction of C2, whereas F8 positively impacts it. Features F7, F3, F15, and F12 also have a smaller influence on the prediction output for the given case and finally, the features F11, F14, and F9, have very little contributions to the classification made by the model for the case under consideration.',\n",
       " \"The prediction probabilities associated with the classes C1 and C2 are 99.56% and 0.44%, respectively. Therefore, we can conclude that the most probable label for the given data is C1. The classification model's decision here is largely based on the impacts of the F16, F6, and F10, whereas the F15, F11, and F17 have very little to say about the decision here. In terms of the direction of influence of the features, F16, F9, F5, F13, and F4 are the top positive features contributing to the prediction outcome of C1. Conversely, the marginal doubt in the classification decision (represented by the probability of C2) is largely due to the negative contributions of F6, F1, F3, and F7. To sum up, the very high certainty in the classification output decision could be explained by considering the fact that the joint influence of the negative features is smaller than that of the positive features.\",\n",
       " \"The model identifies the case as C1 since, the true label has just 33.63 percent chance of being C2 when the prediction probability is calculated. The in-depth analysis found that the bulk of the attributes had negative impacts, driving the prediction away from C1 and toward C2. F4, F15, F3, F12, and F17 are among the features that contribute negatively. Furthermore, these features' values are ranked higher than any of the positive features, which are F14, F2, F8, and F13. Finally, it can be concluded that the values of F1, F7, and F6 are less important in predicting the outcome of the case under review, hence they are ranked the least.\",\n",
       " \"0.0% is the predicted probability that C2 is the true label for the test example under consideration according to the classifier.  Judging based on the predicted probabilities associated with the other remaining labels, the classifier is 75.0% confident that C3 is the correct label. From the analysis, the features ranked according to the degree of impact from the most significant feature to the least relevant ones: F6, F8, F1, F5, F4, F2, F7, F11, F12, F3, F10, and F9. Examining the contributions or attributions of the features further  revealed that the ratio of positive features to negative features is seven to five.  The negative features swinging the prediction decision towards the other classes are F1, F5, F7, F2, and F11 since their contribution decrease  the probability that C3 is the true label for the given case. The value of F6 has the strongest positive contribution increasing the classifier's response in support of assigning C3 but the last four features, F12, F3, F10, and F9, have a weak positive influence on the labelling decision or conclusion with respect to the given case.\",\n",
       " 'The classifier is very certain that C1 is not the true label since the predicted probability of C2 is given as 100.0%.  Analysing the attributions of the features indicates that the most relevant features are F12, F4, F13, and F5 while F2, F8, and F9 are the least relevant features. The values of F3, F1, F10, F11, F7, and F6 have a moderate influence on the classification decision made here. Considering that the classifier is 100.0% certain that C2 is the true label, we can conclude that the collective negative attribution of F13, F1, and F6 is clearly outweighed by the positive attributions of features such as F12, F4, F3, and F5.',\n",
       " \"Based on the information provided to the classifier, the true label for the given case is likely C1, with a confidence level of 76.26%. Each input variable has a different degree of influence on the classifier's final labelling decision with respect to the case under consideration. Whilst F3, F11, and F12 have lower contributions to the classifier's decision, F13, F1, and F9 are identified as the major contributors resulting in the assignment and classification probabilities across the two classes. There is a 23.74% chance that perhaps C2 is the true label and the features responsible for this are the negative features, F9, F2, F5, F15, F10, F3, and F11. Driving the classifier's decision in favour of C1 are the positive features such as F13, F1, F14, F16, F4, F6, and F8.\",\n",
       " 'The classification model employed made its label selection decision based on the information provided about the case under consideration. With a moderately low degree of confidence, it classifies the case under consideration as C1. Specifically, per the model, the probability of labelling the case as C2 is equal to 48.66%, hence not as likely as C1. The decision made here can be attributed to the influence of features such as F16, F8, F2, F12, and F13. However, F1, F6, F4, F15, and F3 are the least relevant features with respect to the classification made.  The confidence level of the model is marginally above average and this can be attributed to the negative contributions of F10, F16, F9, F7, F1, F15, and F3. The negative features shift the prediction decision in the direction of C2, however, the positive contributions of other features such as F8, F2, F12, and F13 improve the odds of the C1 label.',\n",
       " 'The prediction results are as follows:  the probability that C1 is the correct label is 97.12%, the probability that C2 is the correct label is 2.55%, and the probability that C3 is the correct label is 0.33%. Judging based on the prediction probabilities across the classes, C1 is the most probable label. The very high confidence in the assigned label can be attributed to the very strong positive influence and contributions of the variables F1, F6, F10, F4, and F8. The other positive variables are F2, F9, and F7. The positive variables increase the probability that C1 is the correct label for the given case. Decreasing the probability of C1 are the negative variables F5, F11, F3, and F12. Considering that the combined effect of the negative factors is quite minimal in comparison to the top positive variables, it is not surprising that the model is very sure that neither C2 nor C1 is the best label for the given case.',\n",
       " \"C1 is the model's predicted output for this given case, with an accuracy of 87.13% meaning the likelihood of C2 is only 12.87%. F13, F4, F2, F12, and F14 have the most effect on the output prediction choice in this case, whereas on the other hand, F10, F5, F16, and F7 are not that important to the decision made here. F13, F14, and F12 are the top negative features when you consider direction of their respective impacts, decreasing the model's reaction to labelling the given scenario as C1 and also F3, F1, F5, F16, and F7 are the other features that contribute negatively. In a nutshell, F4, F2, F8, F9, and F6 are primarily positive improving the odds of C1  with respect to this classification conclusion.\",\n",
       " 'The classification model or algorithm classifies the provided data or case as C1 with a predicted likelihood of 94.16%, meaning that the chance of C2 being the true label is only 5.84%. The most relevant features driving the classification above are F7, F9, F8, F6, and F10, however, arranging the input features in-order of their contributions revealed that the least influential features are F2, F1, F11, and F5 since their values receive little consideration or emphasis from the algorithm. In relation to the directions of influence of input features, only F6 and F11 are shown to have negative contributions, which tends to drive the labelling judgement towards C2 instead of C1. Considering that the combined effect of all the negative features is lower than that of the positive features such as F7, F9, F8, F10, F3, and F4, it is valid to say that C1 is the most probable label.',\n",
       " 'The final classification made was C2, but with a likelihood of only 55.19%, the model is uncertain about this prediction. By far, feature F12 had the most impact and following F12 are F5, F15, and F6 have been identified as having the comparable influence on classification. The combination of F12, F5, F15, F6, and F1 features has shifted the classification decision from C2 to C1. While F13, F16, and F10 are all features with a moderate impact on the classification, F13  is the only one of that set that has had a positive impact on the C2 classification and the remaining positives are F2, F18, and F11. Lastly, the features F19, F14, F8, F7, and F9 had very marginal negative contributions to the classification verdict.',\n",
       " \"Based on the prediction probabilities, C1 is the most likely label for the given case considering the values of the input variables and because the likelihood of C2 is very marginal, so the classifier is very confident that C1 is the right label. An analysis of the contributions of the variables has shown that F9 is the most relevant, with the strongest influence on the classifier's decision, however, to arrive at the classification above, the classifier probably ignores the values of the least ranked variables, F7 and F6. The level of confidence of the classifier with respect to the above classification decision is higher, primarily because most of the influential variables have a positive impact. F9, F3, and F4 are the top positive variables that increase the likelihood of C1. Having a different direction of influence, F8, F6, F7, and F5 are the negative factors, but compared to F9, their impact on the prediction decision above is low.\",\n",
       " \"Based on the information available about the case under consideration, the classification model is very uncertain about the appropriate labels for the case. According to the model, there is an almost equal distribution in terms of the probability that any one of C1 and C2 is an appropriate label. This indicates that any of the possible labels could be the true one, but for simiplicity, the model selects the class as C1. The above judgement is mainly due to the influence of the following factors or variables: F6, F9, F12, and F3 while the least relevant variables are F10, F2, and F5. Positive variables like F3, F12, F19, and F1 increase the model's response in favour of the assigned label. Nevertheless, negative variables such as F6, F13, F8, and F9 reduce the possibility that C1 is an appropriate label because their values support the selection of C2. Uncertainty about the classification here can be due to the fact that the most important negative properties, F6 and F9, have very high impacts, which moves the model's judgement away from C1 towards C2.\",\n",
       " 'There is about an 81.01% chance that C2 is the probable label, hence the predicted probability for the C1 class is only 18.99%.  The algorithm or classifier arrived at the prediction verdict above mainly based on the influence of features such as F3, F4, F7, and F1. For the algorithm, the least relevant feature is F6, which is shown to have a very small contribution in relation to the label choice here.  When the directions of influence of the input features were investigated, it was discovered that F3, F2, F7, and F1 have positive attributions, pushing the algorithm higher towards the C2 label. Negative features such as F4, F5, and F8 assist in dragging or pushing the classification decision lower towards C2, where it was originally classified and this is mainly because their contributions to the prediction favour choosing or labelling the case as C1.',\n",
       " \"According to the classification algorithm, there is 77.69% chance that the given case is part of the C1 population. The features with the largest impact driving the algorithm to arrive at the above decision are F8, F1, and F15 which are followed in the decreasing order of influence by F14, F4, F13, F7, F3, F6, F11, F2, F5, F12, F9, and F10. Inspecting the direction of influence of the input features showed that, F8, F3, F6, F10, and F1 have negative influence on the prediction, shifting the algorithm's verdict towards the C2 class and can be blamed for the doubt in the classification decision. However,  strongly pushing the classification higher towards the C1 label are the positive features such as F15, F14, F4, F13, F7, and F11.\",\n",
       " \"The likelihood of the true label for the given test case being equal to the model's output prediction, C2, is 85.71% and since it's not 100%, there is a small chance of about 14.29% that the model could be wrong. Among the features employed for this classification, F4, F8, F10, F11, F12, and F9 are the top features influencing the model's prediction decision. The features with the strongest positive influence are F4 and F8 and in fact, these are shown to be the two main driving forces controlling the model's decision regarding the given case. Besides, some otf the other positive  features include F11, F12, F2, F13, and F9. However, the atrribution of F10, F3, F14, F6, and F7 indicates the true label could perhaps be C1. While the different input features have some sort of contribution to the prediction made for this test case, the features F5, F16, and F15 have the least impact on the final decision here.\",\n",
       " \"To begin with, the classification choice is entirely dependent on the information or data provided to the prediction model. According to the model, C2 has a 61.61 percent probability of being the true label, whereas C1 has a 38.39 percent chance of being the true label. Because the estimated probability of C2 is greater than that of C1, it is reasonable to assume that C2 is the most probable true label. The key variable responsible for this classification is F23, with a very significant positive effect on the model's conclusion, pushing it higher towards C2. F22, F7, F30, F14, F13, F20, F8, and F6 are the next set of relevant variables. F22, F30, F14, F20, F18, F12, and F8 have negative contributions that are responsible for the decrease in the chance that C2 is the actual label since they prefer to assign the C1 label instead. This means that the contributions of F7, F13, F10, F29, and F6, together with F23, can explain why the model is rather confident that C2 is the correct label.\",\n",
       " \"With a prediction likelihood of 62.34%, the model trained to generate predictions based on input variables identifies the presented example as C1. The model's label assignment choice for the given case is heavily impacted by the values of input variables such as F3, F1, and F9. The least important variables, on the other hand, are F8, F2, and F4. Furthermore, the impact of F5, F6, and F7 is regarded as moderate. F9 and F5 are the variables identified to have negative contributions to the classification when you take into consideration their respective direction of impact. All of the remaining variables have a positive influence, contributing to the classification of the presented case as C1. As a result, it is unexpected that the model's confidence is just 62.34% which suggest that the negative attributes may have a larger say in the appropriate label for the case under review.\",\n",
       " \"For the case under consideration, the model outputs C2 with high confidence level since the associated predicted class label is 89.73% whilst that of C1 is just 10.27%. Just few features out of the entire input features are shown to have control over the prediction made here. The prediction verdict C2 is mainly based on the variables F16, F43, F35, and F14. Other variables with moderate attributions include F17, F44, F3, F21, F5, and F40. Each variable mentioned above is shown to have different direction of contribution or impact for instance while F16, F14, F5, and F21 positively support the model's output decision, F43, F35, F17, F44, F40, and F3 contributed to decreasing the likelihood or odds of C2 being the true label for the given test instance. The variables shown to have no influence or contribution on the classification decision above are mainly F15, F39, F4, and F18.\",\n",
       " \"The model trained to solve the classification task labels the given case as C2 with a moderately high degree of confidence level equal to 60.13%. However, it is important to note that the prediction likelihood of C1 is 39.87%. Investigation of the contributions of the features to the above label assignment indicates that the most relevant features considered by the model are F16, F2, F9, and F10. Increasing the prediction likelihood of label C2 are mainly the positive features F16, F9, and F10. These features are termed positive features since their direction of influence is in support of the assigned label C2. On the contrary, F2, F3, and F12 are the top negative features, accounting for the uncertainty in the final prediction verdict. In plain terms, these negative features support labelling the case as C1, contradicting the model's decision in this case.\",\n",
       " \"The following assertions are based on the information provided to the classification model. The classification model's confidence in this case's prediction output is approximately 69.40% and this suggest that the chance of label C1 is about 30.60%. The prediction attribution analysis shows that F7 and F8 are the most important features, whereas F4 and F1 are the least influential. F6, F2, and F3 are recognised as the only negative features considering the direction of effect of the features since their contributions reduce the prediction likelihood of the specified label, C2. F7, F8, F5, F4, and F1, on the other hand, have a positive impact on the model in favour of labelling the provided situation as C2 rather than C1.\",\n",
       " 'Because the chance that the label is the alternative class C2 is only 1.94 percent, the model anticipates that C1 will be the correct label in this situation. Specifically, it can be concluded that the model has a high level of confidence in the label C1. The feature attribution analysis conducted suggests that the two most relevant features considered when choosing the C1 are F29 and F1. F8, F27, F7, F13, and F22 were some of the other factors that positively helped with this prediction. F18, F36, F23, and F6, on the other hand, are the features with a negative influence on the above prediction judgement. In comparison to the F31, F22, F27, and F1, the foregoing features have little impact on the model and this might explain why the model is so certain that the correct label is C1. However, it is crucial to note that not all features are considered by the model during the label assignment with the irrelevant features such as F41, F32, F39, and F40 having extremely low attributions which happens to be almost zero.',\n",
       " 'The model predicted that the example should be classified as C1 with a 76.06% likelihood but the model also identified that there was a 23.94% chance that the right label could actually be C2. The positive influence of features F4, F7, F9, and F1 on the model supports the class assignment of C1. Both F3 and F8 are features with a small positive impact on the classification decision for the given case. F11 and F5, in contrast, has a small negative impact on the output verdict that drives the decision away in favour of the other label. The features F12 and F6 have only a very small impact on the final classification decision. Finally, F10 is shown to have zero impact on the model in this case, hence it is not relevant to the prediction of class C1.',\n",
       " \"The classification model labels the given case as C1 at a very high confidence level since the probability that C2 is the correct label according to the model is only 3.50%. The assignment decision above is mainly based on the values of the features F3, F5, F7, and F1. On the other hand, the values of F6 and F2 are shown to have a very weak influence on the model's decision. The analysis revealed that only four of the input features support the decision by the model, while the remaining ones contradict the assigned label. The four positive features are F7, F1, F9, and F8.\",\n",
       " \"The model generated the label, C1, with a very high likelihood of 99.69%, hence the probability that C2 is the right label is only 0.31%. Based on the analysis performed to understand the attributions of the different features, F11 was by far the most impactful positive feature whereas, the most negative feature is identified as F6. F8 also had a positive influence on the model's prediction, as did F1, F10, and F2. This is in contrast to F5 and F7, which had a negative influence on the prediction. Many of the features under consideration had only smaller impact on the outcome of the model and these are F4, F9, F2, F3, and F10. Considering the attributions of the input features, only F6, F5, F7, F4, F9, and F3 are shown to have negative attributions, decreasing the likelihood of the predicted label, however, the collective influence of the negative features is not enough to swing the model towards a different label.\",\n",
       " \"The item is labelled as C2 with a high degree of confidence since the predicted probability associated with the other class is 0.0%. Looking at the contributions of the features, only F1 and F2, are shown to drive the model towards predicting C1. However, these features are ranked as the least relevant, implying that their values have a very low impact on the model's decision. All the positive features, F3, F6, F5, F4, and F7, are ranked higher than the negative ones, with higher impacts on the model, significantly supporting the assigned label which could explain the high confidence level.\",\n",
       " 'With the prediction probability distribution across the labels, C1 and C2, respectively, equal to 0.30% and 99.70%, the model labels this instance as C2. The most important features are F3, F4, and F7. The variables, F8, F5, F1, and F2, have values, increasing the chances of C1 being the label for this case. Increasing the odds of C2 being the correct label are the values of the remaining variables. The strong positive variables are F3, F4, and F7 coupled with the moderate positive influence of F6 and F9 pushes the prediction in favour of C2 hence the prediction confidence level achieved.',\n",
       " 'C3 is given as the predicted label with very high confidence, and according to the classification algorithm, there is no chance that either of the remaining three labels, C4, C3, and C1, is the right label for this case since the predicted probability of C2 is 100.0%. Based on the attribution analysis and investigations, the ranking of the input features from the most important to the least important is: F3, F6, F5, F4, F2, and F1. From the attribution analysis, F3 is the only one that positively contribute and support the above classification decision, while the remaining features such as F6, F5, F2, and F4 have negative contributions, shifting the decision in a different direction. In conclusion, looking at the predicted confidence level, one can say that the very strong attribution or influence of F3 is enough to dwarf the contributions of the features F6, F5, F4, F2, and F1.',\n",
       " 'In the present case, there is only a 12.50% chance that C1 is the correct label, which means there is an 87.50% chance that C2 is the true label. Therefore, the most probable class assigned by the model is C2. The above decision is mainly based on the influence of the following variables: F5, F4, and F7. Of these main variables, only F4 had a very strong positive impact on the model, increasing the prediction probability of the assigned label. The most important variables that lower the likelihood of C2 being the correct label are F7 and F5. The remaining two variables moving the decision away from C2 are F8 and F2. F3 and F6 are the least important variables, with a marginal impact on the model and this positive impact on the model is moderately low.',\n",
       " 'There is an evenly split chance that the prediction could be either of the two labels, C1 and C2. Based on the predicted probabilities, we can conclude that the model is uncertain about which label is the correct one. The abovementioned prediction decision is chiefly attributed to the influence of the following features: F9, F3, and F1, however, the least important or ranked ones are F5 and F2. The attributes F6, F4, F7, and F8 are shown to have moderate contributions.',\n",
       " 'The label assigned to the given sample is C1 at a confidence level of 56.81%. This means that there is a 43.19% chance that the sample could be C2, representing an uncertain classification decision. The values of F9, F2, F3, F4, and F8 are the major contributing factors resulting in the classification decision here. On the other hand, the least important features are F6, F7, and F5, with a low level of influence. Considering the direction of influence of the features (that is, either supporting or contradicting the prediction above), only F3, F4, and F8 are shown to have positive attributions, increasing the likelihood of the assigned label. This implies that the values of the remaining features F1, F9, F2, F7, F6, and F5 have negative attributions, shifting the verdict in the opposite direction in favour of C2. In simple terms, the correct label should be C2 according to the negative features enumerated above.',\n",
       " 'The classification algorithm classifies the given case as C2, since there is only an 18.57% chance that C1 is the correct label. The effects and contributions of positive input variables F9, F10, and F8 are the major drivers for the above classification. Besides, most of the remaining predictors such as F11, F4, F2, F14, and F5, are positive variables, decreasing the likelihood of the C1 label and making the label C2 more likely. The only variables with negative contributions are F3, F5, F13, and F6, which motivate generating the label C1 instead of C2. In summary, comparing negative attribution to positive attribution explains why the algorithm can determine that C2 is the right label for the given case.',\n",
       " 'The odds are in favour of C2 being the correct label for the given case. This is because the probability of the other label, C1, is only 1.03%. Ranking the features in order of relevance to the classification decision above, F1, F2, F4, F8, F5, F3, F7, and F6. Among the set of features used for this prediction, F2, F5, and F3 are the only ones shown to decrease the likelihood of the C2 decision. The positive features increasing the chances of C2 being the correct label are F1, F4, F8, F7, and F6. The joint attribution of the positive features is stronger than that of the negative ones, which explains the confidence level associated with class C2.',\n",
       " 'According to the prediction algorithm or model, there is almost 100% confidence that C2 is the label for the case under consideration. This is because the probability of C1 being the correct label is only 0.70%. The classification decision above is mainly based on the values of the following features: F12, F3, and F9 since their respective attributions are higher than any of the remaining features. F3 has a negative contribution to the prediction made by the model for this case, while in contrast, F12 and F9 have positive contributions, that push the classification decision in favour of C2. Unlike all the features mentioned above, the values of F14, F6, F2, and F11 have a limited impact on the classification decision above.',\n",
       " \"The C2 has a predicted probability of just 3.10 percent, but the C1 has a predicted probability of 96.90 percent, which implies that C1 is the most likely class chosen by the classifier for the supplied data. Not all of the input features are directly relevant to labelling the provided data and, per the attributions analysis, only F33, F5, F24, F10, F22, F21, F11, F23, F32, F29, F9, F17, F28, F20, F38, F19, F1, F4, F6, and F31 are the relevant features. However, F2, F8, and F35 are examples of irrelevant features since their contributions are mostly ignored by the classifier when classifying the given case. According to the attribution assessment, F33 and F5 have a very substantial combined positive influence, enhancing the classifier's response towards C1 rather than C2. In contrast, the top negative features are F24, F22, and F10, which weaken the classifier's response in favour of C2. When the attributions of F33, F21, and F5 are compared to the attributions of the negative features indicated above, it is not unexpected that the classifier is highly certain that C1 is the most likely label in this case.\",\n",
       " 'The classification algorithm labels this instance as C1, but its level of confidence is moderate considering the fact that there is about a 44.0% chance that C2 could be the appropriate label.  The features, F1, F4, F8, and F5, negatively influence the prediction verdict away from C1 and favour assigning C2 as the correct label. Contradicting the influence of the negative feature are features such as F2, F3, and F7, with positive contributions, improving the odds in favour of the probable label, C1.  To summarise, the top features with the most influence on the above label assignment are F2 and F1, but F5 and F9 are the least influential input features considered by the algorithm.',\n",
       " 'The case given is labelled as C2 with close to an 82.07% confidence level, implying that the likelihood of C1 being the correct label is only 17.93%. The classification above is mainly due to the contributions of different features such as F39, F13, F24, F38, F22, and F26. But, not all features are considered by the classifier to arrive at the decision made for the given case. These irrelevant features include F40, F33, F11, and F8. Among the influential features as shown, F39, F13, F24, F38, and F18 are the top positives that increase the probability of C2 being the true label. However, F22, F26, F36, F29, F4, F42, F27, and F20 are the top negative features, driving the prediction lower towards C2 in favour of C1. In closing, the most important features with regard to this classification output are F39 and F13, all with positive attributions, explaining the very high confidence level.',\n",
       " \"The output labelling decision is C1 with almost 100% certainty, which indicates that there is practically no chance that C2 is the right label choice for the case under consideration.  F61, F15, F1, F86, and F23 are the features with the highest joint positive impact, influencing the model's decision to output C1 and the feature F89 also has a high impact, but unlike F61, F15, F1, F86, and F23, F89 attempts to shift the decision away from C1 in the direction of C2. Also, F83 and F4 have a moderate impact on the decision towards C1, although this is still higher than features F65, F13, F90, and F77, which have a moderate impact, favouring the prediction of class C2. Besides, F4, F37, F2, F46, F6, and F28 all have a positive influence on the final classification verdict further increasing the odds in favour of the C1 label. It is worthy to note that for this classification decision, a large number of features are shown to be irrelevant hence received negligible consideration from the model, and these include F35, F3, F8, F85, and F51.\",\n",
       " 'The label assigned by the classifier in this instance is C2, which had a very high prediction likelihood of about 99.93%. According to this classifier, the probability of C1 being the correct class is only 0.07%. Analysis performed shows that the confidence level of the classifier here is due to mainly the values of the features F10, F11, F5, and F2. The least relevant features to this classification verdict are F12, F3, F6, and F13 since the magnitude of their respective attribution is smaller compared to the remaining features. Furthermore, only the features, F4, F8, and F3, have a negative influence, increasing the chances of predicting the alternative label C1. However, when compared to the joint influence of the positive features such as F10, F11, and F5, the influence of the negative features is smaller, hence explaining the high degree of confidence in the predicted C2 label.',\n",
       " \"The classifier is very certain that C2 is not the accurate label for the given data or example, but that C1 fits. F20, F5, F1, F14, F4, F6, and F13 are the input features that have the most influence on the choice or judgment. F16, F9, F30, F7, F22, F24, F11, F2, F27, and F28, on the other hand, are found to be irrelevant and have negligible inlfuence on the classifier. Amongst the top features, F20, F5, and F1 are the one shown to have negative contributions, greatly favouring C2, lowering C1's prediction probability. Despite the significant negative attributions of the top impactful attributes, the classifier is quite certain that C1 is the correct label, based on the prediction probabilities.\",\n",
       " \"The classifier's anticipated label for this case is C2 which is a decision that it is highly confident about since the predicted likelihood is 100.0%. The most important variables are F10, F6, F9, and F5, whose values lead to the aforesaid classification conclusion. Under this classification instance, examination of the attributions of the features showed that F7, F11, and F1 are the least essential features. Because majority of the case's attributes positively validate the assigned label, it's not unexpected that the classifier picked the C2. F10, F6, F5, F2, F12, and F13 are all positive variables, while F9, F4, and F8 are three contradicting variables that moderately drive the labelling judgment towards C1.\",\n",
       " 'The model selects C2 as the correct label with a probability of 57.58%, while the other class, C1, has a slightly lower probability of 42.42%. The most relevant attribute is F5, followed by F7, F1, F6, F8, F9, F3, F4 and finally F2, which is the least relevant. The features F8, F3, and F5 have a positive influence, increasing the probability of the classification output, while F1 has a negative attribution, swinging the model to assign C1 instead. F6, F4, F7, and F9 are some of the other negative attributes. Finally, F2 has a very small positive control over the prediction in this test case but it further increases the confidence in the label chosen for the given case.',\n",
       " 'The prediction verdict here is that the most probable class label is C1. Actually, the classification algorithm indicates that there is no possibility that the correct label is C2.   Majorly contributing to the above classification are F3, F7, F6, and F11, all with positive influence. It is therefore not surprising that the algorithm is confident that C1 is the right label. The other positive features considered to arrive at the decision here are F8, F9, F10, F4, and F1. According to the attribution analysis, only F2, F5, and F13 have negative contributions, which tend to attempt to swing the final verdict in favour of C2. To sum up, the joint negative influence is not enough to outweigh the positive features, hence the C1 is assigned for the given case.',\n",
       " \"Due to the prediction probability distribution across the class labels, the labels assigned to this example is C1 with a high degree of confidence, close to 100 percent. The most significant features driving the classification above, according to the attributions of the input features, are F14, F4, F6, and F9. F10 and F2, on the other hand, are the least essential features to this prediction here. In addition, just four of the input features have a negative impact, skewing the classifier's judgement in favour of the C2 label. F10, F6, F13,  and F2 are the opposing features. The contribution of the negative features, with the exception of F6, is quite modest when compared to the top positive features such as F4, F9, and F11.\",\n",
       " 'The classification algorithm predicts that the data sample given should be classified as C1 with a probability of 76.06%, but it also finds that there is a 23.94% probability that the correct label will be C2. The positive influence of the F6, F11, F8, and F9 features on the algorithm supports the C1 class tasks. F10 and F3 are features with little positive influence on the classification decision for a particular case. F5 and F12, in contrast, has a small negative impact on the output decision that result in the reduction in the likelihood of C1 hence can be said to favour labelling the case as C2. F1 and F4 had only a minor positive impact on the final labelling decision and finally F7 was shown to have zero effect on the algorithm in this case.',\n",
       " \"According to the model, there is a higher chance that the case's label is C1. This prediction decision is based primarily on the attribution of the following features: F3, F9, F4, and F5. Aside from F5, all the other features listed above have a strong positive influence, increasing the probability of the predicted class C1. Similar to F5, the values of features F10, F6, and F8 suggest the other label, C2, could be the correct label. However, unlike F3, F9, and F4, each of the negative features has a moderate contribution to the final decision. The remaining features F1, F2, and F11 are shown to have marginal contributions to the model's decision for this case, and F7 was ranked as the least important feature. In summary, with strong positive attributions from F3, F9, F4, and F1, the model is very certain about the classification verdict, with a certainty of 100.0%.\",\n",
       " \"For the case under consideration, the model's output labelling decision is as follows: there is no possibility that C1 is the label for the given case, C2 is the most likely class label, with a confidence level close of 100.0%. The values of the input features, F27, F74, F84, F79, F72, F45, and F42, are the main driving forces resulting in the above classification. The features with moderate influence on the decision here are F40, F52, F11, F20, F38, F56, F6, F25, F55, F47, F46, F75, and F1. Apart from all the abovementioned input features, all the remaining ones, such as F23, F34, F85, and F57, are shown to be irrelevant to the decision made here. Also per the attribution analysis, not all the influential features support labelling the given case as C2, and these are referred to as negative features since they reduce the probability that C2 is the right label here  and these are F42, F52, F46, F75, and F1. The notable positive features increasing the probability that C2 is the right label are F27, F74, F84, and F79.\",\n",
       " \"Based on the influence of features such as F10, F3, F9, and F1, the classifier is pretty confident that the correct label for the given data is C1, whilst, there is a 10.0% probability that the proper label could be C2.  The majority of the features have positive contributions, while only F1, F11, and F8 are the negative features, decreasing the classifier's response towards choosing C1. The notal positive features that increase the classifier's response higher towards label C1 instead of C2 include F10, F3, F4, F2, F7, and F9. Taking into consideration the attributions of the input features, we can attribute the classifier's confidence associated with this prediction to the fact that the negative features only have a moderate impact on the classifier's decision for the given data.\",\n",
       " \"The model's prediction for this test case is C2 with an almost 100% confidence level which implies that the likelihood of it being a different class label is closer to 0%. Among the top influential feature-set, F10 has a value shifting the label choice in favour of C1, while the others, F11, F5, and F18, all have a positive impact supporting the decision made by the model to assign the label C2. Other features with positive support or impact on the prediction made include F12, F14, F1, and F2. However, F7, F13, F3, and F15 are the other negatives shifting the prediction decision in the direction of the alternative class label. TO sum up, the positive features clearly outweigh the negative features interms of their contributions, hence the confidence level in the classification output.\",\n",
       " 'The classification verdict for the selected case is C1, and the model is very certain about that considering the prediction probabilities across the possible classes. The top variables influencing this decision are F24, F7, F6, F38, and F11. Other variables that are regarded as somewhat important are F19, F26, F14, F18, F37, F4, F28, F25, F3, F22, F21, F30, F8, F15, and F34. Among the top variables, F24 and F7 decrease the prediction response; therefore, they are pushing the verdict toward C2. Similar to these features, F19, F26, and F37 negatively support assigning C1 to the case. Positively supporting the predicted label are the features F6, F38, F11, and F14. Unlike all the features mentioned above, the values of the remaining features such as F23, F17, F32, and F13, are unessential when determining the correct label for this case.',\n",
       " \"Classifying the given case based on the values of its features, C1 is the best label for the given case since its prediction probability is 99.45%, while C2's is just 0.55 percent. The most relevant factors for the classification or prediction declaration above are F2, F8, and F4, whereas the least influential factors are F3, F1, F10, and F7. The other factors' influence can be described as modest and after further inspecting the direction of effect of the factors, F2, F8, F5, F10, and F7 all contribute positively to giving the label C1. These are the favourable factors that raise the likelihood of C1 being the correct designation, however, F4, F9, and F6 are mostly responsible for minimising the chances of C1 and promoting C2.\",\n",
       " 'Per the predicted likelihoods across the classes, the model predicts label C2 in this case with a high confidence level. Features F4, F5, F1, and F7 are all driving the model towards the C2 classification, with feature F4 being the strongest driver and F7 being the weak driver among the above mentioned set of features. Features F8 and F6 have moderate negative impact on the C2 classification, while feature F2 has a strong positive impact. Finally, feature F3 has a very weak negative impact on the C2 classification decision driving the model towards assigning C1 to the case here.',\n",
       " \"The classifier is very uncertain about the correct class for this example and this is because both classes are shown to be equally likely. The above prediction conclusion is mainly based on the influence of the top input features F1, F7, and F4, while F2, F6, and F5 have less influence on the classifier when classifying the given case. When the direction of influence or contribution of each input feature is examined, only F7, F7, F2, and F5 are revealed to have a positive contribution, improving the classifier's affinity to produce the label C1. The remaining features, F4, F1, F8, F9, F3, and F6 have a negative influence and contribution to the final decision.\",\n",
       " \"C1 is the label assigned to this data instance based on the fact that C2 is shown to be very unlikely, with a prediction probability of only 0.68%. The variables most relevant to increasing the probability of the prediction here are F2, F14, F20, and F22. Other positive features that increase the chances of predicting C1 are F6, F3, and F19, however, unlike F20, F14, F2, and F22, these have only moderate contributions to the model's classification decision for this instance. In contrast, F15 is the only top-ranked feature that led the model to classify towards C2, while other negative features with a moderately low contribution included F11, F1, F7, and F12. The least relevant features are F21, F8, F18, and F9, with a very low influence on the C1 prediction, however, unlike these features, F16 and F13 are shown to have no impact, since their attributions are very close to zero, when determining the correct label for the case under consideration. Finally, F13 and F16, according to the attribution analysis have no impact on the classification decision here.\",\n",
       " \"C1 is the class assigned to this case or instance. However, according to the classifier, there is a 5.75% chance that the other label, C2, is the correct one. The labelling decision above is mainly due to the values F2, F6, and F3. F8 and F5 are the least ranked features since they have marginal attributions. F6, F1, F9, and F2 have values, increasing the odds of C1 being the correct label and these four features are commonly known as positive variables given that they support the classifier's output decision for the given case. The remaining variables had negative attributions, driving the classification decision towards label C2 and the most negative variables are F3, F7, and F10.\",\n",
       " 'The model predicts the class label of this test case or instance as C2 and it is quite confident in the above prediction decision considering the predicted confidence level. The above prediction decision was made primarily based on the values of the following features: F6, F8, F3, and F18. The top features, F6 and F8, positively contribute to the final prediction of C2. Besides, F18 also has a positive impact, pushing the model to output C2. However, the value of F3 supports the prediction of the alternative label, C1. However, compared to F6 and F8, the influence of F3 is very small. The features with moderate influence or impact on the prediction made for this test case are F14, F16, and F1. While F14 moderately supports the C2 prediction, F16 and F1 have values, pushing the model toward predicting C1.',\n",
       " 'The case is labelled as C2 by the classification model, and according to the model, there is little to no chance that the correct label could be C1. Per the feature attribution inspection, F8 and F5 are the least influential features. The classification decision to label this case as C2 is mainly due to the positive contributions of F3, F7, and F4. However, the strong negative influence of F6 indicates that the true label could be C1, but since the likelihood of C1 is 0.0%, we can say that the positive features successfully drive the decision in favour of the C2 label. F2, F1, and F5 are the other negative features that unsuccessfully attempt to shift the decision in favour of C1. From the attribution analysis and the predicted likelihoods across the classes, we can conclude that the model is certain that C1 is not the true label.',\n",
       " 'The decision of the classification model on the true label with respect to the given case is based on the information provided to it. From the prediction probabilities, C1 is selected by the model as the most likely label, with a very high confidence level equal to 97.49%. According to the attributions analysis, the very high confidence in the validity of C1 can be attributed to the very strong positive influence of F15, F18, and F13. The contributions of all the other features are moderate to low. The least relevant features are F1, F2, F10, and F5, whereas the moderate ones include F14, F6, F11, and F7. The very marginal uncertainty with respect to the classification decision here can be blamed on the moderate influence of negative features such as F14, F6, F11, F16, F4, and F7. Aside from F15, F18, and F13, some of the other positive features are F19, F12, and F2, with moderate to low contributions, pushing the decision further higher towards C1 away from C2. Finally, F5 has a negligible contribution to the decision above.',\n",
       " 'With a moderate likelihood of 50.0%, the label for this case is judged to be C3. The classifier, on the other hand, says that C1 and C2 are equally likely, with a predicted probability of 25.0 percent. The aforementioned decision is mostly dependent on the features of the given case and the values of F7, F5, and F11 are demonstrated to be the primary factors influencing the classification output decision. When compared to F7, F5, and F11, the other variables, such as F1, F12, and F6, have lower attributions. According to the attribution assessment, F7, F5, F11, F12, and F10 are the factors that positively contribute to the choice, implying that they are the ones that push the classification closer towards C3. F1, F6, F3, F4, and F9, on the other hand, are the top negative factors that sway the choice somewhat toward the other labels, C1 and C2. In fact, it is because of these negative variables that the classifier presents the probabilities across the C2 and C1.',\n",
       " 'With a prediction probability of around 82.06 percent, the algorithm predicts class C1. In the aforementioned prediction judgment, F8, F10, F16, and F3 are all important. The top positively contributing features supporting the C1 prediction are F8, F10, and F3, while F16 is pushing the final prediction away. F12 also has a positive impact on the categorization, but F9 has a negative impact and finally, F17, F5, F19, and F7 have very little influence on the algorithm among the features, when picking the most appropriate label in this case.',\n",
       " 'For this test case, the model predicts C2 with 99.93% certainty and what this means is that there is only 0.07% chance that C1 could be the right one. The features with the highest impact are F4, F5, F13, and F6, which are all shown to contribute positively to the prediction decision mentioned above. While F3 and F1 support the prediction, F10 is the feature with the strongest negative support for the prediction. Of the features with a small impact, namely F9, F8, F2, F12, F11, and F7, only F8 and F12 negatively support the prediction while the others positively support it.',\n",
       " \"This model trained on eleven attributes predicts class label C2 for this case with a confidence level equal to 54.21%. This suggests that the likelihood of C1 being the correct label is 45.79%. The classification decision above is mainly based on the influence of the features F10, F8, F1, and F4. The most relevant features are the negative features, F10, F8, and F1. These features are regarded as negative features given that their values are shifting the prediction decision in the direction of C1. The positive attributes are F4, F6, F3, F7, and F11, supporting the model's prediction for this case.\",\n",
       " 'With a moderate confidence level of 67.95%, the model predicts C2 for the case under consideration, but it is important to consider the fact that there is a 32.05% chance that C1 could be the correct label instead. The most influential variables resulting in the aforementioned classification decision are F9, F5, and F7. While F9 and F5 have negative contributions towards the C2 prediction; favouring the assignment of C1 instead, F7 is the top positive contributing feature. F8, F3, and F10 had a small positive effect on prediction, whereas F1 had a smaller negative effect. Finally, F2 is the least relevant variable, and therefore, its negative attribution has no significant influence on the model with respect to the given case.',\n",
       " 'As per the classification algorithm, the most appropriate label for the given case is C2 because its prediction likelihood is 99.45%, whereas that of C1 is only 0.55%.  For the classification or prediction assertion above, the most important variables are F11, F3, and F4, while the least influential variables are F8, F2, F7, and F9. Regarding the direction of influence of the variables, the ones with positive contributions to assigning label C2 are F11, F3, F1, F7, and F9 which in fact increase the odds of C2 being the correct label. Finally, decreasing the odds of C2 and supporting C1 are mainly the values of the variables F4, F5, and F6.',\n",
       " 'C2 is the label predicted by the classification model employed and looking at the prediction probabilities, it valid to concluded that the model is very certain about the selected label. The features considered most relevant by the model for the above decision are F1, F3, F11, and F4, while those with the least consideration are F10, F9, and F12. On the basis of the analysis, majority of the input features positively affirm the prediction for this case; therefore, it is not surprising that the model chose the C2 label and the positive features include F1, F11, F4, F8, F6, F2, and F5. The three negative features that moderately bias the labelling decision towards C1 are F13, F3, and F7.',\n",
       " \"The confidence level for the prediction made for the given case is 71.57%. F7 has a significant impact on the outcome in the negative. The values F10, F2, F8, F4, F1, F9, and F3 all have a positive impact on the results, but they are still less than the effects of F7. The analysis shows that F7 has the highest impact on the model's prediction decision here,   it has an overwhelmingly negative effect. F2, F8, F4, and F1 have a positive effect on the model's prediction. Because of the strength of the F7 feature, all other features have little effect on the outcome. In addition, the uncertainty in the prediction could be attributed to the pull of F7, which drives the model to predict an alternative label.\",\n",
       " \"53.78% and 46.22%, respectively, are the chance or likelihood of any of the classes C2, and C1 being the appropriate label for the case given here. As a result, it's safe to say that C2 is the most likely label for this situation and F1 is identified as the most influential feature whereas F2, F4, and F5 have very low contributions to the decision made by the classification algorithm with respect to the given case. In addition, F8, F3, F10, F9, F6, and F7 have moderate contributions higher than F2, F4, and F5 but lower than F1. Despite the strong positive influence of F1 and F3 supporting the assignment of C2, the negative influence of F8, F10, F9, F7, and F5 shift the classification judgment fairly towards the C1 label which explains the 46.22% likelihood.\",\n",
       " \"The output decision for the provided data is C1, with a very high confidence level, based on the output prediction probabilities across the two classes since C2 has a probability of around 0.00%. F9, F4, and F10 are the most influential factors in the above-mentioned label assignment, however F7 and F5 are the least influential. The unusually high degree of confidence associated with the classification choice in this case might be attributable to the fact that the bulk of the input variables exhibit attributions that improve the model's responsiveness towards label C1. F3, F6, and F7 have only the negative contributions, attempting to persuade the model to classify this case as C2. To cut a long story short, the joint contribution of the negative variables is quite low in comparison to that of the positive variables, resulting in the model's certainty in the decision above.\",\n",
       " \"When given the task of labelling the given case one of the possible labels, C2 and C1, the model assigns C2 as the most likely correct label, with a confidence level of roughly 99.90%. This degree of confidence indicates that the likelihood of C1 being the right designation is merely 0.10%. According to the attribution analysis, each variable has a distinct degree of effect or contribution to the model's arriving at the above-mentioned classification. F3, F4, F1, and F7 are the features accounting for the model's extremely high confidence in the assigned label. In fact, the only input variables having a negative impact are also the least relevant ones, F2 and F5.\",\n",
       " 'According to the classification model employed here, the most probable label for the given case is C2 with a confidence level equal to 98.97%.  Per the attributions analysis, F4 and F8 are the most significant and influential features driving label selection. The least ranked features are F6 and F2, while F1, F7, F5, and F3 have moderate contributions. Negatively supporting the above classification output are F8, F5, and F3, pushing the model to assign the alternative label. However, given the fact that the prediction probability of C1 is only 1.03%, it can be concluded that the joint positive influence of F4, F1, F7, F6, and F2 strongly drives the model to label the case as C2 instead of C1.',\n",
       " \"The classifier is quite sure that the right label for the data given is C2 based on the influence of variables such as F7, F2, F5, and F11. There is a 10.0% chance that the correct label is C1 and per the attributions examination conducted, the bulk of the traits contribute positively, with only three contributing negatively. The negative variables are F11, F8, and F9, which reduce the classifier's preference for C2. F7, F2, and F5 are notable positive variables that boost the classifier's response to outputting C2 rather than C1. All in all, the classifier's confidence in this prediction may be attributed to the fact that the negative variables only have a minor influence on the prediction choice here.\",\n",
       " 'C2 was assigned to the given case by the classifier with a likelihood of 93.32%, leaving thhe likelihood of the C1 equal to only 6.68%. The most influential features were F3, F5, and F14. The remaining features with non-zero attributions are F20, F1, F12, F7, F33, F18, F10, F17, F27, F26, F19, F32, F11, F16, F31, and finally F21. F3 and F5 were highly influential in the positive direction, increasing the odds of the predicted label being correct, whereas F14 had a negative impact, driving the prediction in favour of a different label. Furthermore, F20 had a positive impact on the prediction, whereas F1 and F12 negatively influenced the prediction. Finally, the features that we can say have no impact at all on the prediction made here are as follows: F4, F22, F24, F9, and F15.',\n",
       " 'With moderately high confidence, the classifier indicates that the most probable label for the given data is C1 with only just a 21.80% chance that it could be C2. The main driving features for the above classification or prediction decision are F15 and F14. The remaining features such as F9, F2, F13, and F19 have moderate to low influence on the above decision. Inspecting the attributions of the the input features showed that the ones with negative impact or contribution are F9, F19, F5, F10, and F18. From the attributions, we can see that the remaining features have positive contributions or influence and as a matter of fact, the certainty of the classifier for this classification can be attributed mainly to the strong positive contributions of F15 and F14 coupled with the contributions of the other positive features such as F2, F13, F11, and F17.',\n",
       " 'Given the fact that the likelihood of C1 being the correct label for the case under consideration is only 36.34%, the model assigns the label C2. The prediction decision between the two classes is highly based on the values of the features F3, F6, F14, and F10, whereas  those with the least attributions or contributions regarding this label assignment are F5 and F8. Among the top influential features, F3 and F6 have very strong positive contributions, increasing the probability of the label C2, while the value of F14 value suggests the other label, C1, could be the true label. This pull or shift towards label C1 is further supported by the values of F11, F4, F1, F13, F5, and F16. Conversely, the remaining features, together with F3 and F6, positively encourage the prediction of C2.',\n",
       " 'C3, out of the three potential classes, is the the label assigned with a high probability of 50.0%. However, the classifier indicates that C2 and C1 are equally likely, with a predicted probability of 25.0%. The aforementioned judgement is mostly based on the variables of the given case. The variables F11, F7, and F1 are shown to be the main factors resulting in the classification output decision. The remaining variables, such as F9, F12, and F8, have lower attributions compared to F11, F7, and F1. The attribution analysis also indicated that F11, F7, F1, F12, and F10 are the variables that positively contribute to the decision, meaning they are the ones that shift the classification higher towards C3. On the contrary, F9, F8, F3, F6, and F5 are the top negative variables that steer the decision slightly towards the other labels, C2 and C1. In fact, it is because of these negative variables that the classifier indicates the probabilities across the C1 and C2.',\n",
       " \"The chances of selecting the correct label from one of the possible labels C1, C2, and C3 are 18.51%, 5.86%, and 75.63%, respectively. As a result, it can be deduced that the classifier's anticipated label in this situation is C3. The values of the input features were used as the basis to make the aforementioned prediction judgments. Some of these features have values that positively support the assigned label, while others have values that contradict the classifier's decision, driving it toward one of the other two labels. F9 is the most influential feature, following which are the variables F10, F1, F7, and F2, enumerated according to their respective relevance to the aforementioned label selection. F9, F7, and F2 are positive features that increase the classifier's response towards generating the C3 label, but F10 and F1 are negative features, lowering the odds of C3 being the correct label. F5, F6, F11, F12, and F3 are features that have a moderate influence on the classifier in this case, while F4 and F8  have only a marginal impact. F10, F1, F11, and F8 are the features that have values supporting the assignment of any of the other labels, while the rest favour the C3 prediction, therefore, the predicted probabilities across labels is unsurprising. Furthermore, the predicted likelihood of C3 is higher than all the other labels which is attributed to the fact that the positive features' combined impact is bigger than negative features' combined impact.\",\n",
       " 'In this case, the model expects C1 to be a label since the probability that the label is the alternative class C2 is only 1.94%. This means that the model has a lot of confidence in the selected label, C1. F34 and F29 are the two most important prediction variables positively controlling the assignment of C1 in this case. Other variables that contributed positively to this prediction included F18, F3, F14, F37, and F23. On the other hand, the values F4, F39, F27, and F21 constitute a feature set with a negative impact on the above prediction decision. However, the above features have little effect on the model compared to the F38, F23, F3, and F29, which may explain why the model is confident that the true label is probably C1. Finally, for the case under consideration, F7, F16, F41, F12, F42, and F10 are some of the features, with practically no effect on the prediction decisions of the model, hence they can be considered negligible to the classification here.',\n",
       " \"The following classification assertions are based on the information provided on the case under consideration. The most probable or likely label judged by the classifier is C1 since its prediction probability is 60.0% compared to the 40.0% of C2. The influence of the features on the classifier's decision here can be ranked in the order F7, F10, F2, F9, F4, F5, F6, F8, F3, F1, F11. In fact, with the exception of F11, all the features are shown to have attributions, resulting in the predicted probabilities across the labels. The F7, F10, F2, and F3 have negative contributions, leading to the classifier's confidence in the validity of the C1 label and this is because they are the features that support labelling the case as C2. However, the positive features F9, F4, F5, F6, F8, and F1 tip the scales higher in favour of C1. Since the most influential features F7, F10, and F2 have negative contributions, it is not surprising that the classifier has the probability of C2 equal to just about 40.0%.\",\n",
       " \"At a confidence level of 100.0%, the model labels this case as C1 and what this indicate is that there is no chance for C2 to be the correct label given the values of the input features. The above classification decision can be attributed to values for features such as F4, F3, F7, F21, F20, and F8. For this C1 prediction, the most important features are F4, F3, and F7. These are all positive features, meaning they strongly support the model's decision with respect to the case under consideration and a further push towards the assigned label is offered by the contributions of the other positive features such as F20, F8, F12, and F5. On the other hand, shifting the decision in the opposite direction are the negative features such as F21, F22, F19, F1, and F10. However, compared to F4, F3, and F7, the joint influence of the negative features mentioned above is weak. Finally, the values of the features F13 and F2, both with almost zero attributions, are not relevant when it comes to deciding the correct label for this case.\",\n",
       " 'For the case under consideration here, there is a 70.83% probability that the true label is C1 and what this means is that there is also a 29.71% chance that C2 could be the correct label. Among the features, the top two most impactful are F1 and F4. The next features, ranked in order of the magnitude of their respective attribution are F5, F7, F8, F9, F6, F3, and F2. Out of the nine features, only three of them have values pushing for the prediction of label C2 while the rest are referred to as positive features given that their values motivate the prediction of class C1. The three attributes with the negative impact, shifting the prediction decision away from C1, are F4, F5, and F7. The collective influence of positive features is higher than that of negative features F4, F5, and F7.',\n",
       " 'The algorithm labels the data given as C1 and the prediction probabilities across the possible labels C1 and C2, respectively, are 51.39% and 48.61%. Judging based on the prediction probabilities, the algorithm shows signs of uncertainty in the above decision. F7, F8, F6, and F1 are the primary contributors to the classification verdict here. The contributions of F1, F2, and F3 are moderate, while those of F9, F5, and F8 are lower compared to the other variables. Positively supporting the classification are F7, F6, F5, and F4, while all the remaining variables have a negative impact that decreases the probability of C1 being the correct label. F8, F1, and F2 are negative variables that can be blamed for the uncertainty in the classification decision being made here.',\n",
       " 'The label assignment decision is solely based on the values of the different input features passed to the classification algorithm since the values of these features are used as the basis to make the prediction judgments. The likelihood of any of the classes C2 and C1 being the correct label is 76.26% and 23.74%, respectively, therefore, it is valid to assert that the true label for this case is C2. From the attribution analysis, F14, F6, and F11 have the highest contribution to the decision, whilst F16 and F13 are the least relevant features. In between these two ends are the moderately influential features, such as F8, F10, F9, F15, and F1. Furthermore, the negative features F6, F9, F3, F7, F2, F4, and F16 can be blamed for the fact that the algorithm is not 100.0% certain about the labelling decision and this mainly because the negative features contribute towards choosing C1 instead of C2. Conversely, the positive features such as F14, F11, F8, F10, F15, F1, and F5 are the ones driving the decision higher towards C2.',\n",
       " 'Here the classifier labels the given case as C1 with a moderately high confidence level. Specifically, the prediction likelihood of class C2 is only 21.67%. The main drivers for the classification above are F26, F36, F18, and F34. Among these top features, F26 and F36 have the most significant influence on the classification outcome, and they happen to have positive contributions, increasing the likelihood of class C1. On the other hand, the F34, F18, and F14 have a moderate negative contribution, reducing the odds of a C1 prediction. F8, F19, F16, and F39 are other notable positive features, while F20, F11, F33, and F1 are notable negative features. However, the classifier did not take into account all of the input features when arriving at the above-mentioned classification verdict; the features including F41, F37, and F30 are deemed irrelevant. To summarise, considering the attributions of influential features such as F26, F36, and F34, it is evident why the classifier is quite certain that C1 is the most probable label for the given case.',\n",
       " 'The label assigned in this case by the classifier is C3, with a moderately high prediction confidence of 66.11%. Since the confidence level with respect to this C3 is not 100.0%, it is possible that one of the other labels is the true or correct label, and C2 is the next most likely label. The input variables F4, F5, F3, and F6 have a significant impact on the abovementioned prediction judgement. The value of features F4, F3, F9, and F11 contributes positively to the C3 label, instead of the other labels. F5, F6, F1, and F2 are the variables having a contradictory influence, shifting the final decision in the direction of the other labels. The remaining positive variables are F8, F12, F10, and F7. Of all the predictors, the ones that contributed the least to the prediction included F1, F10, F2, and F7. In summary, given the attributions of the predictors, it is clear why the classifier indicates that C3 is the correct class in this scenario.',\n",
       " 'The classification assertions arrived here are mainly based on the influence and contributions of the different input variables. The prediction probabilities across the four possible classes C3, C2, C4, and C1 are 0.05%, 0.04%, 0.47%, and 99.45%, respectively.  Therefore according to the classifier, the most likely class label for the case under investigation is C1 and it is quite sure that neither C4 nor C3 nor C2  is the true label here. The influence of F11 is shown to be the major contributing factor resulting in the prediction decision made by the classifier and the contributions of the remaining features such as F6, F15, F12, and F8 are moderately low compared to that of F11. The strong positive influence of F11 coupled with other positive features such as F12, F20, and F8 can explain the very high confidence level in the prediction decision. On the flip-side, the input features F6, F15, and F17 are considered negatives since their attributions marginally reduce the prediction probability of the C1 label.',\n",
       " 'The prediction likelihood of class C2 is 84.87%, making it the most probable label for the given case. When making the above prediction, the most relevant features considered are F2, F7, F1, and F3. Conversely, F10, F11, and F9 are the least influential features, with their values receiving little consideration from the model regarding this classification. Assessing the direction of influence or contribution of the features suggest that there is a split between the number of features with a negative influence and those with a positive influence. However, only two of the negative features, F7 and F6, have a somewhat high influence; the others , F5, F10, F11, and F8, have a lower negative influence. To put it concisely, the combined influence of the positive features, such as F2, F3, F4, F12, and F1, outweighs that of all the negative features combined, therefore, it is entirely plausible to see such confidence level of the model for the classification here.',\n",
       " 'With respect to the given case, the most probable label for the given case is C2, with a 99.81% chance of being the correct label, therefore the probability of C1 is only 0.19% for this case. Among the input variables, only four features are shown to have a negative influence on the classification decision above: F3, F14, F12, and F5 since their contributions to the decision only favour labelling the given case as C1 instead. On the flip side, pushing the classification strongly towards C2 are the features F8, F6, F7, and F1 explaining the very high confidence in the choice of label assigned here. ',\n",
       " 'For a particular case, the model predicted the class designation C1 with 75.50% confidence. Based on the attributions analysis, the feature that had the biggest impact on the final labelling decision were the F6 and F1, which happened to strongly support the assignment of label C1. Contributing differently to F6, the feature F3 is the top negative feature, reducing the odds that C1 is the correct label. F7, F4, F3, and F2 have similar influences on the model in terms of the magnitude of their contributions or attributions, however, the directions of their respective effects are different: the features F7 and F4 positively support the model, driving the prediction towards class C1, while F3 and F2 work against it. F9, F5, and F8 are features that have little effect on the model when assigning the label for the given case, and all of them negatively contributed to the C1 class selection. Among all the features with little contribution to the prediction verdict above, F8 is the least relevant.',\n",
       " 'The model reveals that C4 and C3 each has a zero prediction probability, while C1 has a 3.85%. This indicates that C2 is the most likely label for the present context with approximately 96.15% certainty. F7, F11, and F20 are the most important elements driving the above classification, whereas F5, F15, F14, F16, and F13 are the least important. The intermediate elements, which comprise F6, F8, and F12, have varied degrees of influence, ranging from moderate to low. F6 is the only with a negative contribution among the top influential features, F7, F11, F20, F6, and F8, skewing the forecast slightly towards a different possible label. Furthermore, the top two positive elements, F11 and F7, have a greater effect than the sum of all the negative ones.',\n",
       " \"The prediction is that class label C2 is very likely the correct label, given that the associated confidence level is 99.93%. The features F13, F6, and F4 appear to have very smaller or little impact on the prediction of C2 compared to F1, F5, F10, F12, and F9, according to the attribution analysis. F1 and F5 are the features with the highest impact on the model's output prediction verdict above and fortunately the values of these features positively support the C2 classification verdict. Other positive features increasing the odds in favour of C2 include F10, F12, F7, and F8. On the contrarily, the feature F9 negatively influences the model's prediction of C2, shifting the verdict in the opposite direction. It is important to note that, only the features F9, F2, and F4 have negative attributions, while all the remaining ones have positive attributions. The joint positive attribution outweighs the negative attributions from F9, F2, and F4.\",\n",
       " \"For the given case, the model predicted the class label C2 with a certainty of around 75.50%. By far, the feature with the most impact on the final classification was F4, which positively supports the decision. Feature F7 was the feature that contributed the most to pushing away the classification decision from C2, that is, they are decreasing the likelihood of C2 being the correct label. F1, F5, F7, and F8 all had a similar impact on the classification. However, the direction of influence is different, with features F1 and F5 pushing the model's decision to class C2 and features F7 and F8 doing the opposite. F9, F3, and F6 are the features that had closer to negligible impact on the final classification, all of which had a negative contribution towards class C2.\",\n",
       " 'Judging based on the values of the input features, a decision is made by the classifier to label the given data as C2 with a prediction confidence equal to 84.90%. The major influential features resulting in the classification here are F33, F3, F11, and F29. F33 and F3 are identified as the most negative features, with contributions that lead to a decrease in the classification confidence of label C2. F29 and F11, on the other hand, are the top positive features, leading the classifier to label the case as C2. Other notable negative features are F6, F12, and F38 while other notable positives are F35, F20, F2, and F43. Unlike all those mentioned above, F31, F41, F4, and F10 are among the many irrelevant features with negligible contributions to the classification decision here.',\n",
       " \"The prediction model predicts C2 for the case under consideration since the likelihood of C1 which is equal to 30.05%, is lower than that of C2 and this verdict came about mainly based on the values of the input features passed to the model. F10, F7, and F1 are identified as the most influential features with higher impact on the model's labelling decision here and among them F10 and F7 have negative contributions decreasing the model's response towards the assigned label. Furthermore, F1, F6, and F3 have a positive impact on the model and in effect pushes the decision higher towards C2, while F4, F9, and F2 have identical direction of impact as that of F7 and F10. Finally, F8 is the least relevant feature, therefore, its negative attribution has little effect on the model in this case and also the positive influence of F5 further supports the  assigned label.\",\n",
       " 'The model assigned the label C2 to the given instance since its associated likelihood is far higher than C1. The most relevant features controlling the prediction decision above are F1, F3, and F4. The less relevant ones include F5, F9, and F7. The majority of the features have values, swinging the verdict towards the other class, C1. The only features increasing the likelihood or probability of C2 being the correct label are F1, F8, and F9. Given that only few features positively contribute to arriving at the C2 prediction, it is very strange that the model has 100.0% confidence in its prediction for the selected instance.',\n",
       " 'There is an 80.0% chance that the true label for the given case is C1. Nine out of twenty features have a positive impact. Most features have a moderately low positive or negative impact, with the exception of F2, F7, and F16 and it appears as if F2 has an extremely negative impact, while F7 and F16 have the greater positive impacts. F5 has positive impacts, whereas the attributions of the features F1 and F9 are negatives. The least important features include F19, F8, F15, F4, F10, F3, and F20 with varying smaller effects.',\n",
       " \"There is disagreement about which label is acceptable for the case under consideration since the model is unsure which of the two labels is right. The confusion in the aforementioned classification may be attributable only to the effect of F18. F18 is by far the most influential variable, with a negative contribution that reduces the chance of label C2 being the correct label in the given case substantially; supporting the that case should be labelled as C1. Compared to the influence of F18, the remaining variables have a moderate to low effect on the classification decision made here for the case under consideration. F17, F28, and F24 are notable moderately key variables, with positive contributions boosting the likelihood of label C2. F7, F14, F9, F12, F30, F29, F4, F13, F11, and F8 are not among the features demonstrated to contribute to the classification above; since they have very insignificant impact on the model's conclusion here.\",\n",
       " 'For the case under consideration, the probability of C2 being the correct label is only 12.50%, implying that there is an 87.50% chance that C1 is the true label. The decision above was arrived at mainly based on the values of the following variables F3, F2, and F1. Among these top variables, only F3 has a very strong positive impact on the model, increasing the likelihood of C1 prediction. The most important variables decreasing the prediction are F2 and F1 and  the remaining two shifting the verdict away from C1 are F9 and F6. F5 and F4 are the lowest-ranked variables, less important to the prediction made here since they have a moderately low positive impact on the model.',\n",
       " \"With a high degree of confidence, close to 100 percent, the classifier's final label choice for the given case is C1 due to the predicted probability distribution between the class labels. Analysis of the attributions of the input features indicates that the most relevant features driving the classification above are F1, F9, F4, and F5, whereas F10 and F2 are shown to have little contribution to the decision.  Furthermore, only four of the features have a negative influence, swinging the classifier decision in this case towards the C2 label and  they are F9, F14, F10, and F2. However, except for F9, the contribution of the other negative features is very low when compared with the top positive features such as F4, F15, and F5.\",\n",
       " 'Based on the values of the six input features, the model assigned the label C2 to the given case with a higher degree of confidence and according to the model used here, there is a near-zero chance that the label could be C1. Influencing the prediction assessment above are the top four features, F3, F4, and F2, whereas, the least significant feature here is F6. Among the input features, only two, F4 and F6, contradict the label assignment decision above since their values are shifting the label decision in the C1 direction. However, the joint attribution of these features is outweighed by the remaining four features, F3, F2, F5, and F1. This could explain why the model is very certain about the C2 prediction made for the case under consideration.',\n",
       " \"The most likely label for the given data is C1 and this decision is as the result of the variables passed to the classifier. F7, F17, F19, and F14 are the primary contributors to the aforementioned prediction output. F6, F5, F26, F15, F20, and F8, on the other hand, make insignificant contributions to the classifier labelling the given example. F25 and F21, as well as F13, F18, have a moderate influence on the label selection. The classifier's confidence in the label decision above might be explained away by comparing the greater positive attributions of F21, F25, F7, and F14 to the negative attributions of F13, F10, F19, F16, F17, and F22.\",\n",
       " 'Because the prediction algorithm outputs reveal that the likelihood of C1 being the correct label is equal to 93.02%; hence, there is only a little possibility that the true label for the provided data instance is either of the other labels, C3, C2, and C4. The variables F6, F12, F11, and F2 are the most crucial ones driving the label assignment conclusion above, whereas F1, F7, and F3 are the least vital ones. Taking into account the direction of effect of each input feature, as demonstrated by the attribution analysis, it is possible to deduce that the positive features driving the prediction upward towards C1 are F6, F4, F11, F5, F2, F12, and F7. The negative contributions of F8, F10, F3, F1, and F9 are ascribed to the marginal uncertainty in the expected output decision. When the predicted probabilities across the classes are considered, it is possible to infer that the combined positive contribution outranks the negative contributions; therefore, the algorithm is certain that C1 is the real label.',\n",
       " 'Based mainly on the values of the input variables F2, F7, F44, and F8, the predictor classifies the case as C1 with a 90.15% labelling confidence level, indicating that there is only a 9.85% probability that the right label could be C2. Variables that contribute positively to the prediction verdict include F2, F33, F39, and F8. The values of these variables increase the odds of the model labelling the given case as C1. On the other hand, F44, F7, F11, and F36 are the variables influencing the prediction decision in favour of C2 instead of C1. Simply put, the values of these negative variables contradict the label assigned here and finally, the model places little emphasis on the values of features such as F17, F21, F41, and F18 when determining the correct label in this instance, as they have nearly zero influence.',\n",
       " 'The classification output decision is based solely on the information supplied to the model and it predicts class C4 with a higher confidence level, equal to 94.10%, indicating the model is very confident that the correct label for the given case is not either class C3 or class C1 or class C2. The classification output decision with regards to the given case boils down to the values of the features F5, F4, F6, and F3, which are shown to have the most significant influence on the model. Among these relevant features, only F5, F3, and F4 have a positive impact, increasing the response towards labelling the case as C4. Conversely, the remaining ones, F6 and F1, have negative attributions, decreasing the odds of the assigned label. Finally, feature F2 has little impact on this prediction among the features since its value received little consideration from the model.',\n",
       " \"The model predicts that this case is likely C2 with a confidence level equal to 66.80%, meaning there is a 33.20% chance that it could be C1 instead. According to the analysis for this case under consideration, the most relevant features considered by the model are F5, F2, F1, F8, and F7, however, the least relevant features are F9 and F4. The F1, F8, F7, and F6 can be regarded as positively supporting features given that they increase the model's response in favour of the prediction conclusion above. In contrast, the F5, F2, and F3 are the features supporting the prediction of the alternative or other class label C1. Even though only a small number of features support the prediction of C1, their collective or joint influence is enough to upset the joint influence of the other features, leading to the uncertainty of the C2 prediction.\",\n",
       " \"Based on the values of the input variables resulting in the predicted likelihoods across the classes, the classification algorithm is confident that the right label for the provided data is C1. According to the algorithm, there is no possibility that C2 is the correct label. However, the attributions of F13, F11, F3, and F9 indicate that the correct label might be C2 rather than C1. The top four variables are F12, F7, F6, and F8, all of which have a positive influence on the algorithm's prediction output, hence confirming the C1 classification. This conclusion is further supported by the contributions of F2, F10, F1, F5, and F4, which are also positive variables.\",\n",
       " 'With a higher degree of confidence, the classifier assigns the label C2 due to the fact that there is a close to zero chance that C1 is the label. The confidence level with respect to this classification output is largely due to the strong positive influence of F2. However, decreasing the probability that C2 is the true label are the negative features F5, F7, F4, F3, F6, and F9. Furthermore, F1 and F8 also increase the likelihood of C2 being the true label. In conclusion, the joint impact of the negative features is very weak compared to the positive features, hence the strong driving force of the classifier to assign the chosen label, C2.',\n",
       " \"According to the input variables, there is a 99.81% chance that C2 is the correct label for the given data instance, with a prediction probability of the alternative label, C1, equal to 0.19% which shows that there is little chance that C1 is the true label. F2, F9, and F6 are the top contributing features leading to the classification decision here. On the contrary, the F7, F12, and F1 are the least relevant features. The input features with moderate influence are F4, F10, F3, F5, F14, F8, and F13. Even though the different features have some level of influence on the classification, not all of them positively contribute. Actually, F3, F11, F13, and F12 have negative attributions, decreasing the classifier's response towards assigning C2; however, the joint influence of these features is outweighed by the positive attributions of F2, F9, F6, F4, and F10.\",\n",
       " 'With a confidence level equal to 81.43%, the classification algorithm labels the given data as C2, however, there is about an 18.57% chance that C1 could be the right label.  The assignment of C2 to the given case is mainly based on the positive influence and contribution of input features F7, F1, and F6. Furthermore, the majority of the remaining input features have positive contributions, further increasing the predictability of label C2. F5, F10, F4, and F12 are the features with negative contributions, shifting the decision towards C1 instead of C2. Summarizing, comparing the attributions of the negative features to even those of the top three positive features explains why the algorithm is certain that C2 is the right label here.',\n",
       " \"The classification model employed here is very certain that the correct label is C1, implying that there is a near-zero chance that C2 is the label. The top six variables with the most influence on the prediction are all shifting the prediction in favour of C1. This might explain why the model is very certain about the C1 label and these top positive attributes are F14, F19, F29, F6, F38, and F20. F12, F36, F16, F27, and F26 all have moderately low-negative contributions, weakly swinging the direction of the model's decision towards C2. Finally, the decision to label the case as C1 is marginally supported by F2 and F33, whereas F13, F5, and F41 suggest that C2 could be the true label. In conclusion, the very high confidence level with regard to this prediction can be explained away by considering the very strong positive influence of F14, F19, F6, and F29.\",\n",
       " 'For the given case, the model generates the label C2 instead of C1, since C2 has a higher prediction likelihood than C1. According to the attribution graph shown, F7, and F9 are the most influential variables, resulting in the classification verdict above. F1, F4, and F6, on the other hand, are the least important variables considered by the model. F8, F2, F5, and F3 are shown to have a moderate influence on the classification made here. To sum up, with F1, F4, and F6 being the only variables contributing negatively, it is foreseeable why the model is quite certain that C1 is not the correct label for the given case.',\n",
       " 'Per the classifier, the most probable class with a very high confidence level is C1 mainly because the probability that C2 is the correct label is zero. From the attributions analysis, all the inputs are shown to contribute to or influence the above classification. The ranking of the features from the least important to the most important based on their degree of influence is as follows: F3, F5, F8, F2, F6, F7, F1, F4. Simply looking at the attributions of the input features, it is obvious why the classifier is very confident that C2 is not the correct label for the given All the features have positive contributions, resulting in a strong push towards C1.',\n",
       " 'The model predicted the C3 class for the test case with a very high degree of confidence. F2 is the only feature contributing against the prediction of the C3 class, while F3 and F5 contributed positively towards the prediction of C3. In decreasing order, F1, F6 and F4 were the three features with the least positive impact on the prediction of C3. Overall, given that only F2 has negative influence on the decision, it is not surprising to see the associated confidence level of the assigned label.',\n",
       " 'Per the classification algorithm, the most probable class is C2 since the prediction probabilities indicate there is little to no chance that the correct label for the given data instance is any of the following classes: C1, C3, and C4. This labelling is primarily owing to the roles that the features F12, F13, and F3 performed. On the lower end of the spectrum are the input features F6, F17, F10, and F9, which are demonstrated to be less essential for this labelling assignment task. Finally, only F19 and F11 are features having a negative effect, reducing the likelihood of C2 being the accurate classification here.',\n",
       " \"The predicted label is C1 at a confidence level of 92.11%, insinuating that there is a 7.89% chance that the label could be C2. In this case, the feature with the most significant influence on the model's decision is F11, with a very strong positive contribution in support of the C1 prediction. The next set of features with moderately high impact is F4, F6, F10, F2, and F7. Among this set, only F7 and F4 have a negative influence in support of label C2. Finally, on the lower end, the values of F8, F5, and F12 are deemed less important by the model when labelling this case.\",\n",
       " \"Taking into account the values of the input features, the prediction model's output for the case under consideration is C2. Given that there is a 27.27% probability that it could be C1, this labelling decision is not 100.0% certain. For the case under consideration, the label assignment is mainly due to the values of F1, F8, F5, and F10. F10 is identified as the most important or relevant, while F9 is considered the least important, since its contribution to the model is only marginal. In terms of the influence direction of each feature, F10 and F8 have a very strong positive contribution, driving the prediction higher toward the C2 class followed by F1, F5, and F6 all with moderately positive influence, whereas F9 has a negligible positive impact on the model in this case. Finally, for this case, F4, F2, F7, and F3 all have a negative impact on the prediction verdict, however, their pull or influence is not enough to transfer predictions in the direction of another class label, C1. \",\n",
       " 'The prediction output decision by the model is that the likelihood of label C2 is 94.15% and that of class C1 is only around 5.85%, meaning the model is certain that C2 is likely the true label for the given case. First of all, the classification is performed with negligible contributions from the variables F23, F30, F15, F8, and F12 since their attributions are very close to zero. However, examination or inspection of the attributions of the different variables reveals that F14, F25, F7, F13, and F16 are the highly influential ones driving the predicted probabilities across the classes. In addition, the decision about the correct label for this case is moderately influenced by the values of F19, F3, F26, F24, F22, F1, and F2. In terms of the direction of influence or contributions of the variables, F14, F7, F13, F3, and F26 are the top positive variables, encouraging the predicted output to be equal to C2. Pushing the decision towards the C2 label and further away from C1 are the contriutions of the variables F22, F1, F18, and F10. Finally, the 5.85% likelihood of C1 can be attributed to the negative contributions of the top negative variables F25, F16, F10, F24, and F2.',\n",
       " 'The most probable label, according to the classifier for the given data, is C1, which happens to have a higher predicted probability than that of C2.  The major players in the above prediction output are F18, F10, F4, and F16. Conversely, F23, F12, F2, F15, F6, and F17 have negligible contributions when it comes to the classifier labelling the given case. Features such as F11, F14, F21, and F5 have a moderate influence on the decision.  Comparing the stronger positive attributions of F10, F18, F14, and F21 to the negative attributions of F4, F16, F11, F19, F3, and F20 could explain why the classifier is quite confident in the label choice above.',\n",
       " \"The most likely label is C4 since there is a 30.83% chance it could be C1, a 35.74% chance it could be C4, and a 33.42% chance it could be C3. Therefore, the correct label is not C2, which the model is very certain about. The above decision is primarily controlled by the values F1, F6, F4, and F5 which are shown to have positive influences that support the model's classification judgement here. In contrast, the remaining features F2 and F3 negatively support the classification decision, decreasing the chances of C4 being the correct label. In view of the fact that the probability distributions across the classes, we can conclude that the model is very uncertain about which label is appropriate for the given data instance and the features F2 and F3 should be blamed for this.\",\n",
       " \"Because the prediction probability of C2 is equal to 0.0%, the presented case is labelled as C1 with a very high level of confidence. For this classification scenario, the input features that have the greatest influence on the end outcome are F22, F20, F37, and F10. F16, F23, F24, F5, and F19 have a mild impact. However, because F4, F27, F1, and F18 have insignificant attribution values, they have little influence on the model's judgement. Among the top features, F22, F20, F37, and F10, only F22 and F37 exhibit negative attributions that favour the least likely class, C2, whereas F20 and F10 positively support the model's classification result for the provided data. Finally, only F3 and F14 positively contribute to the model's decision among the remaining significant features: F14, F28, F29, F3, F9, F31, and F12.\",\n",
       " 'Between the four possible classes, the label for this case is predicted as C4, with a 73.08% likelihood that this is correct. With a likelihood of about 26.92%, the next probable label is shown to be C1. The prediction assessment above is mainly based on the values of the features F19, F17, F4, F12, and F13. The strongest impact came from F19, followed by F4, F17, F13, and F12. The collective contributions of the positive features F19, F17, F1, and F14 far outweigh the contributions of the negative attributes F4, F13, F12, and F15. Of the twenty attributes, majority of them are shown to have values pushing the prediction towards one of the three other possible classes and as such, it is surprising to see that the model is not 100% confident in the C4 prediction. On the grounds that the likelihood of C4 being correct is 73.08%, we can conclude that the model is quite confident with its final decision for the case under consideration.',\n",
       " 'The model is very certain that the true label for this case is C1. This is because the classifier is 100.0% certain that this is the case and the F40, F8, F5, and F22 are deemed the most important variables, lending to the prediction decision above. Attempting to decrease the confidence in the C1 prediction are the negative variables, mainly F40, F8, F22, F29, and F4. On the other hand, the positive variables driving the decision higher towards C1 are the higher-ranked variables F5, F6, F45, F27, and F36. Finally, there are a lot of other variables not mentioned here, some of which have little to no impact; therefore, their values are likely ignored by the model when making the labelling decision regarding the given case, and some of the insignificant variables are F18, F20, F15, F44, F11, F10, F26, and F3. The very high confidence in the decision is very surprising given that the top two variables, F40 and F8, have negative contributions that should decrease the likelihood of the C1 label, but the model is 100.0% certain that C1 is indeed the true label.',\n",
       " \"The label assigned to the given case is C1, with a likelihood of 91.95%, confirming that the probability of the other class, C2, is 8.05% which is very low. F6, F5, F26, and F11 are the top features significantly motivating the model to output the label C1. Other features with moderate contributions include F20, F25, F1, and F21. On the other hand, the analysis revealed that the features such as F10, F8, and F9 have close to zero influence on the model with respect to the case under consideration here. Increasing the model's response in favour of the generated output label are mainly the features F6, F11, and F21. On the contrary, the decrease in confidence of the prediction output is mainly due to the negative influence of F5, F26, F1, and F25.\",\n",
       " \"The classifier has assigned the label C1 to the given data because it has a predicted probability of roughly 89.16 percent. C2, on the other hand, has a 10.84 percent chance of being correct. The influence and contributions of variables like F1, F5, F2, and F3 influenced and contributed to the classifier's classification conclusion. However, the values of F7 and F9 are given less weight because their impact on the classifier with respect to the current case is minor compared to the other variables. According to the attribution analysis, four factors have negative contributions, pushing the verdict toward C2. These negative variables are F1, F3, F8, and F10, and their influence on the classifier could justify why there is some doubt about the correctness of the C1 class. Overall, F5, F4, F6, and F2 are the notable positive variables that is responsible for the high confidence level associated with the decision here.\",\n",
       " \"As per this prediction, the most likely label for the given case is C1, since its prediction probability is 97.02 percent. The influence of F10, F11, and F13 is mostly to blame for the aforementioned classification decision. F6, F5, and F15 are the feature sets with moderate contributions. F17, F4, F12, and F14, on the other hand, receive limited attention from the algorithm. Given that all four top features provide a strong positive contribution, it's simple to see why the algorithm is confident that C1 is the correct label in this case. Besides, F5, F2, and F7 are all negative features with a moderate to low impact.\",\n",
       " \"The model is not very confident when picking the most probable label for the given case, since there is a 48.38% chance it could be C1 instead. The above classification judgement is mainly based on the influence of the input features F4, F5, and F6. Reducing the likelihood or probability that C2 is the correct label are the variables F4 and F9, with negative contributions that increase the model's response towards assigning the label C1. In point of fact, the very high uncertainty can be blamed on F4 since it is shown to be the most influential feature. The positive influence of F5, F6, F10, F3, F1, and F7 is only enough to push the classification marginally above the threshold in favour of C2. Finally, the values of F2 and F8 receive very little consideration from the model when picking the most probable label for the given case.\",\n",
       " 'The probability that C3 is the correct label is 82.81%, while those of the remaining classes, C2, C1, and C4, respectively, are 0.08%, 1.60%, and 15.52%. Therefore, looking at the prediction confidence level, one can say that even though there is about a 15.52% chance that C4 could be the right label, the model is very certain about the label choice made here. The prediction decision above is mainly based on the values of F1, F4, F3, and F5, whereas F6 and F6 are the least important. Analysis of each feature attribution revealed that, only F2 is revealed to have a negative contribution to the above decision. All the others have positive attributions, shifting the decision in the direction of label C3. ',\n",
       " 'The prediction likelihoods across the two classes, C2 and C1, is 97.82% and 2.18%, respectively. Based on this, the model assigned the given case the label C2. The significant impact on the above prediction decision is the value of F3, while the least significant feature is identified as F1. F11, F13, F5, and F14 among the set of features considered here have values that contradict the C2 prediction which implies that the majority of the features have values driving the model towards predicting C2 for the case under consideration. The top positive features include F3, F4, F7, and F12. On the other hand, F8, F14, and F1 have less influence on the decision made by the model for this case.',\n",
       " \"The case's predicted class is C3, with a likelihood of around 68.12%, C1, with around 29.87%, and C2 with around 2.01%. It is fairly confident of its C3 classification and is very certain that the given case is not class C2. The features with significant attributions leading to the prediction decision above are F10, F8, F2, and F9. The values of F10 and F8 positively contribute to the C3 prediction, whereas F2 and F9 are the top negative features, decreasing the odds of C3 being the correct label for the given case. Unlike the features mentioned above, each of the remaining ones has a small impact on the decision and among them, only F7 and F1 are shown to negatively drive the decision in favour of the alternative labels. Finally, F4 and F6 are the least ranked positive features since their contributions are only marginal compared to the other input features.\",\n",
       " \"The probability that the true label is C1 according to the machine learning model or algorithm based on the input variables is about 80.0% highlighting that the model is fairly confident in the classification decision made here. With the contribution of different variables, the most important variables in this classification decision are F27, F15, F2, F7, and F21. However, according to the ranking of the variables based on the absolute value of their attributions, some of the variables with little effect on the classification verdict above are F12, F33, F14, and F30. Analysing the directions of influence of the features shows that, while the values of F27 and F2 push the prediction decision toward another label, F15 and F21 have strong positive support for the C1 assigned by the model. Other features that positively supported the model's predictions are F7, F5, F38, and F24. In contrast, F6 and F9 have moderate negative effects on the model, shifting the final decision towards the C2 class.\",\n",
       " \"Per the model, the most probable label for the given case is C1, with a prediction likelihood of 83.0%. But, it is important to note that there is a 14.0% chance of the correct label being C2, and a 3.0% chance that it is C3 instead. The most important input feature controlling this classification verdict is F2, with a very strong positive attribution, increasing the chances of a C1. The following variables have values that contradict the model's output in favour of another class label, possibly C2: F11, F10, F1, and F3. However, the impact or effect of the negative features on the model in this prediction case is very low compared to that of F2. Other features that positively contributed to the model's decision for this test case were F7, F9, F5, F12, F8, F4, and F6.\",\n",
       " 'With 100.0% certainty, the model classifies the given example as C2 and this implies that the model is very confident that the correct label is neither C1 nor C3. Analysis of the contributions of the features indicates that the relevant features to a larger extent are F5, F6, and F9. However, the values of F12 and F1 have a very low contribution to the classification decision here. F2, F11, F10, and F8 are the features with moderate influence. The total influence of all the negative features, F11, F3, and F12, is very small compared to even the top positive features, F5, F6, and F9, explaining the confidence level of the model employed for this classification decision.',\n",
       " \"The likelihood of the different classes is 40.0% and 60.0% meaning there is a 60.0% chance that the label for this case should be C1, while there is a 40% chance that it is not. The top features contributing either positively or negatively to the labelling decision above include F11, F6, F1, and F3 with the strongest contribution to the prediction of C1 from F11, followed by F3, F6, and F1. Within the top set of influential features, F3 is pulling the decision threshold in favour of the alternative label C2 and similar to it, the values of F8, F4, F10, and F9 support the prediction of C2, not the assigned C1 label. However, the magnitude of influence from these features is outweighed by the high contributions from F11, F6, F7, F2, and F1. Finally, even though F5 offers support for the C1 prediction, its attribution to the model's decision, in this case, is very marginal.\",\n",
       " \"The classifier is confident that the best class label for this case is C2, given that the prediction probability is approximately 100.0%. It turns out that the values of the features F1, F29, and F27 are the major contributors to the above prediction decision. From analysing their respective attributions, all of these features are shown to have a positive impact on the classifier's output here. Similarly, the features F12, F22, F8, F15, and F20 are valuable, which further motivates the assignment of the label C2 to the case under investigation. However, some input features have a limited influence on the selection of class label here and F6, F25, F9, F16, and F17 are examples of the irrelevant features. Judging based on the features' contributions to the classification verdict above, it is not surprising that the classifier is confident that the probability of a different label is almost zero.\",\n",
       " 'The prediction probabilities of the classes are: C3 is 99.45%, C1 is 0.47%, C2 is 0.04%, and C4 is 0.05%. Therefore, the most probable class is C3, which is associated with a very high prediction confidence. F2 and F16 impact the aforementioned label choice in favour of C3, but F11 has the reverse effect, favouring an alternate label. F12 and F9 both have a comparable amount of negative influence on the C3 prediction, but F10 has a positive impact. With respect to the case given, F8, F14, F15, and F3 all have a marginal impact on the classification result. Finally, F6 and F1 are the least vital or useful features, as they provide little contribution to the model. Considering the contributions or impacts of the input features and also the predicted probabilities across the labels, we can conclude that the model is very certain about the assignment of the C3 class.',\n",
       " \"Regarding the case under investigation, the prediction or classification output verdict is as follows: the probability of having C2 as the label is only 2.06%, while on the other hand, there is a 97.94% chance that C1 is the true label and the classifier is very confident that C2 is not the correct label for the given case. The top two features, with a very strong positive impact, are F38 and F19, which alone can explain why the classifier is very certain that C1 is likely the true label. Other features with moderate contributions are F46, F40, F17, F31, F42, F43, F5, F37, F39, F28, F7, F1, F10, F16, F3, F25, F6, and F27. The marginal drop in the classifier's certainty represented by the 2.06% prediction probability of C2 can be attributed to the negative contributions of features F46, F17, F43, F39, and F5.\",\n",
       " \"The most likely label for the case under consideration, according to the classifier or model, is C2, with a prediction likelihood of 88.0 percent. However, it's worth noting that the accurate label has a 10.0 percent probability of being C1, and a 2.0 percent chance of being C3. F11, with a very strong positive attribution, is the most crucial input variable determining this classification output, raising the likelihood of a C2. F9, F3, F5, and F1 are variables with values that contradict the model's output decision, pushing for the assignment of a different label. However, as compared to F11, the influence or effect of these negative variables on the model is quite modest. F7, F6, F12, F8, F4, F10, and F2 were other factors that favourably influenced the model's choice in this instance. Finally, the model considers F4, F10, and F2 to be the least essential variables.\",\n",
       " \"For the case under consideration here, the model assigned the class C2 with 93.32% as the confidence level. However, the correct class could be different with a probability of about 6%. The abovementioned classification output can be attributed to the influence of the input features F17, F26, F25, F2, F10, F32, and F21, which are shown to have a significant influence on the model. The values of F25, F10, F32, F13, and F21 show the ability to shift the model's selection in favour of label C1 and together, these features reduce the chances of C2 being the correct label. F3, F9, F7, F19, and F23 have a moderate effect on the model's output label here, with each of them increasing the model's response in favour of C1. Finally, the features with negligible influence on the classification decision with respect to the case under consideration here includes F1, F11, F16, F29, F8, and F33.\",\n",
       " 'The likelihood of any of the classes C2, C1, and C3 being the correct label is given as 5.86%, 18.51%, and 75.63%, respectively, therefore, it can be concluded that the predicted label for this case is C3. The above prediction decision is based on the values of the features and some of these features have values supporting the prediction, while others contradict shifting the decision towards any of the other two labels but the collective influence of the positive features outweighs that of the negative features. The feature with the most significant influence on the model was F1 and the features that follow F1 in terms of order of importance to the label assignment decision above are F7, F5, F10, and F9. Supporting the prediction made are the features F1, F10, and F9, while F7 and F5 offer negative attributions to the prediction above. Features with a moderate influence on  C3 prediction include F12, F6, F2, F11, and F3, contrarily, those with the least influence are F8 and F4. With only F7, F5, F2, and F4 have negative attributions supporting the prediction of any of the other labels, while the rest advocate for C3 prediction; it is unexpected to see the probabilities spread across the classes.',\n",
       " 'The case is labelled as C2 by the classifier, with the likelihood of this being correct equal to 94.37%, suggesting that there is a slight chance of about 5.63% that this decision could be wrong. The above prediction by the classifier is mainly based on the values of the features F4, F6, F11, and F7, which, according to the analysis performed, offer very strong positive support for the prediction. The other variables with a positive influence on the decision are F8, F2, and F5, further cementing the belief in the decision made here. The 5.63% likelihood of the C1 can be blamed on the negative influence of F9, F10, F1, and F3, decreasing the likelihood of the C2 label assigned to the case under consideration. In summary, the confidence level of 94.37% in the C2 assignment is mainly due to the strong positive influence of F6, F4, and F7.',\n",
       " 'C2 is the predicted label from the model for this case, and the model is very confident about it since the associated predicted likelihood of C2 is 100.0%. F7, F10, F9, and F1 are shown to be the most relevant features, with values leading to the verdict above. The least significant features are F5, F3, and F13. Based on the analysis, the majority of the features positively support the prediction made for this case; hence it is not very surprising that the model settled on the label C2. The positive features include F7, F10, F1, F12, and F4. The three negative features that moderately shift the labelling decision in the direction of C1 are F9, F11, and F2.',\n",
       " 'There is a high level of uncertainty when it comes to classifying the case here and this is mainly because the label with the highest possibility of 58.75% is C2, while there is a 41.25% chance that it could be C1. The most relevant features in terms of the classification above are F14, F8, F1, F12, and F4. However, F16, F5, and F7 have a marginal impact when classifying the case. The uncertainty could be attributed to the fact that only seven out of sixteen features positively backed the C2 prediction and these are F14, F8, F1, F2, F6, F11, and F5. The values of F12, F4, and F3 have a moderately high negative impact, pushing the prediction in favour of C1.',\n",
       " \"In this scenario, the classifier predicts class label C1 with a high level of confidence while the likelihood of C2 is only 9.35%. All of F1, F2, F3, and F4 contribute chiefly to the classifier's assigning label C1, with F1 being the strongest and F4 being the weakest among the aforementioned attributes. The C1 classification is moderately impacted negatively by features F7 and F5, whereas feature F6 has a large positive influence. Finally, feature F8 has a little negative influence on the C1 classification decision, marginally increasing the likelihood of C2 being the correct label in this instance.\",\n",
       " \"In this case, the prediction probabilities across the classes C1 and C2 are 80.35% and 19.65%, respectively. From the above statement, the most likely label for the given case, as determined by the model, is C1. As a result of the feature attribution analysis, F6, F2, and F15 were identified as the most influential features. However, the model is shown to pay little attention to the values F7, F12, F14, F17, and F18, so they can be considered irrelevant features to the prediction decision here. Based on the direction of influence of the input features, they can be categorised as either positive or negative. Positive features help increase the chances of the most likely label, while negative features increase the model's response in favour of the least likely classes. F15, F6, and F10 are the most highly rated positive features, while F2, F11, and F16 are the most highly rated negative features. Since most of the features are positive, it is not surprising that the model sets C1 as the correct label for the given case.\",\n",
       " 'Considering the values of the input features, the classifier generates the label C2 with close to 100% confidence, since the prediction probability of C1 is only 0.70%. The above classification judgement is mainly due to the influence of the features F9, F10, and F5 mainly because the classifier places more emphasis on their values than the remaining ones. Among these top features, F5 is the one exhibiting negative influence, shifting the prediction decision towards the least probable class, C1 and away from C2. Conversely, F9 and F10 are referred to as positive features since they increase the odds of the assigned C2 label instead of C1. Finally, unlike all the aforementioned, the values of F11, F14, F17, and F12 have little impact on the classification output decision made here.',\n",
       " 'The prediction by the model for the given observation or case is C2, with the likelihood of being correct equal to 64.11%. It is important to note that there is about a 35.89% chance that the alternative label could be the true label. According to the analysis performed, the most relevant features for this prediction are F11, F5, F6, F12, and F10. Among this set of features, F11, F5, and F12 are shown to positively influence the prediction in favour of C2. On the other hand, the values of F6 and F10 suggest the class label could be C1, contributing the most to its associated likelihood of 35.89%. Other features further reducing the probability that C2 is the true label are F3, F2, and F7, but their influence is only marginal. Also, F1, F8, F13, and F4 have positive contributions, further improving the odds in favour of C2 being the true label. In conclusion, the moderately high confidence level is mainly due to the high positive contributions of F11 and F5, which drive the decision towards the C2 label and away from C1.',\n",
       " 'The classifier assigned to the given case the label C2 with a very high prediction confidence level, and the classifier is very certain that C1 is not the correct label. Analysing the contributions of the features towards the prediction decision above shows that the features can be ranked from the most important to the least important in the following order: F1, F10, F5, F2, F6, F4, F3, F7, F8, F9, and F11. The features such as F10, F5, F2, and F6 are the top negatively contributing features. However, F1, F7, F9, and F11 are the only features that positively contribute to the label assigned. The strongest positive contribution is from F1, which also happens to be the most relevant feature when it comes to determining the correct label for the given instance or case. Another observation is that the majority of the input features have a negative influence on the classifier, pushing the prediction for the given instance in a different direction.',\n",
       " \"The classifier predicts class C2 with approximately 99.0% certainty, leaving only a 1.0% chance that C1 is the true label. F29, F9, F88, F17, and F77 are the variables that have the highest cumulative positive effect on the classifier's decision to output C2. F53 also had a big impact, but it is attempting to move the decision away from C2, hence reducing the likelihood of class C2. In addition, F30, F7, F85, F20, F81, F26, and F3 had a moderate positive impact on C2's decision making, although it was still greater than features F44, F31, F27, and F69, which had a moderate negative impact and contributed to the prediction of the C1 class. However, a host of features appear to be less important to predictions here, which denotes that the classifier paid very little or no attention to their values, and these irrelevant variables include F49, F21, F36, F18, F63, and F87.\",\n",
       " 'This case labelled as C2 with 100.0% certainty by the algorithm or model employed here for this classification task hence there is little chance that C1 is the right label choice. The feature with the most influence on the decision is F7, while the least relevant features  and those with little contributions to the decision are F5, F6, and F1. Intermediate features are F8, F3, F2, F9, and F4 and are ordered by their respective attributes on the predicted label. In terms of the impact aspect of each feature, four of the input features have positive attributions in favour of the assigned label, while the remaining five are opposing features, pushing the model in a different direction.  Positive features are F7, F2, F9, and F5, while negative features are F8, F3, F4, F6, and F1.',\n",
       " 'The algorithm labels the given data or case as C2 with a predicted probability equal to 96.77% and this suggests it is very confident that C1 is not the right label.  The features with the most say in the above-mentioned classification verdict include F19, F11, F6, F16, and F26. However, there are a number of features with very close to zero influence on the verdict above, with F4, F24, F27, F10, and F20 being among them. F6, F26, F11, F14, F15, and F3 are the relevant features with negative contributions, pushing the algorithm to label the data instance as C1 instead of C2. And looking at the predicted likelihoods across the classes, we can see that the negative features only manages to decrease the confidence in the assigned label by only 3.23% hence the positive contributions of F19, F2, F22, F8, F1, F9, F13, and F16 strongly or moderately drives the decision towards the final label choice.',\n",
       " 'The test case or example under consideration is labelled as C2 with a modest level of confidence because the probability that C1 is the correct label is approximately 42.17%. The input features with the highest influence on the prediction above are F22, F24, F2, F30, F1, and F6, and those with moderate contributions are F17, F19, F7, F3, F8, F20, and F4. The influence of F9, F26, F13, F28, F14, F21, and F10 can be described as moderately low. However, not all the features are considered by the classifier to arrive at the decision made for the given case. Irrelevant features include F29, F27, F18, and F11. The positive features driving the prediction in favour of the predicted label are F22, F24, F2, F1, F19, F8, and F10. Overall, the majority of the influential features have negative attributions that decrease the probability that C2 is the correct label, explaining the uncertainty associated with the prediction decision made by the classifier.',\n",
       " \"C1 is the label predicted by the model. The model's confidence in the preceding prediction is around 96.35 percent, however, it is vital to remember that there is a very small probability of about 3.65 percent that the right label is C2. The following is an ordering of the input features based on their individual contributions to the aforesaid classification decision: F2, F18, and F19 are the three most important features. Following these variables are F11, F14, F8, F4, F7, F16, F13, F20, F9, F17, F12, F6, and F5 with moderate contributions whereas the values of F10, F1, F3, and F15 have little influence on the prediction of C1. The evaluation assessments below only take into account the variables that have been found to have the most significant influence on the prediction's direction. Among the most influential variables, only F11 and F14 have a negative influence, but the others, F8, F18, F2, and F19, have been shown to make positive contributions to the model's prediction for the case. Therefore, it is not surprising that the label given is C1, with such a higher level of certainty, when considering the cumulative impacts of each pair of positive and negative traits.\",\n",
       " 'The probability of having C1 as a label is only 7.0%, therefore, the most probable class for the given case is C2. The primary drivers decreasing the odds of C2 for the above classification output are the values of the features F2, F6, F4, and F5 with negative contributions. Conversely, the positive contributions of F11, F9, F1, and F3 drive the model towards generating the label C2. In conclusion, the most relevant feature is F11, while F7, and F10 are not as relevant as F11 for the above labelling task.',\n",
       " 'The probability of the label being C2 in this case is 72.83% while there is a 27.07% chance that C1 is the correct class. Among the features, the two most influential are F4 and F3. The remaining features, arranged by the magnitude of their respective influence, are F9, F8, F5, F1, F2, F7, and F6. Of all the input features, only F3, F9, and F8 have implicit values for the estimation of C1. The remainder are termed positive features given that their values motivate the estimation of the C2 class and  their cumulative effect is higher than negative ones.',\n",
       " 'The label assignment here is based on the information supplied to the classifier and the predicted probability of C2 is 48.40% whereas that of C1 is 51.60%. Hence C1 is chosen as the most probable label over C2, however, it is concerning that the classifier is not certain about this verdict given that the difference between the two probabilities is very small. The uncertainty in the classification decision can be attributed to the influence of negative features such as F21, F26, F32, and F18. The contributions of the aforementioned negative features decrease the likelihood of the true label being equal to C1 since they support generating the alternative label, C2 as the likely one and the remaining negative features are F2, F15, F6, F28, and F22. Increasing the prediction probability towards C1 are the positive features such as F8, F11, F14, F13, F30, and F3 which are further supported by the remaining positive features F25, F20, F31, F24, and F33. Aside from all the above-mentioned features, all the remaining features including F27, F19, F12, and F29 have close to zero attributions since their values are somewhat irrelevant to the labelling assignment for the case given here.',\n",
       " 'The label assigned to this test case by the classification model has a 98.21% chance of being C2 and this means that C1 is only about 1.79% likely to be the appropriate class. The contributions of the input features can be ranked as follows: the most powerful set of features is F2, F5, F8, F7, and F10,  the effects of F9, F4, and F11 are moderate, and The F1, F12, F6, and F3 have little or no effect on the prediction above. As expected, given the strong positive contributions of F2, F5, F8, F7, and F10, the prediction decision is C2. Of the features that contributed moderately to predicting this condition, only F9 had a positive effect. The others, F4 and F11, are shifting the classification verdict toward C1, contradicting the assigned label. Similarly, the values of F1, F12, and F3 adversely affect the label assignment decision by the model for the case under consideration.',\n",
       " 'Since the likelihood of C1 is only 9.70%, the classifier generates the label C2 with a confidence level of roughly 91.30% for the provided data or instance. The values of the input features have an impact on the classification above and the classifier ranks the features based on the strength of impact as follows: F1, F3, F4, F7, F2, F6, F5, indicating that F1 is the most significant feature and F5 is the least essential. To summarise, the high level of confidence in the classification may be due to the fact that only F3 and F2 are demonstrated to have negative contributions to the choice, and the combined effect of the negative features is low when compared to F1, F4, and F7.',\n",
       " 'With a higher degree of confidence, the classification model classifies the case under consideration as C2. Specifically, per the model, the probability of labelling the case as C1 is equal to zero. The most influential variables with attributions resulting in the classification above are F1, F2, and F7. The least relevant variables are F9, F14, and F13 judged based on the degree of their respective contributions. Among the input variables, only F11, F12, and F9 have negative contributions that favour assigning the label C1 instead of C2. However, looking the output prediction probabilities across the classes, we can conclude that the positive contributions from variables such as F2, F1, F7, and F3 outweigh the influence of F11, F12, and F9, hence the confidence in the decision above.',\n",
       " \"There is about an 82.0% chance that the true label of the test observation is C1, therefore, the model is quite confident about this labelling decision. In terms of the contributions from the different features, the most important features for this classification decision include F44, F8, F3, and F27. While the values of F44 and F3 are pushing the prediction decision in the direction of the alternative class, F8 and F27, on the other hand, have strong positive support for the label assigned by the model. Other features that positively support the model's prediction are F10, F40, F46, and F28. In contrast, the F33 and F37 have a moderately negative influence on the model, shifting the final decision towards the class label C2. Finally many features are deemed to have insignificant impact on the prediction made for this test case and these include include F7, F12, F41, and F18.\",\n",
       " \"At a confidence level of 100.0%, the model classifies this case as C1. This means that it is almost impossible for C2 to be the correct label according to the model. The above classification conclusions can be boiled down to the values of features such as F22, F19, F13, F1, F10, and F20. For this C1 assignment, the three most relevant features are F22, F19, and F13 which are all positive features; strongly support the model's decision in the case under consideration. Per the attribution analysis, the positive contributions from F22, F19, and F13 towards the assignment is supported are by other remaining positive features include F20, F1, F3, and F16 . On the other hand, negative influences such as F10, F17, F18, F9, and F7 are shifting the prediction in the opposite direction  but the combined effect of the above negative features on the model in this case is weaker than that of F22, F19, and F13. Finally, the values of F5 and F8 are not important when choosing the right label for the given case.\",\n",
       " \"According to the information supplied about the case under consideration, the model outputs C2 as the most probable label since the prediction probability of C1 is only 34.93%. The attributions analysis indicates that F3, F5, F2, and F4 are the most influential features, whereas F7, F1, and F10 receive less attention from the model when classifying the case here. Furthermore, the analysis revealed that the features have different directions of contribution to the prediction made by the model for the given case. The features with positive contributions that motivate the model to output C2 are F5, F3, F7, and F10. F2, F4, F9, F11, and F6 are among the remaining features with negative contributions that reduce the likelihood of the C2, explaining the model's fairly low uncertainty in classification.\",\n",
       " 'Regarding the case under consideration, C2 is the most likely class, and the ML model is very confident about the above prediction since the predicted likelihood or probability associated with class C2 is 99.72%. The following five variables positively affected the prediction of class C2 with the greatest influence: F10, F5, F4, F8, and F9. Furthermore, F3 and F7 had identical levels of influence on predicting C2, with F3 having a slightly stronger effect. While F3 contributed positively to the prediction of C2, there is a negative contribution from F7 supporting the assignment of the least probable class, C1. The least essential variables, F2 and F6, have very little effect on the model and all of them have negative contributions that move the prediction decision or verdict away from C2. The analysis shows that only the variables F7, F6, and F2 have negative attributions, distorting the assignment of C2 or decreasing the odds of the C2 label. However, the mean attribution of F2, F6, and F7 is very low compared to the positive features, so the model relies heavily on the positive features, resulting in the selection of C2 as the most probable class and also the predicted probability of label C1.',\n",
       " \"The case is labelled as C1 by the model, mainly based on the influence of the following features: F9, F1, F5, and F8. Based on the values of these features, the likelihood of the C1 label is 65.51%. The top positively contributing features are F9 and F1, while the top negatively contributing features are F5 and F8. Unlike F9 and F1, which have higher impacts on the model's prediction decision for this case, the positive influence from F7 and F4 is moderately low. Finally, F6, F3, and F2 have negative effects on prediction, however, their attributions are low when compared to F5.\",\n",
       " 'The prediction likelihood of class C2 is 71.87%, making it the most probable label for the given case. When making the above prediction, all of the input features are shown to have some degree of influence on the decision made by the classifier. F5, F1, F11, F8, F10, F7, F3, F4, F12, F9, F2, and F6 are the input features ranked based on their respective influence on the classification decision. Looking at the prediction probabilities across the classes, it can be concluded that there is a 28.13% chance that the true label could be C1. This can be attributed to the negative contributions of F10, F3, F7, F12, F6, and F2. However, when compared with the top positive features, F5, F1, and F11, the attributions of the negative features are moderately low.',\n",
       " \"The model assigned the C2 label to this case with a confidence level of 61.74%. Comparing the input features taken into consideration for this prediction, the feature with the highest impact was F1 with its very strong positive contributions increasing the model's response towards the prediction of the C2 class. All the other features had much less impact, with F31, F14, F10, and F6 all contributing towards C1 in decreasing order of influence. F16 was the next most impacting feature, shifting the prediction towards C2, whereas the features F5 and F4 had a medium degree of influence and were ranked among the most contributing features, respectively. Unfortunately, the values of features such as F19, F30, F28, and F29 are not relevant when deciding the correct label for the given case.\",\n",
       " 'With a higher level of confidence, the case under consideration is labelled as C3. In simple terms, the chance of any other label is zero. The certainty of the classifier can primarily be traced to the influence of F15. Those with moderate influence include F4, F8, F1, and F7. Finally, F11, F6, F14, and F19 are shown to be among the least relevant features. With the most relevant feature, F15, having such a strong positive contribution, it is not strange to see the classifier selecting the label C3 for the given case.',\n",
       " 'The model is very certain that the true label for this case is C1. As shown, the likelihood of this being true is 100.0%. The values of the features F28, F13, and F1 are shown to be primarily responsible for the prediction verdict above and according to the analysis, all of them have a strong positive influence on the model. Similarly, the features F20, F30, F10, F6, and F12 have values, further pushing the model to label the test case as C1. However, there are some attributes with very limited attributions on the prediction decision and these include F25, F5, and F27. Everything considered, it is not strange that the model is very certain about the odds of a different label being close to zero.',\n",
       " 'The classification model or algorithm predicts the C1 label with a 100.0% confidence level. The variables F5 and F1 were the main influences on the prediction. These variables have a strong positive effect and guide the labelling of this case toward C1. F6, F3, and F2 all increase the chances of the case being labelled as C1. Together with the attributions of F5 and F1, it is not surprising that the model argues that C1 is the correct label. Unlike all the variables mentioned above, the value of F4 swings the label assignment in the other direction, towards C2. However, based on the attribution of F4, it is unlikely that C2 could be the label for the case under consideration.']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds['train']['narration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
