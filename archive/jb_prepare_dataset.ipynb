{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import re\n",
                "from collections import Counter\n",
                "import inflect\n",
                "import random"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "random.seed(42)\n",
                "\n",
                "all_train = json.load(open('raw_data/all_train.json',encoding='utf-8'))\n",
                "test = json.load(open('raw_data/test_set_new.json',encoding='utf-8'))\n",
                "all = all_train + test\n",
                "no_task = [x for x in all if x.get('task_name', None) == None]\n",
                "all = [x for x in all if x.get('task_name', None) != None]\n",
                "\n",
                "sign_dict = {'red': 'negative', 'green': 'positive', 'yellow': 'negligible'}\n",
                "\n",
                "for i in range(len(all)):\n",
                "    # Some of the data is in string form, eval() is to convert it to dict\n",
                "    try:\n",
                "        all[i]['feature_division'] = eval(all[i]['feature_division'])\n",
                "    except:\n",
                "        all[i]['feature_division'] = all[i]['feature_division']\n",
                "    all[i]['feature_division']['explainable_df'] = eval(all[i]['feature_division']['explainable_df'])\n",
                "    \n",
                "    # Some of the fields we want are inside the feature_division dict, moving them to the top level\n",
                "    all[i]['values'] = [format(val, '.2f') for val in all[i]['feature_division']['explainable_df']['Values'].values()]\n",
                "    ft_nums =[re.search('F\\d*', val).group() for val in list(all[i]['feature_division']['explainable_df']['annotate_placeholder'].values())]\n",
                "    ft_names = list(all[i]['feature_division']['explainable_df']['Variable'].values())\n",
                "    all[i]['sign'] = [sign_dict[x] for x in all[i]['feature_division']['explainable_df']['Sign'].values()]\n",
                "    all[i]['narrative_id'] = all[i].pop('id')\n",
                "    all[i]['unique_id'] = i\n",
                "    all[i]['classes_dict'] = {v[0].strip(): v[1].strip() for v in [y.split(':') for y in [x for x in all[i]['prediction_confidence_level'].split(',')]]}\n",
                "    all[i]['narrative_questions'] = all[i]['narrative_question'].strip('<ul><li>/ ').split(' </li> <li> ')\n",
                "    \n",
                "    # Shuffle feature names to ensure separation of train and test\n",
                "    new_ft_nums = ft_nums.copy()\n",
                "    random.shuffle(new_ft_nums)\n",
                "    old2new_ft_nums = dict(zip(ft_nums, new_ft_nums))\n",
                "    ft_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_ft_nums.keys()]))\n",
                "    \n",
                "    all[i]['feature_nums'] = new_ft_nums\n",
                "    all[i]['ft_num2name'] = str(dict(zip(new_ft_nums, ft_names)))\n",
                "    all[i]['old2new_ft_nums'] = str(old2new_ft_nums)\n",
                "    all[i]['narration'] = ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], all[i]['narration'])\n",
                "    all[i]['narrative_questions'] = [ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], x) for x in all[i]['narrative_questions']]\n",
                "    \n",
                "    # # Shuffle class names too\n",
                "    new_classes = list(all[i]['classes_dict'].keys()).copy()\n",
                "    random.shuffle(new_classes)\n",
                "    old2new_classes = dict(zip(list(all[i]['classes_dict'].keys()), new_classes))\n",
                "    cls_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_classes.keys()]))\n",
                "    \n",
                "    all[i]['predicted_class'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], all[i]['predicted_class'])\n",
                "    all[i]['narration'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], all[i]['narration'])\n",
                "    all[i]['classes_dict'] = str({old2new_classes[k]: v for k, v in all[i]['classes_dict'].items()})\n",
                "    all[i]['narrative_questions'] = [cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], x) for x in all[i]['narrative_questions']]\n",
                "    all[i]['old2new_classes'] = str(old2new_classes)\n",
                "\n",
                "    \n",
                "    for key in ['deleted', 'mturk_id','narrative_status', 'predicted_class_label', 'date_submitted',\n",
                "                'date_approved', 'features_placeholder', 'is_paid', 'redeem_code', 'narrator',\n",
                "                'user_ip','feature_division', 'narrative_question', 'prediction_confidence_level',\n",
                "                'test_instance', \"prediction_confidence\"]:\n",
                "        try:\n",
                "            all[i].pop(key)\n",
                "        except:\n",
                "            pass\n",
                "# no_task = prepare_all(no_task)\n",
                "json.dump(all, open('data/processed/all.json', 'w', encoding='utf-8'), indent=4)\n",
                "\n",
                "# Split into train, test, val 80:10:10\n",
                "random.shuffle(all)\n",
                "train = all[:int(0.8*len(all))]\n",
                "test = all[int(0.8*len(all)):int(0.9*len(all))]\n",
                "val = all[int(0.9*len(all)):]\n",
                "\n",
                "json.dump(train, open('data/processed/train.json', 'w', encoding='utf-8'), indent=4)\n",
                "json.dump(test, open('data/processed/test.json', 'w', encoding='utf-8'), indent=4)\n",
                "json.dump(val, open('data/processed/val.json', 'w', encoding='utf-8'), indent=4)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "\"{'F14': 'F5', 'F4': 'F8', 'F7': 'F1', 'F6': 'F11', 'F10': 'F7', 'F9': 'F6', 'F15': 'F16', 'F1': 'F15', 'F13': 'F13', 'F11': 'F3', 'F2': 'F14', 'F8': 'F9', 'F12': 'F10', 'F16': 'F2', 'F5': 'F12', 'F3': 'F4'}\""
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train = json.load(open('data/processed/train.json', 'r', encoding='utf-8'))\n",
                "train[0]['old2new_ft_nums']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "sign_dict = {'red': 'negative', 'green': 'positive', 'yellow': 'negligible'}\n",
                "\n",
                "all = train.copy()\n",
                "for i in range(len(all)):\n",
                "    # # Some of the data is in string form, eval() is to convert it to dict\n",
                "    # try:\n",
                "    #     all[i]['feature_division'] = eval(all[i]['feature_division'])\n",
                "    # except:\n",
                "    #     all[i]['feature_division'] = all[i]['feature_division']\n",
                "    # all[i]['feature_division']['explainable_df'] = eval(all[i]['feature_division']['explainable_df'])\n",
                "    \n",
                "    # # Some of the fields we want are inside the feature_division dict, moving them to the top level\n",
                "    # all[i]['values'] = [format(val, '.2f') for val in all[i]['feature_division']['explainable_df']['Values'].values()]\n",
                "    # ft_nums =[re.search('F\\d*', val).group() for val in list(all[i]['feature_division']['explainable_df']['annotate_placeholder'].values())]\n",
                "    # ft_names = list(all[i]['feature_division']['explainable_df']['Variable'].values())\n",
                "    # all[i]['sign'] = [sign_dict[x] for x in all[i]['feature_division']['explainable_df']['Sign'].values()]\n",
                "    # all[i]['narrative_id'] = all[i].pop('id')\n",
                "    # all[i]['unique_id'] = i\n",
                "    # all[i]['classes_dict'] = {v[0].strip(): v[1].strip() for v in [y.split(':') for y in [x for x in all[i]['prediction_confidence_level'].split(',')]]}\n",
                "    # all[i]['narrative_questions'] = all[i]['narrative_question'].strip('<ul><li>/ ').split(' </li> <li> ')\n",
                "    \n",
                "    # Shuffle feature names to ensure separation of train and test\n",
                "    new_ft_nums = all[i]['feature_nums'].copy()\n",
                "    old_ft_nums = eval(all[i]['old2new_ft_nums']).keys()\n",
                "    ft_names = eval(all[i]['ft_num2name']).values()\n",
                "    random.shuffle(new_ft_nums)\n",
                "    old2new_ft_nums = dict(zip(old_ft_nums, new_ft_nums))\n",
                "    ft_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_ft_nums.keys()]))\n",
                "    \n",
                "    all[i]['feature_nums'] = new_ft_nums\n",
                "    all[i]['ft_num2name'] = str(dict(zip(new_ft_nums, ft_names)))\n",
                "    all[i]['old2new_ft_nums'] = str(old2new_ft_nums)\n",
                "    all[i]['narration'] = ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], all[i]['narration'])\n",
                "    all[i]['narrative_questions'] = [ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], x) for x in all[i]['narrative_questions']]\n",
                "    \n",
                "    # # Shuffle class names too\n",
                "    all[i]['classes_dict'] = eval(all[i]['classes_dict'])\n",
                "    new_classes = list(all[i]['classes_dict'].keys()).copy()\n",
                "    random.shuffle(new_classes)\n",
                "    old2new_classes = dict(zip(list(all[i]['classes_dict'].keys()), new_classes))\n",
                "    cls_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_classes.keys()]))\n",
                "    \n",
                "    all[i]['predicted_class'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], all[i]['predicted_class'])\n",
                "    all[i]['narration'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], all[i]['narration'])\n",
                "    all[i]['classes_dict'] = str({old2new_classes[k]: v for k, v in all[i]['classes_dict'].items()})\n",
                "    all[i]['narrative_questions'] = [cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], x) for x in all[i]['narrative_questions']]\n",
                "    all[i]['old2new_classes'] = str(old2new_classes)\n",
                "\n",
                "    \n",
                "    for key in ['deleted', 'mturk_id','narrative_status', 'predicted_class_label', 'date_submitted',\n",
                "                'date_approved', 'features_placeholder', 'is_paid', 'redeem_code', 'narrator',\n",
                "                'user_ip','feature_division', 'narrative_question', 'prediction_confidence_level',\n",
                "                'test_instance', \"prediction_confidence\"]:\n",
                "        try:\n",
                "            all[i].pop(key)\n",
                "        except:\n",
                "            pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'model_name': 'SVC',\n",
                            " 'predicted_class': 'C2',\n",
                            " 'task_name': 'Health Care Services Satisfaction Prediction',\n",
                            " 'narration': \"The prediction probability associated with class C1 and class C2, respectively, is 35.34% and 64.66%. Based on these probabilities, the model labels the given case as C2 since it is the most probable class. According to the attribution analysis, the most relevant features considered by the model here are F2, F1, and F9, while the least relevant features are F10, F12, and F8. Regarding the direction of influence of the features, F2, F1, F9, and F16 are the top positively supporting features, driving the decision higher in favour of C2. Further increasing the probability that C2 is the true label are the values of other positive features such as F3, F11, F5, and F4. To explain why the likelihood of C1 is 35.34%, we have to look at the negative contributions from F13, F14, F7, F12, F10, and F8. The abovementioned negative features contradict the model's decision with respect to the classification outcome.\",\n",
                            " 'values': ['0.05',\n",
                            "  '0.03',\n",
                            "  '0.03',\n",
                            "  '-0.03',\n",
                            "  '0.02',\n",
                            "  '-0.02',\n",
                            "  '0.02',\n",
                            "  '0.02',\n",
                            "  '-0.02',\n",
                            "  '0.02',\n",
                            "  '0.01',\n",
                            "  '0.01',\n",
                            "  '0.00',\n",
                            "  '-0.00',\n",
                            "  '-0.00',\n",
                            "  '-0.00'],\n",
                            " 'sign': ['positive',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'negative',\n",
                            "  'negative'],\n",
                            " 'narrative_id': 208,\n",
                            " 'unique_id': 445,\n",
                            " 'classes_dict': \"{'C1': '35.34%', 'C2': '64.66%'}\",\n",
                            " 'narrative_questions': [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
                            "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
                            "  'Summarize the direction of influence of the features (F14, F3 and F5) with moderate impact on the prediction made for this test case.'],\n",
                            " 'feature_nums': ['F4',\n",
                            "  'F8',\n",
                            "  'F16',\n",
                            "  'F14',\n",
                            "  'F15',\n",
                            "  'F6',\n",
                            "  'F5',\n",
                            "  'F1',\n",
                            "  'F7',\n",
                            "  'F13',\n",
                            "  'F12',\n",
                            "  'F9',\n",
                            "  'F10',\n",
                            "  'F3',\n",
                            "  'F2',\n",
                            "  'F11'],\n",
                            " 'ft_num2name': \"{'F4': 'waiting rooms', 'F8': 'Hygiene and cleaning', 'F16': 'Specialists avaliable', 'F14': 'Quality\\\\\\\\/experience dr.', 'F15': 'Modern equipment', 'F6': 'Exact diagnosis', 'F5': 'hospital rooms quality', 'F1': 'Check up appointment', 'F7': 'avaliablity of drugs', 'F13': 'friendly health care workers', 'F12': 'Time waiting', 'F9': 'Communication with dr', 'F10': 'lab services', 'F3': 'parking, playing rooms, caffes', 'F2': 'Time of appointment', 'F11': 'Admin procedures'}\",\n",
                            " 'old2new_ft_nums': \"{'F14': 'F4', 'F4': 'F8', 'F7': 'F16', 'F6': 'F14', 'F10': 'F15', 'F9': 'F6', 'F15': 'F5', 'F1': 'F1', 'F13': 'F7', 'F11': 'F13', 'F2': 'F12', 'F8': 'F9', 'F12': 'F10', 'F16': 'F3', 'F5': 'F2', 'F3': 'F11'}\",\n",
                            " 'old2new_classes': \"{'C2': 'C1', 'C1': 'C2'}\"}"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'model_name': 'SVC',\n",
                            " 'predicted_class': 'C2',\n",
                            " 'task_name': 'Health Care Services Satisfaction Prediction',\n",
                            " 'narration': \"The prediction probability associated with class C1 and class C2, respectively, is 35.34% and 64.66%. Based on these probabilities, the model labels the given case as C2 since it is the most probable class. According to the attribution analysis, the most relevant features considered by the model here are F2, F1, and F9, while the least relevant features are F10, F12, and F8. Regarding the direction of influence of the features, F2, F1, F9, and F16 are the top positively supporting features, driving the decision higher in favour of C2. Further increasing the probability that C2 is the true label are the values of other positive features such as F3, F11, F5, and F4. To explain why the likelihood of C1 is 35.34%, we have to look at the negative contributions from F13, F14, F7, F12, F10, and F8. The abovementioned negative features contradict the model's decision with respect to the classification outcome.\",\n",
                            " 'values': ['0.05',\n",
                            "  '0.03',\n",
                            "  '0.03',\n",
                            "  '-0.03',\n",
                            "  '0.02',\n",
                            "  '-0.02',\n",
                            "  '0.02',\n",
                            "  '0.02',\n",
                            "  '-0.02',\n",
                            "  '0.02',\n",
                            "  '0.01',\n",
                            "  '0.01',\n",
                            "  '0.00',\n",
                            "  '-0.00',\n",
                            "  '-0.00',\n",
                            "  '-0.00'],\n",
                            " 'sign': ['positive',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'positive',\n",
                            "  'negative',\n",
                            "  'negative',\n",
                            "  'negative'],\n",
                            " 'narrative_id': 208,\n",
                            " 'unique_id': 445,\n",
                            " 'classes_dict': \"{'C1': '35.34%', 'C2': '64.66%'}\",\n",
                            " 'narrative_questions': [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
                            "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
                            "  'Summarize the direction of influence of the features (F14, F3 and F5) with moderate impact on the prediction made for this test case.'],\n",
                            " 'feature_nums': ['F4',\n",
                            "  'F8',\n",
                            "  'F16',\n",
                            "  'F14',\n",
                            "  'F15',\n",
                            "  'F6',\n",
                            "  'F5',\n",
                            "  'F1',\n",
                            "  'F7',\n",
                            "  'F13',\n",
                            "  'F12',\n",
                            "  'F9',\n",
                            "  'F10',\n",
                            "  'F3',\n",
                            "  'F2',\n",
                            "  'F11'],\n",
                            " 'ft_num2name': \"{'F4': 'waiting rooms', 'F8': 'Hygiene and cleaning', 'F16': 'Specialists avaliable', 'F14': 'Quality\\\\\\\\/experience dr.', 'F15': 'Modern equipment', 'F6': 'Exact diagnosis', 'F5': 'hospital rooms quality', 'F1': 'Check up appointment', 'F7': 'avaliablity of drugs', 'F13': 'friendly health care workers', 'F12': 'Time waiting', 'F9': 'Communication with dr', 'F10': 'lab services', 'F3': 'parking, playing rooms, caffes', 'F2': 'Time of appointment', 'F11': 'Admin procedures'}\",\n",
                            " 'old2new_ft_nums': \"{'F14': 'F4', 'F4': 'F8', 'F7': 'F16', 'F6': 'F14', 'F10': 'F15', 'F9': 'F6', 'F15': 'F5', 'F1': 'F1', 'F13': 'F7', 'F11': 'F13', 'F2': 'F12', 'F8': 'F9', 'F12': 'F10', 'F16': 'F3', 'F5': 'F2', 'F3': 'F11'}\",\n",
                            " 'old2new_classes': \"{'C2': 'C1', 'C1': 'C2'}\"}"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Linearisation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Essel is:\n",
                "\n",
                "For non-step wise\n",
                "\n",
                "    'prediction: predictionlabel && predictionlabel: 51.62% && predictionrankB: 48.38% <|section-sep|> featAN featCP featDP featEN featFP featGP featHP featIP <|section-sep|> <mentions> featCP featDP featFP featGP featHP featIP <|section-sep|> featAN featEN <|section-sep|> </mentions> <|section-sep|> <explain> [N0S]'\n",
                "\n",
                "Special tokens are:\n",
                "\n",
                "    additional_vocab = new_tokens = ['[EON]', '[NLS]', '[N9S]',\n",
                "                                        '[N10S]', '[PFS]', '[NFS]', '[IFS]',\n",
                "                                        '[N4S]', '[N5S]', '[N8S]', '[N6S]',\n",
                "                                        '[N7S]', '[N1S]', '[N2S]','[CON]',\n",
                "                                        '[N0S]', '[N3S]']  # +['predictionlabel', 'predictionrankA','predictionrankB', 'predictionrankC', 'predictionrankD', 'predictionrankE']\n",
                "    specials = ['<positives>', '<neutrals>', '<negatives>',\n",
                "                '</positives>', '</negatives>', '</neutrals>',\n",
                "                '<mentions>', \"</mentions>\"]\n",
                "    special_tokens = ['&&',\n",
                "                        '<|>',\n",
                "                        '<full_explain>',\n",
                "                        '<full_narration>',\n",
                "                        \"<next_sequence>\",\n",
                "                        \"</next_sequence>\",\n",
                "                        '<explain>']+specials\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "| F5 | 1st positive 0.05 | F8 | 2nd positive 0.03 | F1 | 3rd positive 0.03 | F11 | 4th negative -0.03 | F7 | 5th positive 0.02 | F6 | 6th negative -0.02 | F16 | 7th positive 0.02 | F15 | 8th positive 0.02 | F13 | 9th negative -0.02 | F3 | 10th positive 0.02 | F14 | 11th positive 0.01 | F9 | 12th positive 0.01 | F10 | 13th positive 0.00 | F2 | 14th negative -0.00 | F12 | 15th negative -0.00 | F4 | 16th negative -0.00\n"
                    ]
                }
            ],
            "source": [
                "'| predicted class | C4 100.00% | other classes | C2 0.00%; C3 0.00%; C1 0.00% |'\n",
                "\n",
                "\n",
                "other_classes = \"&& \".join([f\"{k} {v}\" for k,v in all[0]['classes_dict'].items() if k != all[0][\"predicted_class\"]])\n",
                "just_fts = ' '.join(all[0]['feature_nums'])\n",
                "fts_and_signs = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign'])])\n",
                "fts_and_pos = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign']) if b == 'positive'])\n",
                "fts_and_nega = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign']) if b == 'negative'])\n",
                "fts_and_negl = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign']) if b == 'negligible'])\n",
                "fts_and_negl = 'None' if fts_and_negl == '' else fts_and_negl\n",
                "\n",
                "essel_input = f'| predicted class | {all[0][\"predicted_class\"]} {all[0][\"classes_dict\"][all[0][\"predicted_class\"]]} | other classes | {other_classes} | \\\n",
                "features | {fts_and_signs}| postive features | {fts_and_pos} | negative features | {fts_and_nega} | \\\n",
                "negligible features | {fts_and_negl} |'\n",
                "\n",
                "p = inflect.engine()\n",
                "\n",
                "ordinals = [p.ordinal(i+1) for i in range(len(all[0]['feature_nums']))]\n",
                "\n",
                "features = ' '.join([f'| {o} | {f} {s} {v}' for o, f, s, v in zip(ordinals, all[0]['feature_nums'], all[0]['sign'], all[0]['values'])])\n",
                "    \n",
                "ord_first_input = f'| predicted class | {all[0][\"predicted_class\"]} {all[0][\"classes_dict\"][all[0][\"predicted_class\"]]} | other classes | {other_classes} {features} |'\n",
                "\n",
                "ft_first_input = ' '.join([f'| {f} | {o} {s} {v}' for o, f, s, v in zip(ordinals, all[0]['feature_nums'], all[0]['sign'], all[0]['values'])])\n",
                "\n",
                "print(ft_first_input)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1. For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\n",
                        "2. Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\n",
                        "3. Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case.\n"
                    ]
                }
            ],
            "source": [
                "print('\\n'.join([f'{idx+1}. {q}' for idx, q in enumerate(all[0]['narrative_questions'])]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "| F5 | 1st positive 0.05 | F8 | 2nd positive 0.03 | F1 | 3rd positive 0.03 | F11 | 4th negative -0.03 | F7 | 5th positive 0.02 | F6 | 6th negative -0.02 | F16 | 7th positive 0.02 | F15 | 8th positive 0.02 | F13 | 9th negative -0.02 | F3 | 10th positive 0.02 | F14 | 11th positive 0.01 | F9 | 12th positive 0.01 | F10 | 13th positive 0.00 | F2 | 14th negative -0.00 | F12 | 15th negative -0.00 | F4 | 16th negative -0.00 \n",
                        " <br> <br> Using the above information, answer the following in detail: <br> <br> 1. For this test instance, provide information on the predicted label along with the confidence level of the model's decision. <br> 2. Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction? <br> 3. Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case. <explain>\n"
                    ]
                }
            ],
            "source": [
                "print(f\"{ft_first_input} \\n <br> <br> Using the above information, answer the following in detail: <br> <br> 1. For this test instance, provide information on the predicted label along with the confidence level of the model's decision. <br> 2. Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction? <br> 3. Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case. <explain>\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with 'Python 3.10.6 ('env': venv)' requires ipykernel package.\n",
                        "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: '/home/james/CodingProjects/Local_level_model_explanations/env/bin/python -m pip install ipykernel -U --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "print(ord_first_input)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.6 ('env': venv)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}