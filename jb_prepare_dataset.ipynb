{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import inflect\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "all_train = json.load(open('raw_data/all_train.json',encoding='utf-8'))\n",
    "test = json.load(open('raw_data/test_set_new.json',encoding='utf-8'))\n",
    "all = all_train + test\n",
    "no_task = [x for x in all if x.get('task_name', None) == None]\n",
    "all = [x for x in all if x.get('task_name', None) != None]\n",
    "\n",
    "sign_dict = {'red': 'negative', 'green': 'positive', 'yellow': 'negligible'}\n",
    "\n",
    "for i in range(len(all)):\n",
    "    # Some of the data is in string form, eval() is to convert it to dict\n",
    "    try:\n",
    "        all[i]['feature_division'] = eval(all[i]['feature_division'])\n",
    "    except:\n",
    "        all[i]['feature_division'] = all[i]['feature_division']\n",
    "    all[i]['feature_division']['explainable_df'] = eval(all[i]['feature_division']['explainable_df'])\n",
    "    \n",
    "    # Some of the fields we want are inside the feature_division dict, moving them to the top level\n",
    "    all[i]['values'] = [format(val, '.2f') for val in all[i]['feature_division']['explainable_df']['Values'].values()]\n",
    "    ft_nums =[re.search('F\\d*', val).group() for val in list(all[i]['feature_division']['explainable_df']['annotate_placeholder'].values())]\n",
    "    ft_names = list(all[i]['feature_division']['explainable_df']['Variable'].values())\n",
    "    all[i]['sign'] = [sign_dict[x] for x in all[i]['feature_division']['explainable_df']['Sign'].values()]\n",
    "    all[i]['narrative_id'] = all[i].pop('id')\n",
    "    all[i]['unique_id'] = i\n",
    "    all[i]['classes_dict'] = {v[0].strip(): v[1].strip() for v in [y.split(':') for y in [x for x in all[i]['prediction_confidence_level'].split(',')]]}\n",
    "    all[i]['narrative_questions'] = all[i]['narrative_question'].strip('<ul><li>/ ').split(' </li> <li> ')\n",
    "    \n",
    "    # Shuffle feature names to ensure separation of train and test\n",
    "    new_ft_nums = ft_nums.copy()\n",
    "    random.shuffle(new_ft_nums)\n",
    "    old2new_ft_nums = dict(zip(ft_nums, new_ft_nums))\n",
    "    ft_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_ft_nums.keys()]))\n",
    "    \n",
    "    all[i]['feature_nums'] = new_ft_nums\n",
    "    all[i]['ft_num_to_name'] = str(dict(zip(new_ft_nums, ft_names)))\n",
    "    all[i]['old2new_ft_nums'] = str(old2new_ft_nums)\n",
    "    all[i]['narration'] = ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], all[i]['narration'])\n",
    "    all[i]['narrative_questions'] = [ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], x) for x in all[i]['narrative_questions']]\n",
    "    \n",
    "    # # Shuffle class names too\n",
    "    new_classes = list(all[i]['classes_dict'].keys()).copy()\n",
    "    random.shuffle(new_classes)\n",
    "    old2new_classes = dict(zip(list(all[i]['classes_dict'].keys()), new_classes))\n",
    "    cls_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_classes.keys()]))\n",
    "    \n",
    "    all[i]['predicted_class'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], all[i]['predicted_class'])\n",
    "    all[i]['narration'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], all[i]['narration'])\n",
    "    all[i]['classes_dict'] = str({old2new_classes[k]: v for k, v in all[i]['classes_dict'].items()})\n",
    "    all[i]['narrative_questions'] = [cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], x) for x in all[i]['narrative_questions']]\n",
    "    all[i]['old2new_classes'] = str(old2new_classes)\n",
    "\n",
    "    \n",
    "    for key in ['deleted', 'mturk_id','narrative_status', 'predicted_class_label', 'date_submitted',\n",
    "                'date_approved', 'features_placeholder', 'is_paid', 'redeem_code', 'narrator',\n",
    "                'user_ip','feature_division', 'narrative_question', 'prediction_confidence_level',\n",
    "                'test_instance', \"prediction_confidence\"]:\n",
    "        try:\n",
    "            all[i].pop(key)\n",
    "        except:\n",
    "            pass\n",
    "# no_task = prepare_all(no_task)\n",
    "json.dump(all, open('jb_data/all.json', 'w', encoding='utf-8'), indent=4)\n",
    "\n",
    "# Split into train, test, val 80:10:10\n",
    "random.shuffle(all)\n",
    "train = all[:int(0.8*len(all))]\n",
    "test = all[int(0.8*len(all)):int(0.9*len(all))]\n",
    "val = all[int(0.9*len(all)):]\n",
    "\n",
    "json.dump(train, open('jb_data/train.json', 'w', encoding='utf-8'), indent=4)\n",
    "json.dump(test, open('jb_data/test.json', 'w', encoding='utf-8'), indent=4)\n",
    "json.dump(val, open('jb_data/val.json', 'w', encoding='utf-8'), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'RandomForestClassifier',\n",
       " 'predicted_class': 'C1',\n",
       " 'task_name': 'Used Cars Price-Range Prediction',\n",
       " 'narration': \"Per the model, class C2 has a prediction probability of 10.50 percent, whereas class C1 has a predicted probability of 89.50 percent. As a result of the model, it can be determined that C1 is the most likely label for the given scenario. All of the input features are shown to contribute to the above conclusion, with F1, F7, and F3 having the most influence on the classification decision. The least influential features with regard to this classification are F5, F2, F10, and F4, whereas, the impact of F8, F6, and F9 can be classified as modest. The large positive contributions of F7 and F1 are responsible for the model's high confidence which further supported by the positive contributions of F8, F5, and F2. In conclusion, the negative features F3, F6, F10, F9, and F4 favour labelling the case as C2 hence the associated predicted probability.\",\n",
       " 'values': ['0.24',\n",
       "  '0.23',\n",
       "  '-0.14',\n",
       "  '0.12',\n",
       "  '-0.10',\n",
       "  '-0.03',\n",
       "  '0.01',\n",
       "  '-0.01',\n",
       "  '0.01',\n",
       "  '-0.00'],\n",
       " 'sign': ['positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'negative'],\n",
       " 'narrative_id': 259,\n",
       " 'unique_id': 334,\n",
       " 'classes_dict': {'C2': '10.50%', 'C1': '89.50%'},\n",
       " 'narrative_questions': [\"For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\",\n",
       "  \"Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\",\n",
       "  'Summarize the direction of influence of the features (F9, F5 and F10) with moderate impact on the prediction made for this test case.'],\n",
       " 'feature_nums': ['F7', 'F1', 'F3', 'F8', 'F6', 'F9', 'F5', 'F10', 'F2', 'F4'],\n",
       " 'ft_num_to_name': {'F7': 'Power',\n",
       "  'F1': 'car_age',\n",
       "  'F3': 'Transmission',\n",
       "  'F8': 'Fuel_Type',\n",
       "  'F6': 'Name',\n",
       "  'F9': 'Mileage',\n",
       "  'F5': 'Engine',\n",
       "  'F10': 'Owner_Type',\n",
       "  'F2': 'Kilometers_Driven',\n",
       "  'F4': 'Seats'},\n",
       " 'old2new_ft_nums': {'F4': 'F7',\n",
       "  'F5': 'F1',\n",
       "  'F8': 'F3',\n",
       "  'F7': 'F8',\n",
       "  'F6': 'F6',\n",
       "  'F2': 'F9',\n",
       "  'F3': 'F5',\n",
       "  'F9': 'F10',\n",
       "  'F1': 'F2',\n",
       "  'F10': 'F4'},\n",
       " 'old2new_classes': {'C1': 'C2', 'C2': 'C1'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essel is:\n",
    "\n",
    "For non-step wise\n",
    "\n",
    "    'prediction: predictionlabel && predictionlabel: 51.62% && predictionrankB: 48.38% <|section-sep|> featAN featCP featDP featEN featFP featGP featHP featIP <|section-sep|> <mentions> featCP featDP featFP featGP featHP featIP <|section-sep|> featAN featEN <|section-sep|> </mentions> <|section-sep|> <explain> [N0S]'\n",
    "\n",
    "Special tokens are:\n",
    "\n",
    "    additional_vocab = new_tokens = ['[EON]', '[NLS]', '[N9S]',\n",
    "                                        '[N10S]', '[PFS]', '[NFS]', '[IFS]',\n",
    "                                        '[N4S]', '[N5S]', '[N8S]', '[N6S]',\n",
    "                                        '[N7S]', '[N1S]', '[N2S]','[CON]',\n",
    "                                        '[N0S]', '[N3S]']  # +['predictionlabel', 'predictionrankA','predictionrankB', 'predictionrankC', 'predictionrankD', 'predictionrankE']\n",
    "    specials = ['<positives>', '<neutrals>', '<negatives>',\n",
    "                '</positives>', '</negatives>', '</neutrals>',\n",
    "                '<mentions>', \"</mentions>\"]\n",
    "    special_tokens = ['&&',\n",
    "                        '<|>',\n",
    "                        '<full_explain>',\n",
    "                        '<full_narration>',\n",
    "                        \"<next_sequence>\",\n",
    "                        \"</next_sequence>\",\n",
    "                        '<explain>']+specials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| F5 | 1st positive 0.05 | F8 | 2nd positive 0.03 | F1 | 3rd positive 0.03 | F11 | 4th negative -0.03 | F7 | 5th positive 0.02 | F6 | 6th negative -0.02 | F16 | 7th positive 0.02 | F15 | 8th positive 0.02 | F13 | 9th negative -0.02 | F3 | 10th positive 0.02 | F14 | 11th positive 0.01 | F9 | 12th positive 0.01 | F10 | 13th positive 0.00 | F2 | 14th negative -0.00 | F12 | 15th negative -0.00 | F4 | 16th negative -0.00\n"
     ]
    }
   ],
   "source": [
    "'| predicted class | C4 100.00% | other classes | C2 0.00%; C3 0.00%; C1 0.00% |'\n",
    "\n",
    "\n",
    "other_classes = \"&& \".join([f\"{k} {v}\" for k,v in all[0]['classes_dict'].items() if k != all[0][\"predicted_class\"]])\n",
    "just_fts = ' '.join(all[0]['feature_nums'])\n",
    "fts_and_signs = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign'])])\n",
    "fts_and_pos = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign']) if b == 'positive'])\n",
    "fts_and_nega = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign']) if b == 'negative'])\n",
    "fts_and_negl = \"&& \".join([f'{a} {b} ' for a, b in zip(all[0]['feature_nums'], all[0]['sign']) if b == 'negligible'])\n",
    "fts_and_negl = 'None' if fts_and_negl == '' else fts_and_negl\n",
    "\n",
    "essel_input = f'| predicted class | {all[0][\"predicted_class\"]} {all[0][\"classes_dict\"][all[0][\"predicted_class\"]]} | other classes | {other_classes} | \\\n",
    "features | {fts_and_signs}| postive features | {fts_and_pos} | negative features | {fts_and_nega} | \\\n",
    "negligible features | {fts_and_negl} |'\n",
    "\n",
    "p = inflect.engine()\n",
    "\n",
    "ordinals = [p.ordinal(i+1) for i in range(len(all[0]['feature_nums']))]\n",
    "\n",
    "features = ' '.join([f'| {o} | {f} {s} {v}' for o, f, s, v in zip(ordinals, all[0]['feature_nums'], all[0]['sign'], all[0]['values'])])\n",
    "    \n",
    "ord_first_input = f'| predicted class | {all[0][\"predicted_class\"]} {all[0][\"classes_dict\"][all[0][\"predicted_class\"]]} | other classes | {other_classes} {features} |'\n",
    "\n",
    "ft_first_input = ' '.join([f'| {f} | {o} {s} {v}' for o, f, s, v in zip(ordinals, all[0]['feature_nums'], all[0]['sign'], all[0]['values'])])\n",
    "\n",
    "print(ft_first_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\n",
      "2. Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\n",
      "3. Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case.\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([f'{idx+1}. {q}' for idx, q in enumerate(all[0]['narrative_questions'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| F5 | 1st positive 0.05 | F8 | 2nd positive 0.03 | F1 | 3rd positive 0.03 | F11 | 4th negative -0.03 | F7 | 5th positive 0.02 | F6 | 6th negative -0.02 | F16 | 7th positive 0.02 | F15 | 8th positive 0.02 | F13 | 9th negative -0.02 | F3 | 10th positive 0.02 | F14 | 11th positive 0.01 | F9 | 12th positive 0.01 | F10 | 13th positive 0.00 | F2 | 14th negative -0.00 | F12 | 15th negative -0.00 | F4 | 16th negative -0.00 \n",
      " <br> <br> Using the above information, answer the following in detail: <br> <br> 1. For this test instance, provide information on the predicted label along with the confidence level of the model's decision. <br> 2. Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction? <br> 3. Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case. <explain>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{ft_first_input} \\n <br> <br> Using the above information, answer the following in detail: <br> <br> 1. For this test instance, provide information on the predicted label along with the confidence level of the model's decision. <br> 2. Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction? <br> 3. Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case. <explain>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 ('env': venv)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/james/CodingProjects/Local_level_model_explanations/env/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(ord_first_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
