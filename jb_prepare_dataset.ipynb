{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import inflect\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "all_train = json.load(open('raw_data/all_train.json',encoding='utf-8'))\n",
    "test = json.load(open('raw_data/test_set_new.json',encoding='utf-8'))\n",
    "all = all_train + test\n",
    "no_task = [x for x in all if x.get('task_name', None) == None]\n",
    "all = [x for x in all if x.get('task_name', None) != None]\n",
    "\n",
    "def prepare_dataset(dataset):\n",
    "    sign_dict = {'red': 'negative', 'green': 'positive', 'yellow': 'negligible'}\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        # Some of the data is in string form, eval() is to convert it to dict\n",
    "        try:\n",
    "            dataset[i]['feature_division'] = eval(dataset[i]['feature_division'])\n",
    "        except:\n",
    "            dataset[i]['feature_division'] = dataset[i]['feature_division']\n",
    "        dataset[i]['feature_division']['explainable_df'] = eval(dataset[i]['feature_division']['explainable_df'])\n",
    "        \n",
    "        # Some of the fields we want are inside the feature_division dict, moving them to the top level\n",
    "        dataset[i]['values'] = [format(val, '.2f') for val in dataset[i]['feature_division']['explainable_df']['Values'].values()]\n",
    "        ft_nums =[re.search('F\\d*', val).group() for val in list(dataset[i]['feature_division']['explainable_df']['annotate_placeholder'].values())]\n",
    "        ft_names = list(dataset[i]['feature_division']['explainable_df']['Variable'].values())\n",
    "        dataset[i]['sign'] = [sign_dict[x] for x in dataset[i]['feature_division']['explainable_df']['Sign'].values()]\n",
    "        dataset[i]['narrative_id'] = dataset[i].pop('id')\n",
    "        dataset[i]['unique_id'] = i\n",
    "        dataset[i]['classes_dict'] = {v[0].strip(): v[1].strip() for v in [y.split(':') for y in [x for x in dataset[i]['prediction_confidence_level'].split(',')]]}\n",
    "        dataset[i]['narrative_questions'] = dataset[i]['narrative_question'].strip('<ul><li>/ ').split(' </li> <li> ')\n",
    "        \n",
    "        # Shuffle feature names to ensure separation of train and test\n",
    "        new_ft_nums = ft_nums.copy()\n",
    "        random.shuffle(new_ft_nums)\n",
    "        old2new_ft_nums = dict(zip(ft_nums, new_ft_nums))\n",
    "        ft_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_ft_nums.keys()]))\n",
    "        \n",
    "        dataset[i]['feature_nums'] = new_ft_nums\n",
    "        dataset[i]['ft_num_to_name'] = dict(zip(new_ft_nums, ft_names))\n",
    "        dataset[i]['old2new_ft_nums'] = old2new_ft_nums\n",
    "        dataset[i]['narration'] = ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], dataset[i]['narration'])\n",
    "        dataset[i]['narrative_questions'] = [ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], x) for x in dataset[i]['narrative_questions']]\n",
    "        \n",
    "        # # Shuffle class names too\n",
    "        new_classes = list(dataset[i]['classes_dict'].keys()).copy()\n",
    "        random.shuffle(new_classes)\n",
    "        old2new_classes = dict(zip(list(dataset[i]['classes_dict'].keys()), new_classes))\n",
    "        cls_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_classes.keys()]))\n",
    "        \n",
    "        dataset[i]['predicted_class'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], dataset[i]['predicted_class'])\n",
    "        dataset[i]['narration'] = cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], dataset[i]['narration'])\n",
    "        dataset[i]['classes_dict'] = {old2new_classes[k]: v for k, v in dataset[i]['classes_dict'].items()}\n",
    "        dataset[i]['narrative_questions'] = [cls_ptn.sub(lambda m: old2new_classes[re.escape(m.group(0))], x) for x in dataset[i]['narrative_questions']]\n",
    "        dataset[i]['old2new_classes'] = old2new_classes\n",
    "\n",
    "        \n",
    "        for key in ['deleted', 'mturk_id','narrative_status', 'predicted_class_label', 'date_submitted',\n",
    "                    'date_approved', 'features_placeholder', 'is_paid', 'redeem_code', 'narrator',\n",
    "                    'user_ip','feature_division', 'narrative_question', 'prediction_confidence_level']:\n",
    "            dataset[i].pop(key)\n",
    "        return dataset\n",
    "all = prepare_dataset(all)\n",
    "# no_task = prepare_dataset(no_task)\n",
    "json.dump(all, open('jb_data/all.json', 'w', encoding='utf-8'), indent=4)\n",
    "\n",
    "# Split into train, test, val 80:10:10\n",
    "random.shuffle(all)\n",
    "train = all[:int(0.8*len(all))]\n",
    "test = all[int(0.8*len(all)):int(0.9*len(all))]\n",
    "val = all[int(0.9*len(all)):]\n",
    "\n",
    "json.dump(train, open('jb_data/train.json', 'w', encoding='utf-8'), indent=4)\n",
    "json.dump(test, open('jb_data/test.json', 'w', encoding='utf-8'), indent=4)\n",
    "json.dump(val, open('jb_data/val.json', 'w', encoding='utf-8'), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In summary, the model predicted an 87.14% likelihood of the class label C1 for the test example under consideration, therefore, there is a chance of about 12.86% that the correct class label could be a different label. The features with the highest impact on the model are F23, F24, F18, and F9, whose values are attributing most to the labeling decision here and among these features, only F9 shows the potential to shift the narrative toward a different label. On impact comparison, features F23, F24, F18 and F9 have higher impact on the model prediction than F17 and F6. Features F23, F24, F18, F17, and F6 show a positive impact shifting towards the prediction of C1. F9 is the most negative of all the set of features passed to the model, F1, F25, and F13 have moderate negative influence, whereas the feature F8 has very little negative impact on the prediction.'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ft_nums = ft_nums.copy()\n",
    "random.shuffle(new_ft_nums)\n",
    "old2new_ft_nums = dict(zip(ft_nums, new_ft_nums))\n",
    "ft_ptn = re.compile(\"|\".join([f'{k}\\\\b' for k in old2new_ft_nums.keys()]))\n",
    "ft_ptn.sub(lambda m: old2new_ft_nums[re.escape(m.group(0))], narration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In summary, the model predicted an 87.14% likelihood of the class label C1 for the test example under consideration, therefore, there is a chance of about 12.86% that the correct class label could be a different label. The features with the highest impact on the model are F1, F2, F3, and F11, whose values are attributing most to the labeling decision here and among these features, only F11 shows the potential to shift the narrative toward a different label. On impact comparison, features F1, F2, F3 and F11 have higher impact on the model prediction than F12 and F6. Features F1, F2, F3, F12, and F6 show a positive impact shifting towards the prediction of C1. F11 is the most negative of all the set of features passed to the model, F4, F7, and F10 have moderate negative influence, whereas the feature F8 has very little negative impact on the prediction.'"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F8': 'F8',\n",
       " 'F2': 'F24',\n",
       " 'F1': 'F23',\n",
       " 'F21': 'F20',\n",
       " 'F25': 'F15',\n",
       " 'F10': 'F13',\n",
       " 'F3': 'F18',\n",
       " 'F9': 'F10',\n",
       " 'F15': 'F11',\n",
       " 'F7': 'F25',\n",
       " 'F20': 'F16',\n",
       " 'F12': 'F17',\n",
       " 'F24': 'F21',\n",
       " 'F6': 'F6',\n",
       " 'F17': 'F26',\n",
       " 'F23': 'F5',\n",
       " 'F11': 'F9',\n",
       " 'F22': 'F2',\n",
       " 'F4': 'F1',\n",
       " 'F14': 'F3',\n",
       " 'F19': 'F4',\n",
       " 'F18': 'F12',\n",
       " 'F16': 'F14',\n",
       " 'F13': 'F19',\n",
       " 'F5': 'F7',\n",
       " 'F26': 'F22'}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old2new_ft_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| predicted class | C1 91.36% | other classes | C2 8.64% | features | F3 negative && F4 negative && F6 positive && F12 positive && F11 positive && F14 positive && F13 negative && F9 positive && F10 negative && F15 positive && F5 positive && F7 positive && F2 positive && F8 negative && F1 positive | postive features | F6 positive && F12 positive && F11 positive && F14 positive && F9 positive && F15 positive && F5 positive && F7 positive && F2 positive && F1 positive  | negative features | F3 negative && F4 negative && F13 negative && F10 negative && F8 negative  | negligible features | None |\n",
      "| predicted class | C1 91.36% | other classes | C2 8.64% | 1st | F3 negative -0.30 | 2nd | F4 negative -0.25 | 3rd | F6 positive 0.23 | 4th | F12 positive 0.15 | 5th | F11 positive 0.09 | 6th | F14 positive 0.09 | 7th | F13 negative -0.07 | 8th | F9 positive 0.07 | 9th | F10 negative -0.06 | 10th | F15 positive 0.05 | 11th | F5 positive 0.05 | 12th | F7 positive 0.02 | 13th | F2 positive 0.02 | 14th | F8 negative -0.01 | 15th | F1 positive 0.01 |\n",
      "| F3 | 1st negative -0.30 | F4 | 2nd negative -0.25 | F6 | 3rd positive 0.23 | F12 | 4th positive 0.15 | F11 | 5th positive 0.09 | F14 | 6th positive 0.09 | F13 | 7th negative -0.07 | F9 | 8th positive 0.07 | F10 | 9th negative -0.06 | F15 | 10th positive 0.05 | F5 | 11th positive 0.05 | F7 | 12th positive 0.02 | F2 | 13th positive 0.02 | F8 | 14th negative -0.01 | F1 | 15th positive 0.01\n"
     ]
    }
   ],
   "source": [
    "'| predicted class | C4 100.00% | other classes | C2 0.00%; C3 0.00%; C1 0.00% |'\n",
    "\n",
    "\n",
    "other_classes = \"&& \".join([f\"{k} {v}\" for k,v in dataset[0]['classes_dict'].items() if k != chosen_class])\n",
    "just_fts = ' '.join(dataset[0]['feature_nums'])\n",
    "fts_and_signs = \"&& \".join([f'{a} {b} ' for a, b in zip(dataset[0]['feature_nums'], dataset[0]['sign'])])\n",
    "fts_and_pos = \"&& \".join([f'{a} {b} ' for a, b in zip(dataset[0]['feature_nums'], dataset[0]['sign']) if b == 'positive'])\n",
    "fts_and_nega = \"&& \".join([f'{a} {b} ' for a, b in zip(dataset[0]['feature_nums'], dataset[0]['sign']) if b == 'negative'])\n",
    "fts_and_negl = \"&& \".join([f'{a} {b} ' for a, b in zip(dataset[0]['feature_nums'], dataset[0]['sign']) if b == 'negligible'])\n",
    "fts_and_negl = 'None' if fts_and_negl == '' else fts_and_negl\n",
    "\n",
    "essel_input = f'| predicted class | {chosen_class} {dataset[0][\"classes_dict\"][chosen_class]} | other classes | {other_classes} | \\\n",
    "features | {fts_and_signs}| postive features | {fts_and_pos} | negative features | {fts_and_nega} | \\\n",
    "negligible features | {fts_and_negl} |'\n",
    "\n",
    "p = inflect.engine()\n",
    "\n",
    "ordinals = [p.ordinal(i+1) for i in range(len(dataset[0]['feature_nums']))]\n",
    "\n",
    "features = ' '.join([f'| {o} | {f} {s} {v}' for o, f, s, v in zip(ordinals, dataset[0]['feature_nums'], dataset[0]['sign'], dataset[0]['values'])])\n",
    "    \n",
    "ord_first_input = f'| predicted class | {chosen_class} {dataset[0][\"classes_dict\"][chosen_class]} | other classes | {other_classes} {features} |'\n",
    "\n",
    "ft_first_input = ' '.join([f'| {f} | {o} {s} {v}' for o, f, s, v in zip(ordinals, dataset[0]['feature_nums'], dataset[0]['sign'], dataset[0]['values'])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essels way is like\n",
    "\n",
    "'prediction: predictionlabel && predictionlabel: 69.02% && predictionrankB: 30.98% <|section-sep|> featAP featCN featDP featEN featFN featGP featHP featIP featJP featKP <|section-sep|> <mentions> featAP featDP featGP featHP featIP featJP featKP <|section-sep|> featCN featEN featFN <|section-sep|> </mentions> <|section-sep|> <explain>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Provide a statement summarizing the prediction made for the test case.',\n",
       " 'For the current test instance, describe the direction of influence of the following features: F3 (value equal to  V0) and F4 (with a value equal to  V0).',\n",
       " 'Compare and contrast the impact of the following features  (F6, F12, F11 and F14) on the modelâ€™s prediction of C1.',\n",
       " 'Describe the degree of impact of the following features: F13, F9, F10 and F15?']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset[0]['narrative_question'].strip('<ul><li>/ ').split(' </li> <li> ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| F3 | 1st negative -0.30 | F4 | 2nd negative -0.25 | F6 | 3rd positive 0.23 | F12 | 4th positive 0.15 | F11 | 5th positive 0.09 | F14 | 6th positive 0.09 | F13 | 7th negative -0.07 | F9 | 8th positive 0.07 | F10 | 9th negative -0.06 | F15 | 10th positive 0.05 | F5 | 11th positive 0.05 | F7 | 12th positive 0.02 | F2 | 13th positive 0.02 | F8 | 14th negative -0.01 | F1 | 15th positive 0.01'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([f'| {f} | {o} {s} {v}' for o, f, s, v in zip(ordinals, dataset[0]['feature_nums'], dataset[0]['sign'], dataset[0]['values'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F6 positive && F12 positive && F11 positive && F14 positive && F9 positive && F15 positive && F5 positive && F7 positive && F2 positive && F1 positive '"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"&& \".join([f'{a} {b} ' for a, b in zip(dataset[0]['feature_nums'], dataset[0]['sign']) if b == 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = {'C1': '20.00%', 'C2': '80.00%', 'C3': '0.00%', 'C4': '0.00%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st\n",
      "6th\n",
      "11th\n",
      "16th\n",
      "21st\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
