{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/CodingProjects/Local_level_model_explanations/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-10 12:01:55.012498: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-10 12:01:55.541260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64\n",
      "2022-12-10 12:01:55.541359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64\n",
      "2022-12-10 12:01:55.541364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer, pipeline\n",
    "# import lmap\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from src.data_collator import linearise_input, convert_to_features\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import yaml\n",
    "import argparse\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/CodingProjects/Local_level_model_explanations/env/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Using custom data configuration james-burton--textual-explanations-19ff8605823ae74a\n",
      "Found cached dataset parquet (/home/james/.cache/huggingface/datasets/james-burton___parquet/james-burton--textual-explanations-19ff8605823ae74a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 3/3 [00:00<00:00, 949.22it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base', return_dict=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "dataset = load_dataset(\"james-burton/textual-explanations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 2790.85ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2829.96ex/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 2890.25ex/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "        lambda x: linearise_input(x, 'essel', 15),\n",
    "        load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"| predicted class | C1 64.66% | other classes | C2 35.34% |     features | F5 && F8 && F1 && F11 && F7 && F6 && F16 && F15 && F13 && F3 && F14 && F9 && F10 && F2 && F12 | postive features | F5 && F8 && F1 && F7 && F16 && F15 && F3 && F14 && F9 && F10  | negative features | F11 && F6 && F13 && F2 && F12  |     negligible features | None |\\n <br> <br> Using the above information, answer the following             in detail: <br> <br> 1. For this test instance, provide information on the predicted label along with the confidence level of the model's decision.\\n2. Summarize the top features influencing the model's decision along with the respective directions of influence on the prediction?\\n3. Summarize the direction of influence of the features (F6, F16 and F15) with moderate impact on the prediction made for this test case.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things I need to generate:\n",
    "* predicted_class\n",
    "* classes_dict\n",
    "* feature_nums\n",
    "* sign\n",
    "* values\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'C2': '35.34%', 'C1': '64.66%'}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['classes_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classes_dict():\n",
    "    sign_dict = {1: 'positive', -1: 'negative', 0: 'negligible'}\n",
    "    x = dict()\n",
    "    classes = ['C1', 'C2']\n",
    "    random.shuffle(['C1', 'C2'])\n",
    "    pct = random.randint(500,9500)/100\n",
    "    other_pct = round(100 - pct, 2)\n",
    "    class_dict  = {classes[0]: format(pct, '.2f'), classes[1]: format(other_pct, '.2f')}\n",
    "    x['predicted_class'] = max(class_dict, key=class_dict.get)\n",
    "    x['classes_dict'] = str({f'{k}': f'{v}%' for k,v in class_dict.items()})\n",
    "    x['feature_nums'] = [f'F{i}' for i in random.sample(range(1, 80), 15)]\n",
    "    values = sorted([random.randint(-50,50)/100 for i in range(15)], key=abs, reverse=True)\n",
    "    x['sign'] = [sign_dict[np.sign(i)] for i in values]\n",
    "    x['values'] =  x['values'] = [format(v, '.2f') for v in values]\n",
    "    return x\n",
    "\n",
    "def question_generator(dict):\n",
    "    # 'What is the value of FA?'\n",
    "    choice = random.randint(0,len(dict['feature_nums'])-1)\n",
    "    feat = dict['feature_nums'][choice]\n",
    "    q1 = f'What is the value of {feat}?'\n",
    "    val = dict['values'][choice]\n",
    "    a1 = val\n",
    "    \n",
    "    # What is FA - FB?\n",
    "    choice1 = random.randint(0,len(dict['feature_nums'])-1)\n",
    "    feat1 = dict['feature_nums'][choice1]\n",
    "    val1 = dict['values'][choice1]\n",
    "    choice2 = random.randint(0,len(dict['feature_nums'])-1)\n",
    "    feat2 = dict['feature_nums'][choice2]\n",
    "    val2 = dict['values'][choice2]\n",
    "    q2 = f'What is the difference between {feat1} and {feat2}?'\n",
    "    a2 = format(float(val1) - float(val2), '.2f')\n",
    "    \n",
    "    # What is the xth most important feature?\n",
    "    choice = random.randint(0,len(dict['feature_nums'])-1)\n",
    "    feat = dict['feature_nums'][choice]\n",
    "    q3 = f'What is the {choice+1}th most important feature?'\n",
    "    a3 = feat\n",
    "    \n",
    "    # Top x postive features: \n",
    "    x = random.randint(1,5)\n",
    "    top_x_pos_fts = [ft for ft, sign in zip(dict['feature_nums'],dict['sign']) if sign == 'positive'][:x]\n",
    "    q4 = f'What are the top {x} positive features?'\n",
    "    a4 = ', '.join(top_x_pos_fts)\n",
    "    \n",
    "    # Top x negative features: \n",
    "    x = random.randint(1,5)\n",
    "    top_x_neg_fts = [ft for ft, sign in zip(dict['feature_nums'],dict['sign']) if sign == 'negative'][:x]\n",
    "    q4 = f'What are the top {x} negative features?'\n",
    "    a4 = ', '.join(top_x_neg_fts)\n",
    "    \n",
    "    dict['questions'] = [q1, q2, q3, q4]\n",
    "    dict['answers'] = [a1, a2, a3, a4]\n",
    "    \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_class': 'C2',\n",
       " 'classes_dict': \"{'C1': '11.85%', 'C2': '88.15%'}\",\n",
       " 'feature_nums': ['F65',\n",
       "  'F68',\n",
       "  'F16',\n",
       "  'F51',\n",
       "  'F12',\n",
       "  'F8',\n",
       "  'F61',\n",
       "  'F45',\n",
       "  'F30',\n",
       "  'F13',\n",
       "  'F40',\n",
       "  'F63',\n",
       "  'F56',\n",
       "  'F21',\n",
       "  'F77'],\n",
       " 'sign': ['positive',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'negative'],\n",
       " 'values': ['0.50',\n",
       "  '-0.49',\n",
       "  '-0.49',\n",
       "  '-0.47',\n",
       "  '-0.47',\n",
       "  '-0.45',\n",
       "  '0.35',\n",
       "  '0.35',\n",
       "  '0.34',\n",
       "  '0.28',\n",
       "  '-0.23',\n",
       "  '0.22',\n",
       "  '0.20',\n",
       "  '-0.11',\n",
       "  '-0.01'],\n",
       " 'input': '| predicted class | C2 88.15% | other classes | C1 11.85% | 1st | F65 positive 0.50 | 2nd | F68 negative -0.49 | 3rd | F16 negative -0.49 | 4th | F51 negative -0.47 | 5th | F12 negative -0.47 | 6th | F8 negative -0.45 | 7th | F61 positive 0.35 | 8th | F45 positive 0.35 | 9th | F30 positive 0.34 | 10th | F13 positive 0.28 | 11th | F40 negative -0.23 | 12th | F63 positive 0.22 | 13th | F56 positive 0.20 | 14th | F21 negative -0.11 | 15th | F77 negative -0.01 |'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dict = create_classes_dict()\n",
    "linearise_input(example_dict, 'ord_first', 15, data_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feature importance score of F#\n",
    "* What is F#1 - F#2?\n",
    "* xth most important feature?\n",
    "* Top 2,3,4,5 positive features?\n",
    "* Top 2,3,4,5 negative features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F65', 'F61', 'F45', 'F30', 'F13', 'F63', 'F56']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ft for ft, sign in zip(example_dict['feature_nums'],example_dict['sign']) if sign == 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,len(example_dict['feature_nums'])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_generator(dict):\n",
    "    # 'What is the value of FA?'\n",
    "    choice = random.randint(0,len(example_dict['feature_nums'])-1)\n",
    "    feat = example_dict['feature_nums'][choice]\n",
    "    q1 = f'What is the value of {feat}?'\n",
    "    val = example_dict['values'][choice]\n",
    "    a1 = val\n",
    "    \n",
    "    # What is FA - FB?\n",
    "    choice1 = random.randint(0,len(example_dict['feature_nums'])-1)\n",
    "    feat1 = example_dict['feature_nums'][choice1]\n",
    "    val1 = example_dict['values'][choice1]\n",
    "    choice2 = random.randint(0,len(example_dict['feature_nums'])-1)\n",
    "    feat2 = example_dict['feature_nums'][choice2]\n",
    "    val2 = example_dict['values'][choice2]\n",
    "    q2 = f'What is the difference between {feat1} and {feat2}?'\n",
    "    a2 = format(float(val1) - float(val2), '.2f')\n",
    "    \n",
    "    # What is the xth most important feature?\n",
    "    choice = random.randint(0,len(example_dict['feature_nums'])-1)\n",
    "    feat = example_dict['feature_nums'][choice]\n",
    "    q3 = f'What is the {choice+1}th most important feature?'\n",
    "    a3 = feat\n",
    "    \n",
    "    # Top x postive features: \n",
    "    x = random.randint(1,5)\n",
    "    top_x_pos_fts = [ft for ft, sign in zip(example_dict['feature_nums'],example_dict['sign']) if sign == 'positive'][:x]\n",
    "    q4 = f'What are the top {x} positive features?'\n",
    "    a4 = ', '.join(top_x_pos_fts)\n",
    "    \n",
    "    # Top x negative features: \n",
    "    x = random.randint(1,5)\n",
    "    top_x_neg_fts = [ft for ft, sign in zip(example_dict['feature_nums'],example_dict['sign']) if sign == 'negative'][:x]\n",
    "    q4 = f'What are the top {x} negative features?'\n",
    "    a4 = ', '.join(top_x_neg_fts)\n",
    "    \n",
    "    dict['quesitons'] = [q1, q2, q3, q4]\n",
    "    dict['answers'] = [a1, a2, a3, a4]\n",
    "    \n",
    "    return dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
