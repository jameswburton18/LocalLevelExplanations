{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/CodingProjects/Local_level_model_explanations/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from src.datasetComposer import DatasetBuilder, composed_train_path, composed_test_path, compactComposer, test_path, train_path, test_path\n",
    "from src.inference_routine import InferenceGenerator\n",
    "from src.datasetHandlers import SmartCollator\n",
    "from src.model_utils import get_basic_model\n",
    "from src.trainerArgs import CustomTrainer, getTrainingArguments\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterative_gen = False\n",
    "composed_already = False\n",
    "\n",
    "# Define the parameters used to set up the models\n",
    "modeltype = 'iterative' if iterative_gen else 'normal'  # either baseline or 'earlyfusion'\n",
    "\n",
    "# either t5-small,t5-base, t5-large, facebook/bart-base, or facebook/bart-large\n",
    "modelbase = 'facebook/bart-base'\n",
    "\n",
    "# we will use the above variables to set up the folder to save our model\n",
    "pre_trained_model_name = modelbase.split(\n",
    "    '/')[1] if 'bart' in modelbase else modelbase\n",
    "\n",
    "# where the trained model will be saved\n",
    "output_path = 'TrainModels/' + modeltype + '/'+pre_trained_model_name+'/'\n",
    "\n",
    "#tests = json.load(open(test_path,encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "Only the data for the iterative generation have been processed already to reduce the loading and processing time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset built\n",
      "Training size: 530\n",
      "Test size: 48\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "if iterative_gen:\n",
    "    experiments_dataset = DatasetBuilder(train_data_path=composed_train_path,\n",
    "                                     test_data_path=composed_test_path,\n",
    "                                     modelbase= modelbase,\n",
    "                                     iterative_mode= iterative_gen,\n",
    "                                     composed_already=composed_already)\n",
    "else:\n",
    "    experiments_dataset = DatasetBuilder(train_data_path=train_path,\n",
    "                                     test_data_path=test_path,\n",
    "                                     modelbase= modelbase,\n",
    "                                     iterative_mode= False,\n",
    "                                     composed_already=False)\n",
    "\n",
    "\n",
    "experiments_dataset.fit()\n",
    "\n",
    "print('Dataset built')\n",
    "print(f\"Training size: {len(experiments_dataset.train_dataset)}\")\n",
    "print(f\"Test size: {len(experiments_dataset.test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Below we create the narration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingArguments??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 453\n",
      "using `logging_steps` to initialize `eval_steps` to 500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "rand_seed = 453\n",
    "seed_everything(rand_seed)\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "arguments = train_arguments = {'output_dir': output_path,\n",
    "                               'warmup_ratio': 0.2,\n",
    "                               #'disable_tqdm':False,\n",
    "                               'per_device_train_batch_size': 8,\n",
    "                               'num_train_epochs': 4,\n",
    "                               'lr_scheduler_type': 'cosine',\n",
    "                               'learning_rate': 5e-5,\n",
    "                               'evaluation_strategy': 'steps',\n",
    "                               'logging_steps': 500,\n",
    "                               \n",
    "                               'seed': rand_seed}\n",
    "\n",
    "# Build actual trainingArgument object\n",
    "training_arguments = getTrainingArguments(train_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/essel/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /home/essel/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "getModel = get_basic_model(experiments_dataset)\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(model_init=getModel,\n",
    "                        data_collator=SmartCollator(\n",
    "                            pad_token_id=experiments_dataset.tokenizer_.pad_token_id),\n",
    "                        args=training_arguments,\n",
    "                        train_dataset=experiments_dataset.train_dataset,\n",
    "                        eval_dataset=experiments_dataset.test_dataset,\n",
    "                        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Save the model with the lowest evaluation loss\n",
    "trainer.save_model()\n",
    "trainer.save_state()\n",
    "\n",
    "# get the best checkpoint\n",
    "best_check_point = trainer.state.best_model_checkpoint\n",
    "\n",
    "\n",
    "params_dict = train_arguments\n",
    "\n",
    "params_dict['best_check_point'] = best_check_point\n",
    "params_dict['output_path'] = output_path\n",
    "json.dump(params_dict, open(f'{output_path}/parameters.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = trainer.model.generator.to(device)\n",
    "inference_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = json.load(open(test_path, encoding='utf-8'))\n",
    "# ,iterative_mode=False,force_section=False\n",
    "if iterative_gen:\n",
    "    test_examples = compactComposer(\n",
    "        tests, iterative_mode=iterative_gen, force_section=True)\n",
    "    test_examples2 = compactComposer(tests, iterative_mode=iterative_gen, force_section=False)\n",
    "else:\n",
    "    test_examples = compactComposer(tests, iterative_mode=iterative_gen, force_section=False)\n",
    "\n",
    "# Instantiate the inference routine\n",
    "iterativeGen = InferenceGenerator(inference_model,\n",
    "                                  experiments_dataset,\n",
    "                                  device,\n",
    "                                  max_iter=8,\n",
    "                                  sampling=False, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Generation Iteratively\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "max_full_len = 300\n",
    "if iterative_gen:\n",
    "    print(\"Explanation Generation Iteratively\")\n",
    "    iterativeGen.sampling = False\n",
    "    #output_sentences = iterativeGen.MultipleIterativeGeneratorJoint( test_examples, parsed_args.seed,)\n",
    "    output_sentences = iterativeGen.MultipleIterativeGeneratorJoint(\n",
    "        test_examples[:1], rand_seed, length_penalty=1.6,max_length=269)\n",
    "    output_sentences2 = iterativeGen.MultipleIterativeGeneratorJoint(\n",
    "        test_examples2[:1], rand_seed, length_penalty=1.6,max_length=269)\n",
    "else:\n",
    "    print(\"Full Explanation Generation\")\n",
    "    output_sentences = iterativeGen.MultipleFullGeneratorJoint(\n",
    "        test_examples, rand_seed, max_length=max_full_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples[:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The most probable label for the given case is C1 with a predicted probability of 69.02%, which implies that there is a 30.98% chance that  C2 could be the correct label. F3, F2, and F8 are the features with the most influence on the classifier's decision. F5, F7, and F10 are the features that increase the likelihood of C1 being the correct label. F3, F2, and F8 are the positive features that increase the likelihood of C1 being the correct label. F5, F7, and F10 are the positive features that increase the odds of C1 being the correct label. On the other hand, F9 and F4 are shown to have very little impact on the classifier's decision here.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f53d471a03fb5b9741311ec5f82522ec5f217d64ed47634b801d3f5199a0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
